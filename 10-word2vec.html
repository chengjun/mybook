

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>è¯å‘é‡æ¨¡å‹ç®€ä»‹ &#8212; è®¡ç®—ä¼ æ’­å­¦</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '10-word2vec';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Doc2Vec" href="10-doc2vec.html" />
    <link rel="prev" title="ç¬¬å…«ç«  æ–‡æœ¬æŒ–æ˜" href="10-text-mining-gov-report.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/socrates_jump.gif" class="logo__image only-light" alt="è®¡ç®—ä¼ æ’­å­¦ - Home"/>
    <script>document.write(`<img src="_static/socrates_jump.gif" class="logo__image only-dark" alt="è®¡ç®—ä¼ æ’­å­¦ - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    å¯»æ‰¾äººç±»ä¼ æ’­è¡Œä¸ºçš„åŸºå› 
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="01-intro2cjc.html">ç¬¬ä¸€ç«  è®¡ç®—ä¼ æ’­å­¦ç®€ä»‹</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="02-bigdata.html">æ•°æ®ç§‘å­¦çš„ç¼–ç¨‹å·¥å…·ï¼šå¤§æ•°æ®</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="03-python-intro.html">ç¬¬äºŒç«  æ•°æ®ç§‘å­¦çš„ç¼–ç¨‹å·¥å…·</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="0-jupyter-notebook.html">Jupyter Notebook</a></li>
<li class="toctree-l2"><a class="reference internal" href="0-chatgpt.html">Using ChatGPT to Learn Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="0-iching.html">iching: A python package of I Ching</a></li>
<li class="toctree-l2"><a class="reference internal" href="01-recombination.html">è®¡ç®—æ€ç»´ï¼šé€šè¿‡æ‹†è§£å’Œé‡ç»„å­¦ä¹ </a></li>
<li class="toctree-l2"><a class="reference internal" href="0-slides.html">ä½¿ç”¨Jupyteråˆ¶ä½œSlidesçš„ä»‹ç»</a></li>
<li class="toctree-l2"><a class="reference internal" href="0-turicreate.html">Turicreate: Departure from Graphlab</a></li>
<li class="toctree-l2"><a class="reference internal" href="0-matplotlib-chinese.html">è§£å†³Matplotlibç»˜å›¾æ˜¾ç¤ºä¸­æ–‡é—®é¢˜</a></li>
<li class="toctree-l2"><a class="reference internal" href="03-UK-MPS-Scandal.html">æ¡ˆä¾‹ï¼š2009å¹´è‹±å›½å›½ä¼šè®®å‘˜å¼€æ”¯ä¸‘é—»</a></li>
<li class="toctree-l2"><a class="reference internal" href="03-umbrella-of-love.html">æ¡ˆä¾‹ï¼šã€Šè½¬è§’é‡åˆ°çˆ±ã€‹èƒŒåçš„æ•°æ®</a></li>
<li class="toctree-l2"><a class="reference internal" href="03-who-runs-China.html">æ¡ˆä¾‹ï¼šWho runs Chinaï¼ŸèƒŒåçš„æ•°æ®</a></li>
<li class="toctree-l2"><a class="reference internal" href="03-gdelt.html">Gdelt Dataset: Events, Mentions, and Global Knowledge Graph</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="04-crawler-beautifulsoup.html">ç¬¬ä¸‰ç«  æ•°æ®æŠ“å–</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-fact-checking.html">æŠ“å–å®æ—¶è¾Ÿè°£æ•°æ®</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-13chambers.html">æŠ“å–ç½‘ç»œå°è¯´</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-wechat.html">æŠ“å–å¾®ä¿¡å…¬ä¼—å·æ–‡ç« å†…å®¹</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-douban.html">ä½¿ç”¨requests + XpathæŠ“å–è±†ç“£ç”µå½±æ•°æ®</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-gov-report.html">æŠ“å–å†å±Šæ”¿åºœå·¥ä½œæŠ¥å‘Š</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-cppcc.html">æŠ“å–æ±Ÿè‹çœæ”¿ååå¹´ææ¡ˆ</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-netease-music.html">æŠ“å–ç½‘æ˜“äº‘éŸ³ä¹çƒ­é—¨è¯„è®º</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-selenium.html">ä½¿ç”¨Seleniumæ“çºµæµè§ˆå™¨</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-selenium-music-history.html">æŠ“å–ç½‘æ˜“äº‘éŸ³ä¹ç”¨æˆ·çš„å¬æ­Œè®°å½•</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-selenium-people-com-search.html">ä½¿ç”¨Seleniumæå–äººæ°‘ç½‘æœç´¢æ•°æ®</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-tripadvisor.html">ä½¿ç”¨SeleniumæŠ“å–TripAdvisorç”¨æˆ·è¯„è®º</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-pyppeteer.html">ä½¿ç”¨Pyppeteerå®ç°å¼‚æ­¥æŠ“å–!</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-weibo.html">è½»å‹å¾®åšçˆ¬è™«</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-snscrape-twitter.html">snscrape</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="06-data-cleaning-intro.html">ç¬¬å››ç«  æ•°æ®æ¸…æ´—</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="06-data-cleaning-preprocessing.html">å¯¹å¤§æ•°æ®è¿›è¡Œé¢„å¤„ç†</a></li>
<li class="toctree-l2"><a class="reference internal" href="06-data-cleaning-tweets.html">æ•°æ®æ¸…æ´—ä¹‹æ¨ç‰¹æ•°æ®</a></li>
<li class="toctree-l2"><a class="reference internal" href="06-data-cleaning-occupy-central-news.html">å¯¹å ä¸­æ–°é—»è¿›è¡Œæ•°æ®æ¸…æ´—</a></li>
<li class="toctree-l2"><a class="reference internal" href="06-data-cleaning-music-list.html">æ¸…æ´—éŸ³ä¹åˆ—è¡¨ğŸµ</a></li>
<li class="toctree-l2"><a class="reference internal" href="06-data-cleaning-pandas.html">ä½¿ç”¨Pandasè¿›è¡Œæ•°æ®æ¸…æ´—</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="08-01-statistics-thinking.html">ç¬¬äº”ç«  ç»Ÿè®¡æ€ç»´</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="08-02-kl-divergence.html">KL Divergence</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-02-linear-algebra.html">Linear algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-03-distributions.html">Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-03-probability.html">Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-04-hypothesis-inference.html">Statistical Hypothesis Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-05-gradient-descent.html">Introduction to Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-06-regression.html">Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-06-statsmodels.html">Statistical Modeling with Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-07-analyzing-titanic-dataset.html">Logistic Regression of Titanic Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-07-covid19-pew-survey.html">Analysing the Pew Survey Data of COVID19</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-11-cfps-survey-analysis.html">ä¸­å›½å®¶åº­è¿½è¸ªè°ƒæŸ¥2018</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-08-covid19-grangercausality.html">ç¤¾äº¤åª’ä½“å¯ä»¥é¢„æµ‹æ–°å† ç–«æƒ…å—ï¼Ÿ</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-09-survival-analysis.html">Survival Analysis with Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-10-dowhy-estimation-methods.html">The Book of Why</a></li>

</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="09-01-machine-learning-with-sklearn.html">ç¬¬å…­ç«  ç¤¾ä¼šç§‘å­¦å®¶çš„æœºå™¨å­¦ä¹ </a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="09-03-hyperparameters-and-model-validation.html">Hyperparameters and Model Validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-04-feature-engineering.html">Feature Engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-05-naive-bayes.html">In Depth: Naive Bayes Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-06-linear-regression.html">In Depth: Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-07-support-vector-machines.html">In-Depth: Support Vector Machines</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-08-random-forests.html">In-Depth: Decision Trees and Random Forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-09-googleflustudy.html">Forecasting and nowcasting with Google Flu Trends</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-10-future-employment.html">The future of employment</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-grf.html">Causal Forests</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="09-11-neural-network-intro.html">ç¬¬ä¸ƒç«  ç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ </a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="09-13-cnn.html">Convolutional Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-14-rnn.html">Sequnce Modeling: Recurrent and Recursive Nets</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-12-hand-written-digits.html">Recognizing Hand-Written Digits with Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-15-cifar10.html">ä½¿ç”¨CNNå¯¹CIFAR10å›¾åƒè¿›è¡Œåˆ†ç±»</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-16-pytorch_vgg_pretrained.html">VGG16é¢„è®­ç»ƒæ¨¡å‹</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="10-text-mining-gov-report.html">ç¬¬å…«ç«  æ–‡æœ¬æŒ–æ˜</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">è¯å‘é‡æ¨¡å‹ç®€ä»‹</a></li>
<li class="toctree-l2"><a class="reference internal" href="10-doc2vec.html">Doc2Vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-1-sentiment-analysis-with-dict.html">åŸºäºå­—å…¸çš„æƒ…æ„Ÿåˆ†æ</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-2-emotion-dict.html">å¤§è¿ç†å·¥å¤§å­¦ä¸­æ–‡æƒ…æ„Ÿè¯æ±‡</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-3-NRC-Chinese-dict.html">åŸºäºNRCå­—å…¸çš„æƒ…æ„Ÿåˆ†æ</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-3-textblob.html">åˆ©ç”¨textblobè¿›è¡Œæƒ…æ„Ÿåˆ†æ</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-4-sentiment-classifier.html">åŸºäºæœºå™¨å­¦ä¹ çš„æƒ…æ„Ÿåˆ†æ</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-5-LIWC.html">LIWC: Linguistic Inquiry and Word Count  analyzer</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-6-Chinese-moral-foundation-dict.html">Chinese Moral Foundation Dictionary 2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="12-topic-models-update.html">ä¸»é¢˜æ¨¡å‹ç®€ä»‹</a></li>
<li class="toctree-l2"><a class="reference internal" href="12-topic-models-with-turicreate.html">ä½¿ç”¨Turicreateå»ºç«‹ä¸»é¢˜æ¨¡å‹</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="13-recsys-intro.html">ç¬¬ä¹ç«  æ¨èç³»ç»Ÿç®€ä»‹</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="13-recsys-latent-factor-model.html">Latent Factor Recommender System</a></li>
<li class="toctree-l2"><a class="reference internal" href="13-recsys-intro-surprise.html">ä½¿ç”¨Surpriseæ„å»ºæ¨èç³»ç»Ÿ</a></li>
<li class="toctree-l2"><a class="reference internal" href="14-millionsong.html">ä½¿ç”¨Turicreateè¿›è¡ŒéŸ³ä¹æ¨è</a></li>
<li class="toctree-l2"><a class="reference internal" href="14-movielens.html">ä½¿ç”¨Turicreateè¿›è¡Œç”µå½±æ¨è</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="15-network-science-intro.html">ç¬¬åç«  ç½‘ç»œç§‘å­¦ç®€ä»‹</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="16-network-science-models.html">ç½‘ç»œç§‘å­¦æ¨¡å‹</a></li>
<li class="toctree-l2"><a class="reference internal" href="17-networkx.html">ä½¿ç”¨NetworkXåˆ†æç½‘ç»œ</a></li>
<li class="toctree-l2"><a class="reference internal" href="18-02-network-diffusion.html">Simulating Network Diffusion With NDlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="18-03-network-epidemics.html">Epidemics on Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="18-04-seir-hcd-model.html">SEIR-HCD Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="18-network-ergm-siena.html">Social Network Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="18-network-weibo-hot-search.html">å¾®åšçƒ­æœåˆ†æ</a></li>
<li class="toctree-l2"><a class="reference internal" href="18-network-analysis-of-tianya-bbs.html">å¤©æ¶¯è®ºå›çš„å›å¸–ç½‘ç»œåˆ†æ</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-facebook-ego-netwrok-visualization.html">å¯è§†åŒ–Facebookç¤¾äº¤ç½‘ç»œ</a></li>
<li class="toctree-l2"><a class="reference internal" href="18-network-ecomplexity.html">Economic Complexity and Product Complexity</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="19-visualization-with-seaborn.html">ç¬¬åä¸€ç«  å¯è§†åŒ–</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-matplotlib-colormap.html">Qualitative Colormaps in Matplotlib Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-scientific-plot.html">Matplotlibçš„ç§‘å­¦ç»˜å›¾æ ·å¼</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-with-pyecharts.html">ä½¿ç”¨PyEchartsè¿›è¡Œå¯è§†åŒ–</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-plotly-express.html">Plotly Express in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-maps-using-folium.html">ä½¿ç”¨foliumåšåœ°å›¾å¯è§†åŒ–</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-datashader.html">ä½¿ç”¨Datashaderå¯è§†åŒ–åœ°ç†ä¿¡æ¯</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-datapane.html">ä½¿ç”¨Datapaneåˆ¶ä½œæ•°æ®æŠ¥å‘Š</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-pantheon.html">ä¸‡ç¥æ®¿é¡¹ç›®ï¼ˆPantheon Projectï¼‰</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/chengjun/mybook/blob/main/10-word2vec.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/chengjun/mybook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/chengjun/mybook/issues/new?title=Issue%20on%20page%20%2F10-word2vec.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/10-word2vec.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>è¯å‘é‡æ¨¡å‹ç®€ä»‹</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-geometry-of-culture">The Geometry of Culture</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#histwords">HistWords</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-embeddings-quantify-100-years-of-gender-and-ethnic-stereotypes">Word embeddings quantify 100 years of gender and ethnic stereotypes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-illustrated-word2vec">The Illustrated Word2vec</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#personality-embeddings">Personality Embeddings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cosine-similarity">Cosine Similarity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-embeddings">Word Embeddings</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#google-news-word2vec">Google News Word2Vec</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-neural-language-model">The neural language model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#language-model-training">Language Model Training</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#skip-gram">Skip-gram</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#negative-sampling">Negative Sampling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#word2vec-training-process">Word2vec Training Process</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-word2vec">Pytorch word2vec</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ngram">NGramè¯å‘é‡æ¨¡å‹</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gensim-word2vec">Gensim Word2vec</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>è¯å‘é‡æ¨¡å‹ç®€ä»‹<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h1>
<p>Introduction to Word Embeddings: Analyzing Meaning through Word Embeddings</p>
<p><strong>Using vectors to represent things</strong></p>
<ul class="simple">
<li><p>one of the most fascinating ideas in machine learning.</p></li>
<li><p>Word2vec is a method to efficiently create word embeddings.</p>
<ul>
<li><p>Mikolov et al. (2013). <a class="reference external" href="https://arxiv.org/pdf/1301.3781.pdf">Efficient Estimation of Word Representations in Vector Space</a></p></li>
<li><p>Mikolov et al. (2013). <a class="reference external" href="https://arxiv.org/pdf/1310.4546.pdf">Distributed representations of words and phrases and their compositionality</a></p></li>
</ul>
</li>
</ul>
<section id="the-geometry-of-culture">
<h2>The Geometry of Culture<a class="headerlink" href="#the-geometry-of-culture" title="Permalink to this heading">#</a></h2>
<p>Analyzing Meaning through Word Embeddings</p>
<p>Austin C. Kozlowski; Matt Taddy; James A. Evans</p>
<p><a class="reference external" href="https://arxiv.org/abs/1803.09288">https://arxiv.org/abs/1803.09288</a></p>
<p>Word embeddings represent <strong>semantic relations</strong> between words as <strong>geometric relationships</strong> between vectors in a high-dimensional space, operationalizing a relational model of meaning consistent with contemporary theories of identity and culture.</p>
<ul class="simple">
<li><p>Dimensions induced by word differences (e.g. man - woman, rich - poor, black - white, liberal - conservative) in these vector spaces closely correspond to dimensions of cultural meaning,</p></li>
<li><p>Macro-cultural investigation with a longitudinal analysis of the coevolution of gender and class associations in the United States over the 20th century</p></li>
</ul>
<p>The success of these high-dimensional models motivates a move towards â€œhigh-dimensional theorizingâ€ of meanings, identities and cultural processes.</p>
<a class="reference internal image-reference" href="_images/gender_class.png"><img alt="_images/gender_class.png" src="_images/gender_class.png" style="width: 700px;" /></a>
</section>
<section id="histwords">
<h2>HistWords<a class="headerlink" href="#histwords" title="Permalink to this heading">#</a></h2>
<p>HistWords is a collection of tools and datasets for analyzing language change using word vector embeddings.</p>
<ul class="simple">
<li><p>The goal of this project is to facilitate quantitative research in diachronic linguistics, history, and the digital humanities.</p></li>
<li><p>We used the historical word vectors in HistWords to study the semantic evolution of more than 30,000 words across 4 languages.</p></li>
<li><p>This study led us to propose two statistical laws that govern the evolution of word meaning</p></li>
</ul>
<p><a class="reference external" href="https://nlp.stanford.edu/projects/histwords/">https://nlp.stanford.edu/projects/histwords/</a></p>
<p><a class="github reference external" href="https://github.com/williamleif/histwords">williamleif/histwords</a></p>
<p><strong>Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change</strong></p>
<a class="reference internal image-reference" href="_images/wordpaths-final.png"><img alt="_images/wordpaths-final.png" src="_images/wordpaths-final.png" style="width: 900px;" /></a>
</section>
<section id="word-embeddings-quantify-100-years-of-gender-and-ethnic-stereotypes">
<h2>Word embeddings quantify 100 years of gender and ethnic stereotypes<a class="headerlink" href="#word-embeddings-quantify-100-years-of-gender-and-ethnic-stereotypes" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="http://www.pnas.org/content/early/2018/03/30/1720347115">http://www.pnas.org/content/early/2018/03/30/1720347115</a></p>
<a class="reference internal image-reference" href="_images/sex.png"><img alt="_images/sex.png" src="_images/sex.png" style="width: 500px;" /></a>
</section>
<section id="the-illustrated-word2vec">
<h2>The Illustrated Word2vec<a class="headerlink" href="#the-illustrated-word2vec" title="Permalink to this heading">#</a></h2>
<p>Jay Alammar.  <a class="reference external" href="https://jalammar.github.io/illustrated-word2vec/">https://jalammar.github.io/illustrated-word2vec/</a></p>
</section>
<section id="personality-embeddings">
<h2>Personality Embeddings<a class="headerlink" href="#personality-embeddings" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><p>What are you like?</p>
</div></blockquote>
<p><strong>Big Five personality traits</strong>: openness to experience, conscientiousness, extraversion, agreeableness, and neuroticism</p>
<ul class="simple">
<li><p>the five-factor model (FFM)</p></li>
<li><p><strong>the OCEAN model</strong></p></li>
</ul>
<ul class="simple">
<li><p>å¼€æ”¾æ€§ï¼ˆopennessï¼‰ï¼šå…·æœ‰æƒ³è±¡ã€å®¡ç¾ã€æƒ…æ„Ÿä¸°å¯Œã€æ±‚å¼‚ã€åˆ›é€ ã€æ™ºèƒ½ç­‰ç‰¹è´¨ã€‚</p></li>
<li><p>è´£ä»»å¿ƒï¼ˆconscientiousnessï¼‰ï¼šæ˜¾ç¤ºèƒœä»»ã€å…¬æ­£ã€æ¡ç†ã€å°½èŒã€æˆå°±ã€è‡ªå¾‹ã€è°¨æ…ã€å…‹åˆ¶ç­‰ç‰¹ç‚¹ã€‚</p></li>
<li><p>å¤–å€¾æ€§ï¼ˆextraversionï¼‰ï¼šè¡¨ç°å‡ºçƒ­æƒ…ã€ç¤¾äº¤ã€æœæ–­ã€æ´»è·ƒã€å†’é™©ã€ä¹è§‚ç­‰ç‰¹è´¨ã€‚</p></li>
<li><p>å®œäººæ€§ï¼ˆagreeablenessï¼‰ï¼šå…·æœ‰ä¿¡ä»»ã€åˆ©ä»–ã€ç›´ç‡ã€ä¾ä»ã€è°¦è™šã€ç§»æƒ…ç­‰ç‰¹è´¨ã€‚</p></li>
<li><p>ç¥ç»è´¨æˆ–æƒ…ç»ªç¨³å®šæ€§ï¼ˆneuroticismï¼‰ï¼šå…·æœ‰å¹³è¡¡ç„¦è™‘ã€æ•Œå¯¹ã€å‹æŠ‘ã€è‡ªæˆ‘æ„è¯†ã€å†²åŠ¨ã€è„†å¼±ç­‰æƒ…ç»ªçš„ç‰¹è´¨ï¼Œå³å…·æœ‰ä¿æŒæƒ…ç»ªç¨³å®šçš„èƒ½åŠ›ã€‚</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Personality Embeddings: What are you like?</span>
<span class="n">jay</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]</span>
<span class="n">john</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]</span>
<span class="n">mike</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="cosine-similarity">
<h2>Cosine Similarity<a class="headerlink" href="#cosine-similarity" title="Permalink to this heading">#</a></h2>
<p>The cosine of two non-zero vectors can be derived by using the Euclidean dot product formula:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{A}\cdot\mathbf{B}
=\left\|\mathbf{A}\right\|\left\|\mathbf{B}\right\|\cos\theta
\]</div>
<div class="math notranslate nohighlight">
\[
\text{similarity} = \cos(\theta) = {\mathbf{A} \cdot \mathbf{B} \over \|\mathbf{A}\| \|\mathbf{B}\|} = \frac{ \sum\limits_{i=1}^{n}{A_i  B_i} }{ \sqrt{\sum\limits_{i=1}^{n}{A_i^2}}  \sqrt{\sum\limits_{i=1}^{n}{B_i^2}} },
\]</div>
<p>where <span class="math notranslate nohighlight">\(A_i\)</span> and <span class="math notranslate nohighlight">\(B_i\)</span> are components of vector <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> respectively.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">dot</span>
<span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">norm</span>

<span class="k">def</span> <span class="nf">cos_sim</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">dot</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">*</span><span class="n">norm</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>

<span class="n">cos_sim</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.4999999999999999
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>

<span class="n">cosine_similarity</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[-0.5]])
</pre></div>
</div>
</div>
</div>
<div class="math notranslate nohighlight">
\[CosineDistance = 1- CosineSimilarity\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">spatial</span>
<span class="c1"># spatial.distance.cosine computes </span>
<span class="c1"># the Cosine distance between 1-D arrays.</span>
<span class="mi">1</span><span class="o">-</span><span class="n">spatial</span><span class="o">.</span><span class="n">distance</span><span class="o">.</span><span class="n">cosine</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.5
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cos_sim</span><span class="p">(</span><span class="n">jay</span><span class="p">,</span> <span class="n">john</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6582337075311759
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cos_sim</span><span class="p">(</span><span class="n">jay</span><span class="p">,</span> <span class="n">mike</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.3683509554826695
</pre></div>
</div>
</div>
</div>
<p>Cosine similarity works for any number of dimensions.</p>
<ul class="simple">
<li><p>We can represent people (and things) as vectors of numbers (which is great for machines!).</p></li>
<li><p>We can easily calculate how similar vectors are to each other.</p></li>
</ul>
</section>
<section id="word-embeddings">
<h2>Word Embeddings<a class="headerlink" href="#word-embeddings" title="Permalink to this heading">#</a></h2>
<section id="google-news-word2vec">
<h3>Google News Word2Vec<a class="headerlink" href="#google-news-word2vec" title="Permalink to this heading">#</a></h3>
<p>You can download Googleâ€™s pre-trained model here.</p>
<ul class="simple">
<li><p>Itâ€™s 1.5GB!</p></li>
<li><p>It includes word vectors for a vocabulary of 3 million words and phrases</p></li>
<li><p>It is trained on roughly 100 billion words from a Google News dataset.</p></li>
<li><p>The vector length is 300 features.</p></li>
</ul>
<p><a class="reference external" href="http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/">http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/</a></p>
<p>Using the <strong>Gensim</strong> library in python, we can</p>
<ul class="simple">
<li><p>find the most similar words to the resulting vector.</p></li>
<li><p>add and subtract word vectors,</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gensim</span>
<span class="c1"># Load Google&#39;s pre-trained Word2Vec model.</span>
<span class="n">filepath</span> <span class="o">=</span> <span class="s1">&#39;/Users/datalab/bigdata/GoogleNews-vectors-negative300.bin&#39;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">[</span><span class="s1">&#39;woman&#39;</span><span class="p">][:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 0.24316406, -0.07714844, -0.10302734, -0.10742188,  0.11816406],
      dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s1">&#39;woman&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;man&#39;, 0.7664012908935547),
 (&#39;girl&#39;, 0.7494640946388245),
 (&#39;teenage_girl&#39;, 0.7336829900741577),
 (&#39;teenager&#39;, 0.631708562374115),
 (&#39;lady&#39;, 0.6288785934448242),
 (&#39;teenaged_girl&#39;, 0.614178478717804),
 (&#39;mother&#39;, 0.6076306104660034),
 (&#39;policewoman&#39;, 0.6069462299346924),
 (&#39;boy&#39;, 0.5975908637046814),
 (&#39;Woman&#39;, 0.5770983099937439)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="s1">&#39;woman&#39;</span><span class="p">,</span> <span class="s1">&#39;man&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.76640123
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cos_sim</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="s1">&#39;woman&#39;</span><span class="p">],</span> <span class="n">model</span><span class="p">[</span><span class="s1">&#39;man&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.76640123
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;woman&#39;</span><span class="p">,</span> <span class="s1">&#39;king&#39;</span><span class="p">],</span> <span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;man&#39;</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;queen&#39;, 0.7118193507194519),
 (&#39;monarch&#39;, 0.6189674735069275),
 (&#39;princess&#39;, 0.5902431011199951),
 (&#39;crown_prince&#39;, 0.5499460697174072),
 (&#39;prince&#39;, 0.5377321243286133)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;London&#39;</span><span class="p">,</span> <span class="s1">&#39;China&#39;</span><span class="p">],</span> <span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Beijing&#39;</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;UK&#39;, 0.6304796934127808),
 (&#39;Britain&#39;, 0.6012536287307739),
 (&#39;EURASIAN_NATURAL_RESOURCES_CORP.&#39;, 0.5524139404296875),
 (&#39;Europe&#39;, 0.5444058775901794),
 (&#39;United_Kingdom&#39;, 0.5375455021858215)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;big&#39;</span><span class="p">,</span> <span class="s1">&#39;worst&#39;</span><span class="p">],</span> <span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;bad&#39;</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;biggest&#39;, 0.7630176544189453),
 (&#39;greatest&#39;, 0.6113720536231995),
 (&#39;major&#39;, 0.5540789365768433),
 (&#39;huge&#39;, 0.5368192195892334),
 (&#39;Biggest&#39;, 0.5305125713348389)]
</pre></div>
</div>
</div>
</div>
<div class="math notranslate nohighlight">
\[King- Queen = Man - Woman\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;go&#39;</span><span class="p">,</span> <span class="s1">&#39;do&#39;</span><span class="p">],</span> <span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;did&#39;</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;come&#39;, 0.6050394177436829),
 (&#39;get&#39;, 0.5739777684211731),
 (&#39;goes&#39;, 0.5202917456626892),
 (&#39;happen&#39;, 0.5166401267051697),
 (&#39;sit&#39;, 0.5145819187164307)]
</pre></div>
</div>
</div>
</div>
<a class="reference internal image-reference" href="_images/word2vec.png"><img alt="_images/word2vec.png" src="_images/word2vec.png" style="width: 700px;" /></a>
<p>Now that weâ€™ve looked at trained word embeddings,</p>
<ul class="simple">
<li><p>letâ€™s learn more about the training process.</p></li>
<li><p>But before we get to word2vec, we need to look at a conceptual parent of word embeddings: <strong>the neural language model</strong>.</p></li>
</ul>
</section>
</section>
<section id="the-neural-language-model">
<h2>The neural language model<a class="headerlink" href="#the-neural-language-model" title="Permalink to this heading">#</a></h2>
<p>â€œYou shall know a word by the company it keepsâ€ J.R. Firth</p>
<blockquote>
<div><p>Bengio 2003 A Neural Probabilistic Language Model. Journal of Machine Learning Research. 3:1137â€“1155</p>
</div></blockquote>
<p>After being trained, early neural language models (Bengio 2003) would calculate a prediction in three steps:</p>
<a class="reference internal image-reference" href="_images/neural-language-model-prediction.png"><img alt="_images/neural-language-model-prediction.png" src="_images/neural-language-model-prediction.png" style="width: 700px;" /></a>
<a class="reference internal image-reference" href="_images/bengio.png"><img alt="_images/bengio.png" src="_images/bengio.png" style="width: 400px;" /></a>
<p>The output of the neural language model is a probability score for all the words the model knows.</p>
<ul class="simple">
<li><p>Weâ€™re referring to the probability as a percentage here,</p></li>
<li><p>but 40% would actually be represented as 0.4 in the output vector.</p></li>
</ul>
<section id="language-model-training">
<h3>Language Model Training<a class="headerlink" href="#language-model-training" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>We get a lot of text data (say, all Wikipedia articles, for example). then</p></li>
<li><p>We have a window (say, of three words) that we slide against all of that text.</p></li>
<li><p>The sliding window generates training samples for our model</p></li>
</ul>
<a class="reference internal image-reference" href="_images/lm-sliding-window-4.png"><img alt="_images/lm-sliding-window-4.png" src="_images/lm-sliding-window-4.png" style="width: 700px;" /></a>
<p>As this window slides against the text, we (virtually) generate a dataset that we use to train a model.</p>
<p>Instead of only looking two words before the target word, we can also look at two words after it.</p>
<a class="reference internal image-reference" href="_images/continuous-bag-of-words-example.png"><img alt="_images/continuous-bag-of-words-example.png" src="_images/continuous-bag-of-words-example.png" style="width: 700px;" /></a>
<p>If we do this, the dataset weâ€™re virtually building and training the model against would look like this:</p>
<a class="reference internal image-reference" href="_images/continuous-bag-of-words-dataset.png"><img alt="_images/continuous-bag-of-words-dataset.png" src="_images/continuous-bag-of-words-dataset.png" style="width: 700px;" /></a>
<p>This is called a <strong>Continuous Bag of Words</strong> (CBOW) <a class="reference external" href="https://arxiv.org/pdf/1301.3781.pdf">https://arxiv.org/pdf/1301.3781.pdf</a></p>
</section>
<section id="skip-gram">
<h3>Skip-gram<a class="headerlink" href="#skip-gram" title="Permalink to this heading">#</a></h3>
<p>Instead of guessing a word based on its context (the words before and after it), this other architecture tries to guess neighboring words using the current word.</p>
<a class="reference internal image-reference" href="_images/skipgram.png"><img alt="_images/skipgram.png" src="_images/skipgram.png" style="width: 700px;" /></a>
<p><a class="reference external" href="https://arxiv.org/pdf/1301.3781.pdf">https://arxiv.org/pdf/1301.3781.pdf</a></p>
<a class="reference internal image-reference" href="_images/cbow.png"><img alt="_images/cbow.png" src="_images/cbow.png" style="width: 700px;" /></a>
<a class="reference internal image-reference" href="_images/skipgram-sliding-window-samples.png"><img alt="_images/skipgram-sliding-window-samples.png" src="_images/skipgram-sliding-window-samples.png" style="width: 700px;" /></a>
<p>The pink boxes are in different shades because this sliding window actually creates four separate samples in our training dataset.</p>
<ul class="simple">
<li><p>We then slide our window to the next position:</p></li>
<li><p>Which generates our next four examples:</p></li>
</ul>
<a class="reference internal image-reference" href="_images/skipgram-language-model-training.png"><img alt="_images/skipgram-language-model-training.png" src="_images/skipgram-language-model-training.png" style="width: 700px;" /></a>
<a class="reference internal image-reference" href="_images/skipgram-language-model-training-4.png"><img alt="_images/skipgram-language-model-training-4.png" src="_images/skipgram-language-model-training-4.png" style="width: 700px;" /></a>
<a class="reference internal image-reference" href="_images/skipgram-language-model-training-5.png"><img alt="_images/skipgram-language-model-training-5.png" src="_images/skipgram-language-model-training-5.png" style="width: 700px;" /></a>
<a class="reference internal image-reference" href="_images/language-model-expensive.png"><img alt="_images/language-model-expensive.png" src="_images/language-model-expensive.png" style="width: 700px;" /></a>
</section>
<section id="negative-sampling">
<h3>Negative Sampling<a class="headerlink" href="#negative-sampling" title="Permalink to this heading">#</a></h3>
<p>And switch it to a model that takes the input and output word, and outputs a score indicating <strong>if theyâ€™re neighbors or not</strong></p>
<ul class="simple">
<li><p>0 for â€œnot neighborsâ€, 1 for â€œneighborsâ€.</p></li>
</ul>
<a class="reference internal image-reference" href="_images/are-the-words-neighbors.png"><img alt="_images/are-the-words-neighbors.png" src="_images/are-the-words-neighbors.png" style="width: 700px;" /></a>
<a class="reference internal image-reference" href="_images/word2vec-negative-sampling-2.png"><img alt="_images/word2vec-negative-sampling-2.png" src="_images/word2vec-negative-sampling-2.png" style="width: 700px;" /></a>
<p>we need to introduce negative samples to our dataset</p>
<ul class="simple">
<li><p>samples of words that are not neighbors.</p></li>
<li><p>Our model needs to return 0 for those samples.</p></li>
<li><p>This leads to a great tradeoff of computational and statistical efficiency.</p></li>
</ul>
<p><strong>Skipgram with Negative Sampling (SGNS)</strong></p>
</section>
<section id="word2vec-training-process">
<h3>Word2vec Training Process<a class="headerlink" href="#word2vec-training-process" title="Permalink to this heading">#</a></h3>
<a class="reference internal image-reference" href="_images/word2vec-training-update.png"><img alt="_images/word2vec-training-update.png" src="_images/word2vec-training-update.png" style="width: 700px;" /></a>
</section>
</section>
<section id="pytorch-word2vec">
<h2>Pytorch word2vec<a class="headerlink" href="#pytorch-word2vec" title="Permalink to this heading">#</a></h2>
<p><a class="github reference external" href="https://github.com/jojonki/word2vec-pytorch/blob/master/word2vec.ipynb">jojonki/word2vec-pytorch</a></p>
<p><a class="github reference external" href="https://github.com/bamtercelboo/pytorch_word2vec/blob/master/model.py">bamtercelboo/pytorch_word2vec</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># see http://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;torch._C.Generator at 0x116c571d0&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;We are about to study the idea of a computational process.</span>
<span class="s2">Computational processes are abstract beings that inhabit computers.</span>
<span class="s2">As they evolve, processes manipulate other abstract things called data.</span>
<span class="s2">The evolution of a process is directed by a pattern of rules</span>
<span class="s2">called a program. People create programs to direct processes. In effect,</span>
<span class="s2">we conjure the spirits of the computer with our spells.&quot;&quot;&quot;</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># By deriving a set from `raw_text`, we deduplicate the array</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;vocab_size:&#39;</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

<span class="n">w2i</span> <span class="o">=</span> <span class="p">{</span><span class="n">w</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span>
<span class="n">i2w</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">w</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>vocab_size: 44
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># context window size is two</span>
<span class="k">def</span> <span class="nf">create_cbow_dataset</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
        <span class="n">context</span> <span class="o">=</span> <span class="p">[</span><span class="n">text</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">2</span><span class="p">],</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span>
                   <span class="n">text</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">context</span><span class="p">,</span> <span class="n">target</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">data</span>

<span class="n">cbow_train</span> <span class="o">=</span> <span class="n">create_cbow_dataset</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;cbow sample&#39;</span><span class="p">,</span> <span class="n">cbow_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cbow sample ([&#39;we&#39;, &#39;are&#39;, &#39;to&#39;, &#39;study&#39;], &#39;about&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_skipgram_dataset</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">random</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
        <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="c1"># negative sampling</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">or</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">-</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">rand_id</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">rand_id</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">text</span><span class="p">[</span><span class="n">rand_id</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">data</span>


<span class="n">skipgram_train</span> <span class="o">=</span> <span class="n">create_skipgram_dataset</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;skipgram sample&#39;</span><span class="p">,</span> <span class="n">skipgram_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>skipgram sample (&#39;about&#39;, &#39;we&#39;, 1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CBOW</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embd_size</span><span class="p">,</span> <span class="n">context_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CBOW</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embd_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">context_size</span><span class="o">*</span><span class="n">embd_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">hid</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">embedded</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="p">(</span><span class="n">hid</span><span class="p">)</span>
        <span class="n">log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_probs</span>
    
    <span class="k">def</span> <span class="nf">extract</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">embeds</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SkipGram</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embd_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SkipGram</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embd_size</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">focus</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
        <span class="n">embed_focus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">focus</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># input</span>
        <span class="n">embed_ctx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">context</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># output</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">embed_focus</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">embed_ctx</span><span class="p">))</span> <span class="c1"># input*output</span>
        <span class="n">log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">logsigmoid</span><span class="p">(</span><span class="n">score</span><span class="p">)</span> <span class="c1"># sigmoid</span>
        <span class="k">return</span> <span class="n">log_probs</span>
    
    <span class="k">def</span> <span class="nf">extract</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">focus</span><span class="p">):</span>
        <span class="n">embed_focus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">focus</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">embed_focus</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">torch.mm</span></code> Performs a matrix multiplication of the matrices</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.t</span></code> Expects :attr:<code class="docutils literal notranslate"><span class="pre">input</span></code> to be a matrix (2-D tensor) and transposes dimensions 0
and 1. Can be seen as a short-hand function for <code class="docutils literal notranslate"><span class="pre">transpose(input,</span> <span class="pre">0,</span> <span class="pre">1)</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embd_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">n_epoch</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">CONTEXT_SIZE</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># 2 words to the left, 2 to the right</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_cbow</span><span class="p">():</span>
    <span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">CBOW</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embd_size</span><span class="p">,</span> <span class="n">CONTEXT_SIZE</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epoch</span><span class="p">):</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">.0</span>
        <span class="k">for</span> <span class="n">context</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">cbow_train</span><span class="p">:</span>
            <span class="n">ctx_idxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">w2i</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">context</span><span class="p">]</span>
            <span class="n">ctx_var</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">ctx_idxs</span><span class="p">))</span>

            <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">log_probs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">ctx_var</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">w2i</span><span class="p">[</span><span class="n">target</span><span class="p">]])))</span>

            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_loss</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">losses</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_skipgram</span><span class="p">():</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">SkipGram</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embd_size</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epoch</span><span class="p">):</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">.0</span>
        <span class="k">for</span> <span class="n">in_w</span><span class="p">,</span> <span class="n">out_w</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">skipgram_train</span><span class="p">:</span>
            <span class="n">in_w_var</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">w2i</span><span class="p">[</span><span class="n">in_w</span><span class="p">]]))</span>
            <span class="n">out_w_var</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">w2i</span><span class="p">[</span><span class="n">out_w</span><span class="p">]]))</span>
            
            <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">log_probs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">in_w_var</span><span class="p">,</span> <span class="n">out_w_var</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">log_probs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">target</span><span class="p">])))</span>
            
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_loss</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">losses</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cbow_model</span><span class="p">,</span> <span class="n">cbow_losses</span> <span class="o">=</span> <span class="n">train_cbow</span><span class="p">()</span>
<span class="n">sg_model</span><span class="p">,</span> <span class="n">sg_losses</span> <span class="o">=</span> <span class="n">train_skipgram</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CBOW(
  (embeddings): Embedding(44, 100)
  (linear1): Linear(in_features=400, out_features=64, bias=True)
  (linear2): Linear(in_features=64, out_features=44, bias=True)
)
SkipGram(
  (embeddings): Embedding(44, 100)
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_epoch</span><span class="p">),</span> <span class="n">cbow_losses</span><span class="p">,</span> <span class="s1">&#39;r-o&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;CBOW Losses&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_epoch</span><span class="p">),</span> <span class="n">sg_losses</span><span class="p">,</span> <span class="s1">&#39;g-s&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;SkipGram Losses&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e0e533f62149b697a39be11984134982da41109a81caf981026e6789783156c0.png" src="_images/e0e533f62149b697a39be11984134982da41109a81caf981026e6789783156c0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cbow_vec</span> <span class="o">=</span> <span class="n">cbow_model</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">w2i</span><span class="o">.</span><span class="n">values</span><span class="p">()])))</span>
<span class="n">cbow_vec</span> <span class="o">=</span> <span class="n">cbow_vec</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">len</span><span class="p">(</span><span class="n">cbow_vec</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sg_vec</span> <span class="o">=</span> <span class="n">sg_model</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">w2i</span><span class="o">.</span><span class="n">values</span><span class="p">()])))</span>
<span class="n">sg_vec</span> <span class="o">=</span> <span class="n">sg_vec</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">len</span><span class="p">(</span><span class="n">sg_vec</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># åˆ©ç”¨PCAç®—æ³•è¿›è¡Œé™ç»´</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="n">X_reduced</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">sg_vec</span><span class="p">)</span>

<span class="c1"># ç»˜åˆ¶æ‰€æœ‰å•è¯å‘é‡çš„äºŒç»´ç©ºé—´æŠ•å½±</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_reduced</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="c1"># ç»˜åˆ¶å‡ ä¸ªç‰¹æ®Šå•è¯çš„å‘é‡</span>
<span class="n">words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">w2i</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="c1"># è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œå¦åˆ™æ— æ³•åœ¨å›¾å½¢ä¸Šæ˜¾ç¤ºä¸­æ–‡</span>
<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">w2i</span><span class="p">:</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">w2i</span><span class="p">[</span><span class="n">w</span><span class="p">]</span>
        <span class="n">xy</span> <span class="o">=</span> <span class="n">X_reduced</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xy</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xy</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">xy</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xy</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1885356bce901c5609348555ad9d541563565dbd9c652c2cfdfff15e3b235a06.png" src="_images/1885356bce901c5609348555ad9d541563565dbd9c652c2cfdfff15e3b235a06.png" />
</div>
</div>
</section>
<section id="ngram">
<h2>NGramè¯å‘é‡æ¨¡å‹<a class="headerlink" href="#ngram" title="Permalink to this heading">#</a></h2>
<p>æœ¬æ–‡ä»¶æ˜¯é›†æ™ºAIå­¦å›­http://campus.swarma.org å‡ºå“çš„â€œç«ç‚¬ä¸Šçš„æ·±åº¦å­¦ä¹ â€ç¬¬VIè¯¾çš„é…å¥—æºä»£ç </p>
<p>åŸç†ï¼šåˆ©ç”¨ä¸€ä¸ªäººå·¥ç¥ç»ç½‘ç»œæ¥æ ¹æ®å‰Nä¸ªå•è¯æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œä»è€Œå¾—åˆ°æ¯ä¸ªå•è¯çš„è¯å‘é‡</p>
<p>ä»¥åˆ˜æ…ˆæ¬£è‘—åçš„ç§‘å¹»å°è¯´ã€Šä¸‰ä½“ã€‹ä¸ºä¾‹ï¼Œæ¥å±•ç¤ºåˆ©ç”¨NGramæ¨¡å‹è®­ç»ƒè¯å‘é‡çš„æ–¹æ³•</p>
<ul class="simple">
<li><p>é¢„å¤„ç†åˆ†ä¸ºä¸¤ä¸ªæ­¥éª¤ï¼š1ã€è¯»å–æ–‡ä»¶ã€2ã€åˆ†è¯ã€3ã€å°†è¯­æ–™åˆ’åˆ†ä¸ºNï¼‹1å…ƒç»„ï¼Œå‡†å¤‡å¥½è®­ç»ƒç”¨æ•°æ®</p></li>
<li><p>åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¹¶æ²¡æœ‰å»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œä¸€æ˜¯ä¸ºäº†ç¼–ç¨‹ç®€æ´ï¼Œè€Œæ˜¯è€ƒè™‘åˆ°åˆ†è¯ä¼šè‡ªåŠ¨å°†æ ‡ç‚¹ç¬¦å·å½“ä½œä¸€ä¸ªå•è¯å¤„ç†ï¼Œå› æ­¤ä¸éœ€è¦é¢å¤–è€ƒè™‘ã€‚</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;../data/3body.txt&quot;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jieba</span><span class="o">,</span> <span class="nn">re</span>
<span class="n">temp</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">temp</span><span class="p">:</span>
    <span class="c1">#è¿‡æ»¤æ‰æ‰€æœ‰çš„æ ‡ç‚¹ç¬¦å·</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;[\s+\.\!\/_,$%^*(+</span><span class="se">\&quot;\&#39;</span><span class="s2">â€â€ã€Šã€‹]+|[+â€”â€”ï¼ï¼Œã€‚ï¼Ÿã€~@#ï¿¥%â€¦â€¦&amp;*ï¼ˆï¼‰ï¼š]+&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>7754
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;å…«ä¸‡äº”åƒä¸‰ä½“æ—¶ï¼ˆçº¦8.6ä¸ªåœ°çƒå¹´ï¼‰åã€‚\n\nå…ƒé¦–ä¸‹ä»¤å¬å¼€ä¸‰ä½“ä¸–ç•Œå…¨ä½“æ‰§æ”¿å®˜ç´§æ€¥ä¼šè®®ï¼Œè¿™å¾ˆä¸å¯»å¸¸ï¼Œä¸€å®šæœ‰ä»€ä¹ˆé‡å¤§çš„äº‹ä»¶å‘ç”Ÿã€‚\n\nä¸¤ä¸‡ä¸‰ä½“æ—¶å‰ï¼Œä¸‰ä½“èˆ°é˜Ÿå¯èˆªäº†ï¼Œå®ƒä»¬åªçŸ¥é“ç›®æ ‡çš„å¤§è‡´æ–¹å‘ï¼Œå´ä¸çŸ¥é“å®ƒçš„è·ç¦»ã€‚ä¹Ÿ&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="o">*</span><span class="n">words</span><span class="p">[:</span><span class="mi">50</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>å…«ä¸‡äº”åƒ ä¸‰ä½“ æ—¶ çº¦ 86 ä¸ª åœ°çƒ å¹´ å å…ƒé¦– ä¸‹ä»¤ å¬å¼€ ä¸‰ä½“ ä¸–ç•Œ å…¨ä½“ æ‰§æ”¿å®˜ ç´§æ€¥ä¼šè®® è¿™ å¾ˆ ä¸ å¯»å¸¸ ä¸€å®š æœ‰ ä»€ä¹ˆ é‡å¤§ çš„ äº‹ä»¶ å‘ç”Ÿ ä¸¤ä¸‡ ä¸‰ä½“ æ—¶å‰ ä¸‰ä½“ èˆ°é˜Ÿ å¯èˆª äº† å®ƒä»¬ åª çŸ¥é“ ç›®æ ‡ çš„ å¤§è‡´ æ–¹å‘ å´ ä¸ çŸ¥é“ å®ƒ çš„ è·ç¦» ä¹Ÿè®¸ ç›®æ ‡
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trigrams</span> <span class="o">=</span> <span class="p">[([</span><span class="n">words</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">words</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">words</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)]</span>
<span class="c1"># æ‰“å°å‡ºå‰ä¸‰ä¸ªå…ƒç´ çœ‹çœ‹</span>
<span class="nb">print</span><span class="p">(</span><span class="n">trigrams</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[([&#39;å…«ä¸‡äº”åƒ&#39;, &#39;ä¸‰ä½“&#39;], &#39;æ—¶&#39;), ([&#39;ä¸‰ä½“&#39;, &#39;æ—¶&#39;], &#39;çº¦&#39;), ([&#39;æ—¶&#39;, &#39;çº¦&#39;], &#39;86&#39;)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># å¾—åˆ°è¯æ±‡è¡¨</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">word_to_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:[</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span> 
<span class="n">idx_to_word</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span><span class="n">i</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span>
<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
     <span class="n">word_to_idx</span><span class="p">[</span><span class="n">w</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span><span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2000
</pre></div>
</div>
</div>
</div>
<p>æ„é€ NGramç¥ç»ç½‘ç»œæ¨¡å‹ (ä¸‰å±‚çš„ç½‘ç»œ)</p>
<ol class="arabic simple">
<li><p>è¾“å…¥å±‚ï¼šembeddingå±‚ï¼Œè¿™ä¸€å±‚çš„ä½œç”¨æ˜¯ï¼šå…ˆå°†è¾“å…¥å•è¯çš„ç¼–å·æ˜ å°„ä¸ºä¸€ä¸ªone hotç¼–ç çš„å‘é‡ï¼Œå½¢å¦‚ï¼š001000ï¼Œç»´åº¦ä¸ºå•è¯è¡¨å¤§å°ã€‚
ç„¶åï¼Œembeddingä¼šé€šè¿‡ä¸€ä¸ªçº¿æ€§çš„ç¥ç»ç½‘ç»œå±‚æ˜ å°„åˆ°è¿™ä¸ªè¯çš„å‘é‡è¡¨ç¤ºï¼Œè¾“å‡ºä¸ºembedding_dim</p></li>
<li><p>çº¿æ€§å±‚ï¼Œä»embedding_dimç»´åº¦åˆ°128ç»´åº¦ï¼Œç„¶åç»è¿‡éçº¿æ€§ReLUå‡½æ•°</p></li>
<li><p>çº¿æ€§å±‚ï¼šä»128ç»´åº¦åˆ°å•è¯è¡¨å¤§å°ç»´åº¦ï¼Œç„¶ålog softmaxå‡½æ•°ï¼Œç»™å‡ºé¢„æµ‹æ¯ä¸ªå•è¯çš„æ¦‚ç‡</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">NGram</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">context_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NGram</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>  <span class="c1">#åµŒå…¥å±‚</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">context_size</span> <span class="o">*</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span> <span class="c1">#çº¿æ€§å±‚</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span> <span class="c1">#çº¿æ€§å±‚</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="c1">#åµŒå…¥è¿ç®—ï¼ŒåµŒå…¥è¿ç®—åœ¨å†…éƒ¨åˆ†ä¸ºä¸¤æ­¥ï¼šå°†è¾“å…¥çš„å•è¯ç¼–ç æ˜ å°„ä¸ºone hotå‘é‡è¡¨ç¤ºï¼Œç„¶åç»è¿‡ä¸€ä¸ªçº¿æ€§å±‚å¾—åˆ°å•è¯çš„è¯å‘é‡</span>
        <span class="n">embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># çº¿æ€§å±‚åŠ ReLU</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">embeds</span><span class="p">))</span>
        
        <span class="c1"># çº¿æ€§å±‚åŠ Softmax</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_probs</span>
    <span class="k">def</span> <span class="nf">extract</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">embeds</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1">#çºªå½•æ¯ä¸€æ­¥çš„æŸå¤±å‡½æ•°</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span> <span class="c1">#è¿ç”¨è´Ÿå¯¹æ•°ä¼¼ç„¶å‡½æ•°ä½œä¸ºç›®æ ‡å‡½æ•°ï¼ˆå¸¸ç”¨äºå¤šåˆ†ç±»é—®é¢˜çš„ç›®æ ‡å‡½æ•°ï¼‰</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">NGram</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1">#å®šä¹‰NGramæ¨¡å‹ï¼Œå‘é‡åµŒå…¥ç»´æ•°ä¸º10ç»´ï¼ŒNï¼ˆçª—å£å¤§å°ï¼‰ä¸º2</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span> <span class="c1">#ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•ä½œä¸ºä¼˜åŒ–å™¨ </span>
<span class="c1">#å¾ªç¯100ä¸ªå‘¨æœŸ</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">context</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">trigrams</span><span class="p">:</span>
        <span class="c1"># å‡†å¤‡å¥½è¾“å…¥æ¨¡å‹çš„æ•°æ®ï¼Œå°†è¯æ±‡æ˜ å°„ä¸ºç¼–ç </span>
        <span class="n">context_idxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">word_to_idx</span><span class="p">[</span><span class="n">w</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">context</span><span class="p">]</span>
        <span class="c1"># åŒ…è£…æˆPyTorchçš„Variable</span>
        <span class="n">context_var</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">context_idxs</span><span class="p">))</span>
        <span class="c1"># æ¸…ç©ºæ¢¯åº¦ï¼šæ³¨æ„PyTorchä¼šåœ¨è°ƒç”¨backwardçš„æ—¶å€™è‡ªåŠ¨ç§¯ç´¯æ¢¯åº¦ä¿¡æ¯ï¼Œæ•…è€Œæ¯éš”å‘¨æœŸè¦æ¸…ç©ºæ¢¯åº¦ä¿¡æ¯ä¸€æ¬¡ã€‚</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1"># ç”¨ç¥ç»ç½‘ç»œåšè®¡ç®—ï¼Œè®¡ç®—å¾—åˆ°è¾“å‡ºçš„æ¯ä¸ªå•è¯çš„å¯èƒ½æ¦‚ç‡å¯¹æ•°å€¼</span>
        <span class="n">log_probs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">context_var</span><span class="p">)</span>
        <span class="c1"># è®¡ç®—æŸå¤±å‡½æ•°ï¼ŒåŒæ ·éœ€è¦æŠŠç›®æ ‡æ•°æ®è½¬åŒ–ä¸ºç¼–ç ï¼Œå¹¶åŒ…è£…ä¸ºVariable</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">word_to_idx</span><span class="p">[</span><span class="n">target</span><span class="p">][</span><span class="mi">0</span><span class="p">]])))</span>
        <span class="c1"># æ¢¯åº¦åä¼ </span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># å¯¹ç½‘ç»œè¿›è¡Œä¼˜åŒ–</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="c1"># ç´¯åŠ æŸå¤±å‡½æ•°å€¼</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span>
    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_loss</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;ç¬¬</span><span class="si">{}</span><span class="s1">è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š</span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">total_loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ç¬¬0è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š56704.61
ç¬¬1è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š53935.28
ç¬¬2è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š52241.16
ç¬¬3è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š51008.51
ç¬¬4è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š50113.76
ç¬¬5è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š49434.07
ç¬¬6è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š48879.33
ç¬¬7è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š48404.71
ç¬¬8è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š47983.95
ç¬¬9è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š47600.01
ç¬¬10è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š47240.32
ç¬¬11è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š46897.53
ç¬¬12è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š46566.24
ç¬¬13è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š46241.59
ç¬¬14è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š45920.18
ç¬¬15è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š45599.50
ç¬¬16è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š45277.74
ç¬¬17è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š44953.10
ç¬¬18è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š44624.41
ç¬¬19è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š44290.34
ç¬¬20è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š43950.63
ç¬¬21è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š43604.48
ç¬¬22è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š43251.90
ç¬¬23è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š42891.99
ç¬¬24è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š42524.64
ç¬¬25è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š42149.46
ç¬¬26è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š41766.14
ç¬¬27è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š41374.89
ç¬¬28è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š40975.62
ç¬¬29è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š40568.36
ç¬¬30è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š40153.31
ç¬¬31è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š39730.61
ç¬¬32è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š39300.70
ç¬¬33è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š38863.39
ç¬¬34è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š38419.11
ç¬¬35è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š37968.16
ç¬¬36è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š37510.99
ç¬¬37è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š37048.06
ç¬¬38è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š36579.82
ç¬¬39è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š36106.78
ç¬¬40è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š35629.46
ç¬¬41è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š35148.57
ç¬¬42è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š34665.39
ç¬¬43è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š34180.25
ç¬¬44è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š33693.93
ç¬¬45è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š33207.48
ç¬¬46è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š32721.72
ç¬¬47è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š32237.36
ç¬¬48è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š31755.00
ç¬¬49è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š31275.05
ç¬¬50è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š30798.38
ç¬¬51è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š30325.62
ç¬¬52è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š29857.59
ç¬¬53è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š29394.65
ç¬¬54è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š28937.08
ç¬¬55è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š28485.72
ç¬¬56è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š28041.07
ç¬¬57è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š27603.33
ç¬¬58è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š27173.14
ç¬¬59è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š26750.82
ç¬¬60è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š26336.92
ç¬¬61è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š25931.60
ç¬¬62è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š25534.87
ç¬¬63è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š25147.07
ç¬¬64è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š24768.02
ç¬¬65è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š24397.92
ç¬¬66è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š24036.68
ç¬¬67è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š23684.69
ç¬¬68è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š23341.30
ç¬¬69è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š23006.46
ç¬¬70è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š22680.18
ç¬¬71è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š22361.95
ç¬¬72è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š22051.86
ç¬¬73è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š21749.46
ç¬¬74è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š21454.48
ç¬¬75è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š21167.06
ç¬¬76è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š20886.72
ç¬¬77è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š20613.04
ç¬¬78è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š20346.13
ç¬¬79è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š20085.52
ç¬¬80è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š19831.27
ç¬¬81è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š19583.16
ç¬¬82è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š19341.03
ç¬¬83è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š19104.43
ç¬¬84è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š18873.11
ç¬¬85è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š18646.91
ç¬¬86è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š18425.87
ç¬¬87è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š18209.80
ç¬¬88è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š17998.34
ç¬¬89è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š17791.97
ç¬¬90è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š17589.94
ç¬¬91è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š17392.24
ç¬¬92è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š17199.04
ç¬¬93è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š17009.97
ç¬¬94è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š16824.82
ç¬¬95è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š16643.87
ç¬¬96è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š16466.76
ç¬¬97è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š16293.54
ç¬¬98è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š16123.99
ç¬¬99è½®ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š15957.75
</pre></div>
</div>
</div>
</div>
<p>12m 24s!!!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ä»è®­ç»ƒå¥½çš„æ¨¡å‹ä¸­æå–æ¯ä¸ªå•è¯çš„å‘é‡</span>
<span class="n">vec</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">word_to_idx</span><span class="o">.</span><span class="n">values</span><span class="p">()])))</span>
<span class="n">vec</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="c1"># åˆ©ç”¨PCAç®—æ³•è¿›è¡Œé™ç»´</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="n">X_reduced</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">vec</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ç»˜åˆ¶æ‰€æœ‰å•è¯å‘é‡çš„äºŒç»´ç©ºé—´æŠ•å½±</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_reduced</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="c1"># ç»˜åˆ¶å‡ ä¸ªç‰¹æ®Šå•è¯çš„å‘é‡</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;æ™ºå­&#39;</span><span class="p">,</span> <span class="s1">&#39;åœ°çƒ&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¸‰ä½“&#39;</span><span class="p">,</span> <span class="s1">&#39;è´¨å­&#39;</span><span class="p">,</span> <span class="s1">&#39;ç§‘å­¦&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¸–ç•Œ&#39;</span><span class="p">,</span> <span class="s1">&#39;æ–‡æ˜&#39;</span><span class="p">,</span> <span class="s1">&#39;å¤ªç©º&#39;</span><span class="p">,</span> <span class="s1">&#39;åŠ é€Ÿå™¨&#39;</span><span class="p">,</span> <span class="s1">&#39;å¹³é¢&#39;</span><span class="p">,</span> <span class="s1">&#39;å®‡å®™&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¿¡æ¯&#39;</span><span class="p">]</span>
<span class="c1"># è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œå¦åˆ™æ— æ³•åœ¨å›¾å½¢ä¸Šæ˜¾ç¤ºä¸­æ–‡</span>
<span class="n">zhfont1</span> <span class="o">=</span> <span class="n">matplotlib</span><span class="o">.</span><span class="n">font_manager</span><span class="o">.</span><span class="n">FontProperties</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s1">&#39;/Library/Fonts/åæ–‡ä»¿å®‹.ttf&#39;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">35</span><span class="p">)</span>
<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">word_to_idx</span><span class="p">:</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">word_to_idx</span><span class="p">[</span><span class="n">w</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">xy</span> <span class="o">=</span> <span class="n">X_reduced</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xy</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xy</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">xy</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xy</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">fontproperties</span> <span class="o">=</span> <span class="n">zhfont1</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;white&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c85e2f07de1f0a85af0cb1de4f1532ce6da9a6dfca7d17ba918f1887706d5bf5.png" src="_images/c85e2f07de1f0a85af0cb1de4f1532ce6da9a6dfca7d17ba918f1887706d5bf5.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># å®šä¹‰è®¡ç®—cosineç›¸ä¼¼åº¦çš„å‡½æ•°</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="k">def</span> <span class="nf">cos_similarity</span><span class="p">(</span><span class="n">vec1</span><span class="p">,</span> <span class="n">vec2</span><span class="p">):</span>
    <span class="n">norm1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vec1</span><span class="p">)</span>
    <span class="n">norm2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vec2</span><span class="p">)</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="n">norm1</span> <span class="o">*</span> <span class="n">norm2</span>
    <span class="n">dot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vec1</span><span class="p">,</span> <span class="n">vec2</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">dot</span> <span class="o">/</span> <span class="n">norm</span> <span class="k">if</span> <span class="n">norm</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">result</span>
    
<span class="c1"># åœ¨æ‰€æœ‰çš„è¯å‘é‡ä¸­å¯»æ‰¾åˆ°ä¸ç›®æ ‡è¯ï¼ˆwordï¼‰ç›¸è¿‘çš„å‘é‡ï¼Œå¹¶æŒ‰ç›¸ä¼¼åº¦è¿›è¡Œæ’åˆ—</span>
<span class="k">def</span> <span class="nf">find_most_similar</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">vectors</span><span class="p">,</span> <span class="n">word_idx</span><span class="p">):</span>
    <span class="n">vector</span> <span class="o">=</span> <span class="n">vectors</span><span class="p">[</span><span class="n">word_to_idx</span><span class="p">[</span><span class="n">word</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">simi</span> <span class="o">=</span> <span class="p">[[</span><span class="n">cos_similarity</span><span class="p">(</span><span class="n">vector</span><span class="p">,</span> <span class="n">vectors</span><span class="p">[</span><span class="n">num</span><span class="p">]),</span> <span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">num</span><span class="p">,</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_idx</span><span class="o">.</span><span class="n">keys</span><span class="p">())]</span>
    <span class="n">sort</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">simi</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sort</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">words</span>

<span class="c1"># ä¸æ™ºå­é è¿‘çš„è¯æ±‡</span>
<span class="n">find_most_similar</span><span class="p">(</span><span class="s1">&#39;æ™ºå­&#39;</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">word_to_idx</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;å±€éƒ¨&#39;, &#39;ä¸€åœº&#39;, &#39;æ¥&#39;, &#39;é”™è¯¯&#39;, &#39;ä¸€ç”Ÿ&#39;, &#39;æ­£ä¸­&#39;, &#39;èˆªè¡Œ&#39;, &#39;åœ°é¢&#39;, &#39;åªæ˜¯&#39;, &#39;æ”¿åºœ&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="gensim-word2vec">
<h2>Gensim Word2vec<a class="headerlink" href="#gensim-word2vec" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gensim</span> <span class="k">as</span> <span class="nn">gensim</span>
<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">Word2Vec</span>
<span class="kn">from</span> <span class="nn">gensim.models.keyedvectors</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>
<span class="kn">from</span> <span class="nn">gensim.models.word2vec</span> <span class="kn">import</span> <span class="n">LineSentence</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;./data/ä¸‰ä½“.txt&quot;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">lines</span> <span class="o">=</span> <span class="p">[]</span>

<span class="kn">import</span> <span class="nn">jieba</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">temp</span><span class="p">:</span>
        <span class="c1">#è¿‡æ»¤æ‰æ‰€æœ‰çš„æ ‡ç‚¹ç¬¦å·</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;[\s+\.\!\/_,$%^*(+</span><span class="se">\&quot;\&#39;</span><span class="s2">â€â€ã€Šã€‹]+|[+â€”â€”ï¼ï¼Œã€‚ï¼Ÿã€~@#ï¿¥%â€¦â€¦&amp;*ï¼ˆï¼‰ï¼šï¼›â€˜]+&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">lines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Building prefix dict from the default dictionary ...
Loading model from cache /var/folders/8b/hhnbt0nd4zsg2qhxc28q23w80000gn/T/jieba.cache
Loading model cost 0.685 seconds.
Prefix dict has been built successfully.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># è°ƒç”¨gensim Word2Vecçš„ç®—æ³•è¿›è¡Œè®­ç»ƒã€‚</span>
<span class="c1"># å‚æ•°åˆ†åˆ«ä¸ºï¼šsize: åµŒå…¥åçš„è¯å‘é‡ç»´åº¦ï¼›window: ä¸Šä¸‹æ–‡çš„å®½åº¦ï¼Œmin_countä¸ºè€ƒè™‘è®¡ç®—çš„å•è¯çš„æœ€ä½è¯é¢‘é˜ˆå€¼</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="n">vector_size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">window</span> <span class="o">=</span> <span class="mi">2</span> <span class="p">,</span> <span class="n">min_count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="s1">&#39;ä¸‰ä½“&#39;</span><span class="p">,</span> <span class="n">topn</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;åœ°çƒ&#39;, 0.9974961876869202),
 (&#39;å¤–æ˜Ÿ&#39;, 0.9959420561790466),
 (&#39;ä¸­&#39;, 0.9958519339561462),
 (&#39;çš„&#39;, 0.9958161115646362),
 (&#39;ä¿¡æ¯&#39;, 0.9955942034721375),
 (&#39;æ–‡æ˜&#39;, 0.9955913424491882),
 (&#39;æ—¶é—´&#39;, 0.9953882694244385),
 (&#39;å®‡å®™&#39;, 0.9951216578483582),
 (&#39;å‘å±•&#39;, 0.9950591325759888),
 (&#39;ä¸&#39;, 0.9950133562088013),
 (&#39;ä¸€ä¸ª&#39;, 0.9949650764465332),
 (&#39;å®ƒ&#39;, 0.9945959448814392),
 (&#39;å››ä¸ª&#39;, 0.9944809079170227),
 (&#39;ä¸–ç•Œ&#39;, 0.9944674968719482),
 (&#39;åŠ é€Ÿå™¨&#39;, 0.9942856431007385),
 (&#39;å¤ªé˜³&#39;, 0.9941897988319397),
 (&#39;é€šè¿‡&#39;, 0.9940699934959412),
 (&#39;æ”¾åˆ°&#39;, 0.9940448999404907),
 (&#39;å°†&#39;, 0.9940245151519775),
 (&#39;ç¤¾ä¼š&#39;, 0.9938994646072388),
 (&#39;å®éªŒ&#39;, 0.9938514232635498),
 (&#39;ç›®å‰&#39;, 0.993848979473114),
 (&#39;å…¶ä»–&#39;, 0.9938352704048157),
 (&#39;ç»“æ„&#39;, 0.9938239455223083),
 (&#39;å­˜åœ¨&#39;, 0.9937348961830139),
 (&#39;èˆ°é˜Ÿ&#39;, 0.9936554431915283),
 (&#39;è¿™ä¸ª&#39;, 0.9936324954032898),
 (&#39;å†å²&#39;, 0.993557333946228),
 (&#39;å†…&#39;, 0.9935263991355896),
 (&#39;ä½¿&#39;, 0.9934986233711243),
 (&#39;å·¨å¤§&#39;, 0.9934812188148499),
 (&#39;å‡ºç°&#39;, 0.9934180974960327),
 (&#39;æœ€è¿‘&#39;, 0.9934037327766418),
 (&#39;å¤§æ®¿&#39;, 0.9933778047561646),
 (&#39;æ¯ç­&#39;, 0.993355929851532),
 (&#39;ç­‰&#39;, 0.9933347105979919),
 (&#39;åœ¨&#39;, 0.9933309555053711),
 (&#39;è¿™æ ·&#39;, 0.9933069944381714),
 (&#39;è€Œ&#39;, 0.9932495355606079),
 (&#39;æ¨å†¬&#39;, 0.9932450652122498),
 (&#39;å‘¨å›´&#39;, 0.9932316541671753),
 (&#39;é‚£ä¸ª&#39;, 0.9932215213775635),
 (&#39;äº§ç”Ÿ&#39;, 0.9931648373603821),
 (&#39;ä¸º&#39;, 0.9931637644767761),
 (&#39;æ‰€æœ‰&#39;, 0.9931597113609314),
 (&#39;æ²™ç‘å±±&#39;, 0.9931430220603943),
 (&#39;ä¸åŒ&#39;, 0.9931164383888245),
 (&#39;ä½ ä»¬&#39;, 0.9930866360664368),
 (&#39;äººä»¬&#39;, 0.993083119392395),
 (&#39;ä¸Š&#39;, 0.993078351020813),
 (&#39;äººç±»&#39;, 0.9930549263954163),
 (&#39;äºº&#39;, 0.9930544495582581),
 (&#39;æ—¶&#39;, 0.9930477142333984),
 (&#39;é‚£äº›&#39;, 0.9930435419082642),
 (&#39;ä¸€äº›&#39;, 0.9930272698402405),
 (&#39;è¯¥&#39;, 0.9929757714271545),
 (&#39;é¢‘ç‡&#39;, 0.9928855895996094),
 (&#39;æŠ€æœ¯&#39;, 0.9928467273712158),
 (&#39;ç¾å¥½&#39;, 0.9928457736968994),
 (&#39;ä¸»è¦&#39;, 0.9928236603736877),
 (&#39;ç–¯ç‹‚&#39;, 0.9928078055381775),
 (&#39;åŠªåŠ›&#39;, 0.9927535653114319),
 (&#39;è¿›è¡Œ&#39;, 0.9927522540092468),
 (&#39;éœ€è¦&#39;, 0.992743730545044),
 (&#39;è¢«&#39;, 0.9927397966384888),
 (&#39;å‘ç”Ÿ&#39;, 0.992729127407074),
 (&#39;æ¥è§¦&#39;, 0.9927168488502502),
 (&#39;å¤æ‚&#39;, 0.99271559715271),
 (&#39;ç ”ç©¶&#39;, 0.9927100539207458),
 (&#39;å’Œ&#39;, 0.9926401376724243),
 (&#39;äº&#39;, 0.992630660533905),
 (&#39;å‘å‡º&#39;, 0.9926106333732605),
 (&#39;ä¸‰&#39;, 0.9926024675369263),
 (&#39;è¿åŠ¨&#39;, 0.9925642013549805),
 (&#39;åªèƒ½&#39;, 0.9925564527511597),
 (&#39;ä¸€ç‰‡&#39;, 0.9925556182861328),
 (&#39;å·²ç»&#39;, 0.9925482273101807),
 (&#39;è‡ªå·±&#39;, 0.992435872554779),
 (&#39;è®¡ç®—&#39;, 0.9924312829971313),
 (&#39;é‚£æ ·&#39;, 0.9924249649047852),
 (&#39;è¿™äº›&#39;, 0.9924024343490601),
 (&#39;ç¬¬ä¸€æ¬¡&#39;, 0.9923712611198425),
 (&#39;ä¸€å¼ &#39;, 0.9923089742660522),
 (&#39;åŸºåœ°&#39;, 0.9922966361045837),
 (&#39;è¾å°„&#39;, 0.9922692775726318),
 (&#39;æ··ä¹±&#39;, 0.9922570586204529),
 (&#39;ä¸€å&#39;, 0.9922410249710083),
 (&#39;å…¶&#39;, 0.9922134280204773),
 (&#39;æ¯”&#39;, 0.9921837449073792),
 (&#39;ä¸ºäº†&#39;, 0.992165744304657),
 (&#39;è®¡ç®—æœº&#39;, 0.9921648502349854),
 (&#39;ä¸ª&#39;, 0.99213045835495),
 (&#39;å¤©çº¿&#39;, 0.9921154975891113),
 (&#39;ä¹‹é—´&#39;, 0.9921114444732666),
 (&#39;ä¸¤æ¬¡&#39;, 0.9920859336853027),
 (&#39;å»ºé€ &#39;, 0.9920815825462341),
 (&#39;æ¨æ¯&#39;, 0.9920707941055298),
 (&#39;åé¢&#39;, 0.9920520186424255),
 (&#39;æ¥æ”¶&#39;, 0.9920087456703186),
 (&#39;å¦‚ä½•&#39;, 0.9919811487197876)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># å°†è¯å‘é‡æŠ•å½±åˆ°äºŒç»´ç©ºé—´</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="n">rawWordVec</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">word2ind</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">key_to_index</span><span class="p">):</span>
    <span class="n">rawWordVec</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="n">w</span><span class="p">])</span>
    <span class="n">word2ind</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
<span class="n">rawWordVec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rawWordVec</span><span class="p">)</span>
<span class="n">X_reduced</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">rawWordVec</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ç»˜åˆ¶æ˜Ÿç©ºå›¾</span>
<span class="c1"># ç»˜åˆ¶æ‰€æœ‰å•è¯å‘é‡çš„äºŒç»´ç©ºé—´æŠ•å½±</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.sans-serif&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;SimHei&#39;</span><span class="p">]</span>  <span class="c1"># ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.unicode_minus&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_reduced</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="c1"># ç»˜åˆ¶å‡ ä¸ªç‰¹æ®Šå•è¯çš„å‘é‡</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;æ™ºå­&#39;</span><span class="p">,</span> <span class="s1">&#39;åœ°çƒ&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¸‰ä½“&#39;</span><span class="p">,</span> <span class="s1">&#39;è´¨å­&#39;</span><span class="p">,</span> <span class="s1">&#39;ç§‘å­¦&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¸–ç•Œ&#39;</span><span class="p">,</span> <span class="s1">&#39;æ–‡æ˜&#39;</span><span class="p">,</span> <span class="s1">&#39;å¤ªç©º&#39;</span><span class="p">,</span> <span class="s1">&#39;åŠ é€Ÿå™¨&#39;</span><span class="p">,</span> <span class="s1">&#39;å¹³é¢&#39;</span><span class="p">,</span> <span class="s1">&#39;å®‡å®™&#39;</span><span class="p">,</span> <span class="s1">&#39;è¿›å±•&#39;</span><span class="p">,</span><span class="s1">&#39;çš„&#39;</span><span class="p">]</span>
<span class="c1"># è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œå¦åˆ™æ— æ³•åœ¨å›¾å½¢ä¸Šæ˜¾ç¤ºä¸­æ–‡</span>
<span class="c1">#zhfont1 = matplotlib.font_manager.FontProperties(fname=&#39;/Library/Fonts/åæ–‡ä»¿å®‹.ttf&#39;, size=26)</span>
<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">word2ind</span><span class="p">:</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">word2ind</span><span class="p">[</span><span class="n">w</span><span class="p">]</span>
        <span class="n">xy</span> <span class="o">=</span> <span class="n">X_reduced</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xy</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xy</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span>
        <span class="c1">#plt.text(xy[0], xy[1], w, fontproperties = zhfont1, alpha = 1, color = &#39;yellow&#39;)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">xy</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xy</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;yellow&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">16</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/09f2a763d0528fdb6658e6f88786200e0b349e4978f05162fb322de60b33a871.png" src="_images/09f2a763d0528fdb6658e6f88786200e0b349e4978f05162fb322de60b33a871.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ç»˜åˆ¶æ˜Ÿç©ºå›¾</span>
<span class="c1"># ç»˜åˆ¶æ‰€æœ‰å•è¯å‘é‡çš„äºŒç»´ç©ºé—´æŠ•å½±</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_reduced</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">markersize</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="c1"># ç»˜åˆ¶å‡ ä¸ªç‰¹æ®Šå•è¯çš„å‘é‡</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;æ™ºå­&#39;</span><span class="p">,</span> <span class="s1">&#39;åœ°çƒ&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¸‰ä½“&#39;</span><span class="p">,</span> <span class="s1">&#39;è´¨å­&#39;</span><span class="p">,</span> <span class="s1">&#39;ç§‘å­¦&#39;</span><span class="p">,</span> <span class="s1">&#39;ä¸–ç•Œ&#39;</span><span class="p">,</span> <span class="s1">&#39;æ–‡æ˜&#39;</span><span class="p">,</span> <span class="s1">&#39;å¤ªç©º&#39;</span><span class="p">,</span> <span class="s1">&#39;åŠ é€Ÿå™¨&#39;</span><span class="p">,</span> <span class="s1">&#39;å¹³é¢&#39;</span><span class="p">,</span> <span class="s1">&#39;å®‡å®™&#39;</span><span class="p">,</span> <span class="s1">&#39;è¿›å±•&#39;</span><span class="p">,</span><span class="s1">&#39;çš„&#39;</span><span class="p">]</span>
<span class="c1"># è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œå¦åˆ™æ— æ³•åœ¨å›¾å½¢ä¸Šæ˜¾ç¤ºä¸­æ–‡</span>
<span class="n">zhfont1</span> <span class="o">=</span> <span class="n">matplotlib</span><span class="o">.</span><span class="n">font_manager</span><span class="o">.</span><span class="n">FontProperties</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s1">&#39;/Library/Fonts/åæ–‡ä»¿å®‹.ttf&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">26</span><span class="p">)</span>
<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">word2ind</span><span class="p">:</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">word2ind</span><span class="p">[</span><span class="n">w</span><span class="p">]</span>
        <span class="n">xy</span> <span class="o">=</span> <span class="n">X_reduced</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xy</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xy</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">xy</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xy</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">fontproperties</span> <span class="o">=</span> <span class="n">zhfont1</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;yellow&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a89c6e9fcb0a356e3403493890b959bd477b366ac7e7d7b23d0b4dcd6239f89b.png" src="_images/a89c6e9fcb0a356e3403493890b959bd477b366ac7e7d7b23d0b4dcd6239f89b.png" />
</div>
</div>
<p><img alt="" src="_images/end.png" /></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="10-text-mining-gov-report.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">ç¬¬å…«ç«  æ–‡æœ¬æŒ–æ˜</p>
      </div>
    </a>
    <a class="right-next"
       href="10-doc2vec.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Doc2Vec</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-geometry-of-culture">The Geometry of Culture</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#histwords">HistWords</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-embeddings-quantify-100-years-of-gender-and-ethnic-stereotypes">Word embeddings quantify 100 years of gender and ethnic stereotypes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-illustrated-word2vec">The Illustrated Word2vec</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#personality-embeddings">Personality Embeddings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cosine-similarity">Cosine Similarity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#word-embeddings">Word Embeddings</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#google-news-word2vec">Google News Word2Vec</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-neural-language-model">The neural language model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#language-model-training">Language Model Training</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#skip-gram">Skip-gram</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#negative-sampling">Negative Sampling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#word2vec-training-process">Word2vec Training Process</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-word2vec">Pytorch word2vec</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ngram">NGramè¯å‘é‡æ¨¡å‹</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gensim-word2vec">Gensim Word2vec</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Cheng-Jun Wang
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      Â© Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>