
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>使用Turicreate建立主题模型 &#8212; 《计算传播基础》</title>
    
  <link rel="stylesheet" href="_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/sphinx-book-theme.2d2078699c18a0efb88233928e1cf6ed.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.be0a4a0c39cd630af62a2fcf693f3f06.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="第九章 推荐系统简介" href="13-recsys-intro.html" />
    <link rel="prev" title="主题模型简介" href="12-topic-models-update.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/Socratessee.gif" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">《计算传播基础》</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   寻找人类传播行为的基因
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="01-intro2cjc.html">
   第一章 计算传播学简介
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03-python-intro.html">
   第二章 数据科学的编程工具
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04-crawler-beautifulsoup.html">
   第三章 数据抓取
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06-data-cleaning-intro.html">
   第四章 数据清洗
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08-01-statistics-thinking.html">
   第五章 统计思维
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09-01-machine-learning-with-sklearn.html">
   第六章 社会科学家的机器学习
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09-11-neural-network-intro.html">
   第七章 神经网络与深度学习
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="reference internal" href="10-text-minning-gov-report.html">
   第八章 文本挖掘
  </a>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="10-word2vec.html">
     词向量模型简介
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11-1-sentiment-analysis-with-dict.html">
     基于字典的情感分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11-2-emotion-dict.html">
     大连理工大学中文情感词汇
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11-3-NRC-Chinese-dict.html">
     基于NRC字典的情感分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11-3-textblob.html">
     利用textblob进行情感分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11-4-sentiment-classifier.html">
     基于机器学习的情感分析
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12-topic-models-update.html">
     主题模型简介
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     使用Turicreate建立主题模型
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="13-recsys-intro.html">
   第九章 推荐系统简介
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="15-network-science-intro.html">
   第十章 网络科学简介
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="19-visualization-with-seaborn.html">
   第十一章 可视化
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/12-topic-models-with-turicreate.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/chengjun/mybook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/chengjun/mybook/issues/new?title=Issue%20on%20page%20%2F12-topic-models-with-turicreate.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/chengjun/mybook/main?urlpath=tree/12-topic-models-with-turicreate.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/chengjun/mybook/blob/main/12-topic-models-with-turicreate.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transformations">
   Transformations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-cleaning">
   Text Cleaning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#topic-modeling">
   Topic modeling
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#initializing-from-other-models">
     Initializing from other models
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#seeding-the-model-with-prior-knowledge">
     Seeding the model with prior knowledge
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   阅读材料
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="turicreate">
<h1>使用Turicreate建立主题模型<a class="headerlink" href="#turicreate" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">turicreate</span> <span class="k">as</span> <span class="nn">tc</span>
</pre></div>
</div>
</div>
</div>
<p>Download Data: <del>http://select.cs.cmu.edu/code/graphlab/datasets/wikipedia/wikipedia_raw/w15</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sf</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">SFrame</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;/Users/datalab/bigdata/cjc/w15&quot;</span><span class="p">,</span> 
                              <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre>Finished parsing file /Users/datalab/bigdata/cjc/w15</pre></div><div class="output text_html"><pre>Parsing completed. Parsed 100 lines in 0.447868 secs.</pre></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>------------------------------------------------------
Inferred types from first 100 line(s) of file as 
column_type_hints=[str]
If parsing fails due to incorrect types, you can correct
the inferred type list above and pass it to read_csv in
the column_type_hints argument
------------------------------------------------------
</pre></div>
</div>
<div class="output text_html"><pre>Read 12278 lines. Lines per second: 16914.5</pre></div><div class="output text_html"><pre>Finished parsing file /Users/datalab/bigdata/cjc/w15</pre></div><div class="output text_html"><pre>Parsing completed. Parsed 72269 lines in 1.73223 secs.</pre></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div style="max-height:1000px;max-width:1500px;overflow:auto;"><table frame="box" rules="cols">
    <tr>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">X1</th>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">aynrand born and educated<br>in russia rand migrated ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">asphalt in american<br>english asphalt or ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">actinopterygii the<br>actinopterygii consti ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">altaiclanguages these<br>language families share ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">argon the name argon is<br>derived from the greek ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">augustderleth a 1938<br>guggenheim fellow der ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">amateur amateurism can be<br>seen in both a negative ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">assemblyline an assembly<br>line is a manufacturing ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">astronomicalunit an<br>astronomical unit ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">abbess an abbess latin<br>abbatissa feminine form ...</td>
    </tr>
</table>
[72269 rows x 1 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.
</div></div></div>
</div>
<div class="section" id="transformations">
<h2>Transformations<a class="headerlink" href="#transformations" title="Permalink to this headline">¶</a></h2>
<p>https://dato.com/learn/userguide/text/analysis.html</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">dir</span><span class="p">(</span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;X1&#39;</span><span class="p">])</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;_SArray__check_min_observations&#39;,
 &#39;__abs__&#39;,
 &#39;__add__&#39;,
 &#39;__and__&#39;,
 &#39;__bool__&#39;,
 &#39;__class__&#39;,
 &#39;__contains__&#39;,
 &#39;__copy__&#39;,
 &#39;__deepcopy__&#39;,
 &#39;__delattr__&#39;,
 &#39;__dir__&#39;,
 &#39;__div__&#39;,
 &#39;__doc__&#39;,
 &#39;__eq__&#39;,
 &#39;__floordiv__&#39;,
 &#39;__format__&#39;,
 &#39;__ge__&#39;,
 &#39;__get_content_identifier__&#39;,
 &#39;__getattribute__&#39;,
 &#39;__getitem__&#39;,
 &#39;__gt__&#39;,
 &#39;__has_size__&#39;,
 &#39;__hash__&#39;,
 &#39;__init__&#39;,
 &#39;__is_materialized__&#39;,
 &#39;__iter__&#39;,
 &#39;__le__&#39;,
 &#39;__len__&#39;,
 &#39;__lt__&#39;,
 &#39;__materialize__&#39;,
 &#39;__mod__&#39;,
 &#39;__module__&#39;,
 &#39;__mul__&#39;,
 &#39;__ne__&#39;,
 &#39;__neg__&#39;,
 &#39;__new__&#39;,
 &#39;__nonzero__&#39;,
 &#39;__or__&#39;,
 &#39;__pos__&#39;,
 &#39;__pow__&#39;,
 &#39;__proxy__&#39;,
 &#39;__radd__&#39;,
 &#39;__rdiv__&#39;,
 &#39;__reduce__&#39;,
 &#39;__reduce_ex__&#39;,
 &#39;__repr__&#39;,
 &#39;__rfloordiv__&#39;,
 &#39;__rmod__&#39;,
 &#39;__rmul__&#39;,
 &#39;__rpow__&#39;,
 &#39;__rsub__&#39;,
 &#39;__rtruediv__&#39;,
 &#39;__setattr__&#39;,
 &#39;__sizeof__&#39;,
 &#39;__slots__&#39;,
 &#39;__str__&#39;,
 &#39;__sub__&#39;,
 &#39;__subclasshook__&#39;,
 &#39;__truediv__&#39;,
 &#39;_count_ngrams&#39;,
 &#39;_count_words&#39;,
 &#39;_getitem_cache&#39;,
 &#39;_save_as_text&#39;,
 &#39;all&#39;,
 &#39;any&#39;,
 &#39;append&#39;,
 &#39;apply&#39;,
 &#39;argmax&#39;,
 &#39;argmin&#39;,
 &#39;astype&#39;,
 &#39;clip&#39;,
 &#39;clip_lower&#39;,
 &#39;clip_upper&#39;,
 &#39;contains&#39;,
 &#39;countna&#39;,
 &#39;cumulative_max&#39;,
 &#39;cumulative_mean&#39;,
 &#39;cumulative_min&#39;,
 &#39;cumulative_std&#39;,
 &#39;cumulative_sum&#39;,
 &#39;cumulative_var&#39;,
 &#39;date_range&#39;,
 &#39;datetime_to_str&#39;,
 &#39;dict_has_all_keys&#39;,
 &#39;dict_has_any_keys&#39;,
 &#39;dict_keys&#39;,
 &#39;dict_trim_by_keys&#39;,
 &#39;dict_trim_by_values&#39;,
 &#39;dict_values&#39;,
 &#39;dropna&#39;,
 &#39;dtype&#39;,
 &#39;element_slice&#39;,
 &#39;explore&#39;,
 &#39;fillna&#39;,
 &#39;filter&#39;,
 &#39;filter_by&#39;,
 &#39;from_const&#39;,
 &#39;from_sequence&#39;,
 &#39;hash&#39;,
 &#39;head&#39;,
 &#39;is_in&#39;,
 &#39;is_materialized&#39;,
 &#39;is_topk&#39;,
 &#39;item_length&#39;,
 &#39;materialize&#39;,
 &#39;max&#39;,
 &#39;mean&#39;,
 &#39;min&#39;,
 &#39;nnz&#39;,
 &#39;pixel_array_to_image&#39;,
 &#39;plot&#39;,
 &#39;random_integers&#39;,
 &#39;random_split&#39;,
 &#39;read_json&#39;,
 &#39;rolling_count&#39;,
 &#39;rolling_max&#39;,
 &#39;rolling_mean&#39;,
 &#39;rolling_min&#39;,
 &#39;rolling_stdv&#39;,
 &#39;rolling_sum&#39;,
 &#39;rolling_var&#39;,
 &#39;sample&#39;,
 &#39;save&#39;,
 &#39;shape&#39;,
 &#39;show&#39;,
 &#39;sort&#39;,
 &#39;split_datetime&#39;,
 &#39;stack&#39;,
 &#39;std&#39;,
 &#39;str_to_datetime&#39;,
 &#39;sum&#39;,
 &#39;summary&#39;,
 &#39;tail&#39;,
 &#39;to_numpy&#39;,
 &#39;unique&#39;,
 &#39;unpack&#39;,
 &#39;value_counts&#39;,
 &#39;var&#39;,
 &#39;vector_slice&#39;,
 &#39;where&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bow</span> <span class="o">=</span> <span class="n">sf</span><span class="p">[</span><span class="s1">&#39;X1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">_count_words</span><span class="p">()</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;X1&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>turicreate.data_structures.sarray.SArray
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">bow</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>turicreate.data_structures.sarray.SArray
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bow</span><span class="o">.</span><span class="n">dict_has_any_keys</span><span class="p">([</span><span class="s1">&#39;limited&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dtype: int
Rows: 72269
[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ... ]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bow</span><span class="o">.</span><span class="n">dict_values</span><span class="p">()[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">20</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div style="max-height:1000px;max-width:1500px;overflow:auto;"><table frame="box" rules="cols">
    <tr>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">X1</th>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">aynrand born and educated<br>in russia rand migrated ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">asphalt in american<br>english asphalt or ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">actinopterygii the<br>actinopterygii consti ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">altaiclanguages these<br>language families share ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">argon the name argon is<br>derived from the greek ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">augustderleth a 1938<br>guggenheim fellow der ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">amateur amateurism can be<br>seen in both a negative ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">assemblyline an assembly<br>line is a manufacturing ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">astronomicalunit an<br>astronomical unit ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">abbess an abbess latin<br>abbatissa feminine form ...</td>
    </tr>
</table>
[72269 rows x 1 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;bow&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bow</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div style="max-height:1000px;max-width:1500px;overflow:auto;"><table frame="box" rules="cols">
    <tr>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">X1</th>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">bow</th>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">aynrand born and educated<br>in russia rand migrated ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;spoke&#x27;: 1, &#x27;5000&#x27;: 1,<br>&#x27;follows&#x27;: 1, &#x27;given&#x27; ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">asphalt in american<br>english asphalt or ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;lain&#x27;: 1, &#x27;commonly&#x27;:<br>4, &#x27;has&#x27;: 6, &#x27;percent&#x27;: ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">actinopterygii the<br>actinopterygii consti ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;what&#x27;: 1, &#x27;follows&#x27;: 1,<br>&#x27;given&#x27;: 1, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">altaiclanguages these<br>language families share ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;follows&#x27;: 2, &#x27;has&#x27;: 11,<br>&#x27;general&#x27;: 1, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">argon the name argon is<br>derived from the greek ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;commonly&#x27;: 1,<br>&#x27;lattice&#x27;: 1, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">augustderleth a 1938<br>guggenheim fellow der ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;rescue&#x27;: 2, &#x27;amoral&#x27;:<br>1, &#x27;lovecraft&#x27;: 11, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">amateur amateurism can be<br>seen in both a negative ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;receiving&#x27;: 1,<br>&#x27;having&#x27;: 1, &#x27;hand&#x27;: 1, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">assemblyline an assembly<br>line is a manufacturing ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;consider&#x27;: 1, &#x27;world&#x27;:<br>1, &#x27;bring&#x27;: 2, &#x27;pins&#x27; ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">astronomicalunit an<br>astronomical unit ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;given&#x27;: 1, &#x27;ephemeris&#x27;:<br>2, &#x27;world&#x27;: 2, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">abbess an abbess latin<br>abbatissa feminine form ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;major&#x27;: 1, &#x27;abbess&#x27;:<br>10, &#x27;given&#x27;: 1, ...</td>
    </tr>
</table>
[72269 rows x 2 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;bow&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>turicreate.data_structures.sarray.SArray
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;bow&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>72269
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;bow&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">())[:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;spoke&#39;, 1), (&#39;5000&#39;, 1), (&#39;follows&#39;, 1)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;tfidf&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">text_analytics</span><span class="o">.</span><span class="n">tf_idf</span><span class="p">(</span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;X1&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div style="max-height:1000px;max-width:1500px;overflow:auto;"><table frame="box" rules="cols">
    <tr>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">X1</th>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">bow</th>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">tfidf</th>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">aynrand born and educated<br>in russia rand migrated ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;spoke&#x27;: 1, &#x27;5000&#x27;: 1,<br>&#x27;follows&#x27;: 1, &#x27;given&#x27; ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;spoke&#x27;:<br>4.830308280673057, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">asphalt in american<br>english asphalt or ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;lain&#x27;: 1, &#x27;commonly&#x27;:<br>4, &#x27;has&#x27;: 6, &#x27;percent&#x27;: ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;lain&#x27;:<br>8.480100346078947, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">actinopterygii the<br>actinopterygii consti ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;what&#x27;: 1, &#x27;follows&#x27;: 1,<br>&#x27;given&#x27;: 1, ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;what&#x27;:<br>2.505781957805935, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">altaiclanguages these<br>language families share ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;follows&#x27;: 2, &#x27;has&#x27;: 11,<br>&#x27;general&#x27;: 1, ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;follows&#x27;:<br>7.5113334785280745, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">argon the name argon is<br>derived from the greek ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;commonly&#x27;: 1,<br>&#x27;lattice&#x27;: 1, ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;commonly&#x27;:<br>3.7717720679882287, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">augustderleth a 1938<br>guggenheim fellow der ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;rescue&#x27;: 2, &#x27;amoral&#x27;:<br>1, &#x27;lovecraft&#x27;: 11, ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;rescue&#x27;:<br>9.19021202607744, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">amateur amateurism can be<br>seen in both a negative ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;receiving&#x27;: 1,<br>&#x27;having&#x27;: 1, &#x27;hand&#x27;: 1, ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;receiving&#x27;:<br>4.162612232542636, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">assemblyline an assembly<br>line is a manufacturing ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;consider&#x27;: 1, &#x27;world&#x27;:<br>1, &#x27;bring&#x27;: 2, &#x27;pins&#x27; ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;consider&#x27;:<br>4.336965619687414, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">astronomicalunit an<br>astronomical unit ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;given&#x27;: 1, &#x27;ephemeris&#x27;:<br>2, &#x27;world&#x27;: 2, ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;given&#x27;:<br>2.5682202783138064, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">abbess an abbess latin<br>abbatissa feminine form ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;major&#x27;: 1, &#x27;abbess&#x27;:<br>10, &#x27;given&#x27;: 1, ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;major&#x27;:<br>2.356876809458607, ...</td>
    </tr>
</table>
[72269 rows x 3 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;tfidf&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">())[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;spoke&#39;, 4.830308280673057),
 (&#39;5000&#39;, 4.791220891965009),
 (&#39;follows&#39;, 3.7556667392640373),
 (&#39;given&#39;, 2.5682202783138064),
 (&#39;percent&#39;, 17.481279902908025)]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="text-cleaning">
<h2>Text Cleaning<a class="headerlink" href="#text-cleaning" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">docs</span> <span class="o">=</span> <span class="n">sf</span><span class="p">[</span><span class="s1">&#39;bow&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dict_trim_by_values</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">docs</span> <span class="o">=</span> <span class="n">docs</span><span class="o">.</span><span class="n">dict_trim_by_keys</span><span class="p">(</span>
    <span class="n">tc</span><span class="o">.</span><span class="n">text_analytics</span><span class="o">.</span><span class="n">stop_words</span><span class="p">(),</span>
    <span class="n">exclude</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="topic-modeling">
<h2>Topic modeling<a class="headerlink" href="#topic-modeling" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">tc</span><span class="o">.</span><span class="n">topic_model</span><span class="o">.</span><span class="n">create</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Help on function create in module turicreate.toolkits.topic_model.topic_model:

create(dataset, num_topics=10, initial_topics=None, alpha=None, beta=0.1, num_iterations=10, num_burnin=5, associations=None, verbose=False, print_interval=10, validation_set=None, method=&#39;auto&#39;)
    Create a topic model from the given data set. A topic model assumes each
    document is a mixture of a set of topics, where for each topic some words
    are more likely than others. One statistical approach to do this is called a
    &quot;topic model&quot;. This method learns a topic model for the given document
    collection.
    
    Parameters
    ----------
    dataset : SArray of type dict or SFrame with a single column of type dict
        A bag of words representation of a document corpus.
        Each element is a dictionary representing a single document, where
        the keys are words and the values are the number of times that word
        occurs in that document.
    
    num_topics : int, optional
        The number of topics to learn.
    
    initial_topics : SFrame, optional
        An SFrame with a column of unique words representing the vocabulary
        and a column of dense vectors representing
        probability of that word given each topic. When provided,
        these values are used to initialize the algorithm.
    
    alpha : float, optional
        Hyperparameter that controls the diversity of topics in a document.
        Smaller values encourage fewer topics per document.
        Provided value must be positive. Default value is 50/num_topics.
    
    beta : float, optional
        Hyperparameter that controls the diversity of words in a topic.
        Smaller values encourage fewer words per topic. Provided value
        must be positive.
    
    num_iterations : int, optional
        The number of iterations to perform.
    
    num_burnin : int, optional
        The number of iterations to perform when inferring the topics for
        documents at prediction time.
    
    verbose : bool, optional
        When True, print most probable words for each topic while printing
        progress.
    
    print_interval : int, optional
        The number of iterations to wait between progress reports.
    
    associations : SFrame, optional
        An SFrame with two columns named &quot;word&quot; and &quot;topic&quot; containing words
        and the topic id that the word should be associated with. These words
        are not considered during learning.
    
    validation_set : SArray of type dict or SFrame with a single column
        A bag of words representation of a document corpus, similar to the
        format required for `dataset`. This will be used to monitor model
        performance during training. Each document in the provided validation
        set is randomly split: the first portion is used estimate which topic
        each document belongs to, and the second portion is used to estimate
        the model&#39;s performance at predicting the unseen words in the test data.
    
    method : {&#39;cgs&#39;, &#39;alias&#39;}, optional
        The algorithm used for learning the model.
    
        - *cgs:* Collapsed Gibbs sampling
        - *alias:* AliasLDA method.
    
    Returns
    -------
    out : TopicModel
        A fitted topic model. This can be used with
        :py:func:`~TopicModel.get_topics()` and
        :py:func:`~TopicModel.predict()`. While fitting is in progress, several
        metrics are shown, including:
    
        +------------------+---------------------------------------------------+
        |      Field       | Description                                       |
        +==================+===================================================+
        | Elapsed Time     | The number of elapsed seconds.                    |
        +------------------+---------------------------------------------------+
        | Tokens/second    | The number of unique words processed per second   |
        +------------------+---------------------------------------------------+
        | Est. Perplexity  | An estimate of the model&#39;s ability to model the   |
        |                  | training data. See the documentation on evaluate. |
        +------------------+---------------------------------------------------+
    
    See Also
    --------
    TopicModel, TopicModel.get_topics, TopicModel.predict,
    turicreate.SArray.dict_trim_by_keys, TopicModel.evaluate
    
    References
    ----------
    - `Wikipedia - Latent Dirichlet allocation
      &lt;http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation&gt;`_
    
    - Alias method: Li, A. et al. (2014) `Reducing the Sampling Complexity of
      Topic Models. &lt;http://www.sravi.org/pubs/fastlda-kdd2014.pdf&gt;`_.
      KDD 2014.
    
    Examples
    --------
    The following example includes an SArray of documents, where
    each element represents a document in &quot;bag of words&quot; representation
    -- a dictionary with word keys and whose values are the number of times
    that word occurred in the document:
    
    &gt;&gt;&gt; docs = turicreate.SArray(&#39;https://static.turi.com/datasets/nytimes&#39;)
    
    Once in this form, it is straightforward to learn a topic model.
    
    &gt;&gt;&gt; m = turicreate.topic_model.create(docs)
    
    It is also easy to create a new topic model from an old one  -- whether
    it was created using Turi Create or another package.
    
    &gt;&gt;&gt; m2 = turicreate.topic_model.create(docs, initial_topics=m[&#39;topics&#39;])
    
    To manually fix several words to always be assigned to a topic, use
    the `associations` argument. The following will ensure that topic 0
    has the most probability for each of the provided words:
    
    &gt;&gt;&gt; from turicreate import SFrame
    &gt;&gt;&gt; associations = SFrame({&#39;word&#39;:[&#39;hurricane&#39;, &#39;wind&#39;, &#39;storm&#39;],
                               &#39;topic&#39;: [0, 0, 0]})
    &gt;&gt;&gt; m = turicreate.topic_model.create(docs,
                                        associations=associations)
    
    More advanced usage allows you  to control aspects of the model and the
    learning method.
    
    &gt;&gt;&gt; import turicreate as tc
    &gt;&gt;&gt; m = tc.topic_model.create(docs,
                                  num_topics=20,       # number of topics
                                  num_iterations=10,   # algorithm parameters
                                  alpha=.01, beta=.1)  # hyperparameters
    
    To evaluate the model&#39;s ability to generalize, we can create a train/test
    split where a portion of the words in each document are held out from
    training.
    
    &gt;&gt;&gt; train, test = tc.text_analytics.random_split(.8)
    &gt;&gt;&gt; m = tc.topic_model.create(train)
    &gt;&gt;&gt; results = m.evaluate(test)
    &gt;&gt;&gt; print results[&#39;perplexity&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">tc</span><span class="o">.</span><span class="n">text_analytics</span><span class="o">.</span><span class="n">random_split</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Help on function random_split in module turicreate.toolkits.text_analytics._util:

random_split(dataset, prob=0.5)
    Utility for performing a random split for text data that is already in
    bag-of-words format. For each (word, count) pair in a particular element,
    the counts are uniformly partitioned in either a training set or a test
    set.
    
    Parameters
    ----------
    dataset : SArray of type dict, SFrame with columns of type dict
        A data set in bag-of-words format.
    
    prob : float, optional
        Probability for sampling a word to be placed in the test set.
    
    Returns
    -------
    train, test : SArray
        Two data sets in bag-of-words format, where the combined counts are
        equal to the counts in the original data set.
    
    Examples
    --------
    &gt;&gt;&gt; docs = turicreate.SArray([{&#39;are&#39;:5, &#39;you&#39;:3, &#39;not&#39;: 1, &#39;entertained&#39;:10}])
    &gt;&gt;&gt; train, test = turicreate.text_analytics.random_split(docs)
    &gt;&gt;&gt; print(train)
    [{&#39;not&#39;: 1.0, &#39;you&#39;: 3.0, &#39;are&#39;: 3.0, &#39;entertained&#39;: 7.0}]
    &gt;&gt;&gt; print(test)
    [{&#39;are&#39;: 2.0, &#39;entertained&#39;: 3.0}]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">text_analytics</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="o">.</span><span class="mi">8</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">topic_model</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> 
                                <span class="n">num_topics</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>       <span class="c1"># number of topics</span>
                                <span class="n">num_iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>   <span class="c1"># algorithm parameters</span>
                                <span class="n">alpha</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">beta</span><span class="o">=.</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># hyperparameters</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre>Learning a topic model</pre></div><div class="output text_html"><pre>       Number of documents     72269</pre></div><div class="output text_html"><pre>           Vocabulary size    108205</pre></div><div class="output text_html"><pre>   Running collapsed Gibbs sampling</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div><div class="output text_html"><pre>| Iteration | Elapsed Time  | Tokens/Second  | Est. Perplexity |</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div><div class="output text_html"><pre>| 10        | 1.66s         | 6.17013e+06    | 0               |</pre></div><div class="output text_html"><pre>| 20        | 3.12s         | 6.57117e+06    | 0               |</pre></div><div class="output text_html"><pre>| 30        | 4.58s         | 6.41968e+06    | 0               |</pre></div><div class="output text_html"><pre>| 40        | 6.00s         | 6.61674e+06    | 0               |</pre></div><div class="output text_html"><pre>| 50        | 7.42s         | 6.53873e+06    | 0               |</pre></div><div class="output text_html"><pre>| 60        | 8.85s         | 6.46591e+06    | 0               |</pre></div><div class="output text_html"><pre>| 70        | 10.38s        | 5.92867e+06    | 0               |</pre></div><div class="output text_html"><pre>| 80        | 11.90s        | 6.36375e+06    | 0               |</pre></div><div class="output text_html"><pre>| 90        | 13.42s        | 6.20572e+06    | 0               |</pre></div><div class="output text_html"><pre>| 100       | 15.03s        | 5.4879e+06     | 0               |</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;perplexity&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4552.105441414741
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Class                          : TopicModel

Schema
------
Vocabulary Size                : 108205

Settings
--------
Number of Topics               : 100
alpha                          : 0.5
beta                           : 0.1
Iterations                     : 100
Training time                  : 16.0432
Verbose                        : True

Accessible fields             : 
m.topics                      : An SFrame containing the topics.
m.vocabulary                  : An SArray containing the words in the vocabulary.
Useful methods                : 
m.get_topics()                : Get the most probable words per topic.
m.predict(new_docs)           : Make predictions for new documents.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="o">.</span><span class="n">get_topics</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div style="max-height:1000px;max-width:1500px;overflow:auto;"><table frame="box" rules="cols">
    <tr>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">topic</th>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">word</th>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">score</th>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">years</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.004647514462204498</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">evans</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.004059221492305195</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">lebanon</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.0028172696669622205</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">green</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.0028172696669622205</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">time</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.0020982449259741827</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">1</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">national</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.005351237598960527</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">1</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">back</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.002278117379832135</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">1</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">baldwin</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.0018772756121197358</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">1</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">chicago</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.0018104686508343358</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">1</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">private</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.0016100477669781365</td>
    </tr>
</table>
[500 rows x 3 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">get_topics</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Help on method get_topics in module turicreate.toolkits.topic_model.topic_model:

get_topics(topic_ids=None, num_words=5, cdf_cutoff=1.0, output_type=&#39;topic_probabilities&#39;) method of turicreate.toolkits.topic_model.topic_model.TopicModel instance
    Get the words associated with a given topic. The score column is the
    probability of choosing that word given that you have chosen a
    particular topic.
    
    Parameters
    ----------
    topic_ids : list of int, optional
        The topics to retrieve words. Topic ids are zero-based.
        Throws an error if greater than or equal to m[&#39;num_topics&#39;], or
        if the requested topic name is not present.
    
    num_words : int, optional
        The number of words to show.
    
    cdf_cutoff : float, optional
        Allows one to only show the most probable words whose cumulative
        probability is below this cutoff. For example if there exist
        three words where
    
        .. math::
           p(word_1 | topic_k) = .1
    
           p(word_2 | topic_k) = .2
    
           p(word_3 | topic_k) = .05
    
        then setting :math:`cdf_{cutoff}=.3` would return only
        :math:`word_1` and :math:`word_2` since
        :math:`p(word_1 | topic_k) + p(word_2 | topic_k) &lt;= cdf_{cutoff}`
    
    output_type : {&#39;topic_probabilities&#39; | &#39;topic_words&#39;}, optional
        Determine the type of desired output. See below.
    
    Returns
    -------
    out : SFrame
        If output_type is &#39;topic_probabilities&#39;, then the returned value is
        an SFrame with a column of words ranked by a column of scores for
        each topic. Otherwise, the returned value is a SArray where
        each element is a list of the most probable words for each topic.
    
    Examples
    --------
    Get the highest ranked words for all topics.
    
    &gt;&gt;&gt; docs = turicreate.SArray(&#39;https://static.turi.com/datasets/nips-text&#39;)
    &gt;&gt;&gt; m = turicreate.topic_model.create(docs,
                                        num_iterations=50)
    &gt;&gt;&gt; m.get_topics()
    +-------+----------+-----------------+
    | topic |   word   |      score      |
    +-------+----------+-----------------+
    |   0   |   cell   |  0.028974400831 |
    |   0   |  input   | 0.0259470208503 |
    |   0   |  image   | 0.0215721599763 |
    |   0   |  visual  | 0.0173635081992 |
    |   0   |  object  | 0.0172447874156 |
    |   1   | function | 0.0482834508265 |
    |   1   |  input   | 0.0456270024091 |
    |   1   |  point   | 0.0302662839454 |
    |   1   |  result  | 0.0239474934631 |
    |   1   | problem  | 0.0231750116011 |
    |  ...  |   ...    |       ...       |
    +-------+----------+-----------------+
    
    Get the highest ranked words for topics 0 and 1 and show 15 words per
    topic.
    
    &gt;&gt;&gt; m.get_topics([0, 1], num_words=15)
    +-------+----------+------------------+
    | topic |   word   |      score       |
    +-------+----------+------------------+
    |   0   |   cell   |  0.028974400831  |
    |   0   |  input   | 0.0259470208503  |
    |   0   |  image   | 0.0215721599763  |
    |   0   |  visual  | 0.0173635081992  |
    |   0   |  object  | 0.0172447874156  |
    |   0   | response | 0.0139740298286  |
    |   0   |  layer   | 0.0122585145062  |
    |   0   | features | 0.0115343177265  |
    |   0   | feature  | 0.0103530459301  |
    |   0   | spatial  | 0.00823387994361 |
    |  ...  |   ...    |       ...        |
    +-------+----------+------------------+
    
    If one wants to instead just get the top words per topic, one may
    change the format of the output as follows.
    
    &gt;&gt;&gt; topics = m.get_topics(output_type=&#39;topic_words&#39;)
    dtype: list
    Rows: 10
    [[&#39;cell&#39;, &#39;image&#39;, &#39;input&#39;, &#39;object&#39;, &#39;visual&#39;],
     [&#39;algorithm&#39;, &#39;data&#39;, &#39;learning&#39;, &#39;method&#39;, &#39;set&#39;],
     [&#39;function&#39;, &#39;input&#39;, &#39;point&#39;, &#39;problem&#39;, &#39;result&#39;],
     [&#39;model&#39;, &#39;output&#39;, &#39;pattern&#39;, &#39;set&#39;, &#39;unit&#39;],
     [&#39;action&#39;, &#39;learning&#39;, &#39;net&#39;, &#39;problem&#39;, &#39;system&#39;],
     [&#39;error&#39;, &#39;function&#39;, &#39;network&#39;, &#39;parameter&#39;, &#39;weight&#39;],
     [&#39;information&#39;, &#39;level&#39;, &#39;neural&#39;, &#39;threshold&#39;, &#39;weight&#39;],
     [&#39;control&#39;, &#39;field&#39;, &#39;model&#39;, &#39;network&#39;, &#39;neuron&#39;],
     [&#39;hidden&#39;, &#39;layer&#39;, &#39;system&#39;, &#39;training&#39;, &#39;vector&#39;],
     [&#39;component&#39;, &#39;distribution&#39;, &#39;local&#39;, &#39;model&#39;, &#39;optimal&#39;]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">topics</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">get_topics</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">unstack</span><span class="p">([</span><span class="s1">&#39;word&#39;</span><span class="p">,</span><span class="s1">&#39;score&#39;</span><span class="p">],</span> \
                                <span class="n">new_column_name</span><span class="o">=</span><span class="s1">&#39;topic_words&#39;</span><span class="p">)[</span><span class="s1">&#39;topic_words&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="k">for</span> <span class="n">topic</span> <span class="ow">in</span> <span class="n">topics</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">topic</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;storm&#39;, &#39;florida&#39;, &#39;area&#39;, &#39;due&#39;, &#39;texas&#39;, &#39;people&#39;, &#39;damage&#39;, &#39;hurricane&#39;, &#39;tropical&#39;, &#39;system&#39;]
[&#39;project&#39;, &#39;ryan&#39;, &#39;founded&#39;, &#39;harvard&#39;, &#39;carroll&#39;, &#39;including&#39;, &#39;wilson&#39;, &#39;school&#39;, &#39;oxford&#39;, &#39;national&#39;]
[&#39;alliance&#39;, &#39;organization&#39;, &#39;membership&#39;, &#39;board&#39;, &#39;member&#39;, &#39;members&#39;, &#39;association&#39;, &#39;groups&#39;, &#39;group&#39;, &#39;society&#39;]
[&#39;summer&#39;, &#39;george&#39;, &#39;kan&#39;, &#39;julian&#39;, &#39;1978&#39;, &#39;date&#39;, &#39;years&#39;, &#39;wolfe&#39;, &#39;london&#39;, &#39;italian&#39;]
[&#39;german&#39;, &#39;division&#39;, &#39;forces&#39;, &#39;british&#39;, &#39;army&#39;, &#39;men&#39;, &#39;battle&#39;, &#39;general&#39;, &#39;war&#39;, &#39;military&#39;]
[&#39;arrow&#39;, &#39;williams&#39;, &#39;california&#39;, &#39;warren&#39;, &#39;santa&#39;, &#39;los&#39;, &#39;san&#39;, &#39;great&#39;, &#39;angeles&#39;, &#39;renamed&#39;]
[&#39;miller&#39;, &#39;time&#39;, &#39;produced&#39;, &#39;years&#39;, &#39;lewis&#39;, &#39;hamilton&#39;, &#39;morris&#39;, &#39;1999&#39;, &#39;2005&#39;, &#39;epic&#39;]
[&#39;played&#39;, &#39;games&#39;, &#39;coach&#39;, &#39;won&#39;, &#39;points&#39;, &#39;team&#39;, &#39;game&#39;, &#39;record&#39;, &#39;season&#39;, &#39;teams&#39;]
[&#39;green&#39;, &#39;time&#39;, &#39;connecticut&#39;, &#39;evans&#39;, &#39;years&#39;, &#39;sixth&#39;, &#39;lebanon&#39;, &#39;2001&#39;, &#39;worked&#39;, &#39;2005&#39;]
[&#39;van&#39;, &#39;berlin&#39;, &#39;im&#39;, &#39;des&#39;, &#39;von&#39;, &#39;die&#39;, &#39;den&#39;, &#39;der&#39;, &#39;das&#39;, &#39;und&#39;]
[&#39;clothing&#39;, &#39;hat&#39;, &#39;worn&#39;, &#39;wear&#39;, &#39;made&#39;, &#39;green&#39;, &#39;summer&#39;, &#39;black&#39;, &#39;top&#39;, &#39;dress&#39;]
[&#39;2009&#39;, &#39;year&#39;, &#39;kids&#39;, &#39;october&#39;, &#39;2010&#39;, &#39;2007&#39;, &#39;school&#39;, &#39;2006&#39;, &#39;2008&#39;, &#39;national&#39;]
[&#39;magazine&#39;, &#39;grant&#39;, &#39;oregon&#39;, &#39;portland&#39;, &#39;college&#39;, &#39;1985&#39;, &#39;2006&#39;, &#39;year&#39;, &#39;long&#39;, &#39;beer&#39;]
[&#39;network&#39;, &#39;show&#39;, &#39;local&#39;, &#39;news&#39;, &#39;broadcast&#39;, &#39;radio&#39;, &#39;channel&#39;, &#39;stations&#39;, &#39;television&#39;, &#39;station&#39;]
[&#39;bridge&#39;, &#39;north&#39;, &#39;river&#39;, &#39;county&#39;, &#39;state&#39;, &#39;west&#39;, &#39;route&#39;, &#39;city&#39;, &#39;east&#39;, &#39;road&#39;]
[&#39;part&#39;, &#39;degree&#39;, &#39;na&#39;, &#39;valid&#39;, &#39;agent&#39;, &#39;history&#39;, &#39;reform&#39;, &#39;born&#39;, &#39;agency&#39;, &#39;trn&#39;]
[&#39;children&#39;, &#39;father&#39;, &#39;mother&#39;, &#39;married&#39;, &#39;years&#39;, &#39;family&#39;, &#39;born&#39;, &#39;life&#39;, &#39;died&#39;, &#39;time&#39;]
[&#39;early&#39;, &#39;population&#39;, &#39;century&#39;, &#39;american&#39;, &#39;war&#39;, &#39;government&#39;, &#39;states&#39;, &#39;british&#39;, &#39;united&#39;, &#39;people&#39;]
[&#39;stories&#39;, &#39;magazine&#39;, &#39;writing&#39;, &#39;history&#39;, &#39;work&#39;, &#39;wrote&#39;, &#39;works&#39;, &#39;published&#39;, &#39;book&#39;, &#39;books&#39;]
[&#39;collection&#39;, &#39;painting&#39;, &#39;arts&#39;, &#39;museum&#39;, &#39;work&#39;, &#39;york&#39;, &#39;design&#39;, &#39;artists&#39;, &#39;art&#39;, &#39;works&#39;]
[&#39;named&#39;, &#39;flag&#39;, &#39;orange&#39;, &#39;blue&#39;, &#39;colors&#39;, &#39;yellow&#39;, &#39;tiger&#39;, &#39;black&#39;, &#39;red&#39;, &#39;white&#39;]
[&#39;made&#39;, &#39;mission&#39;, &#39;test&#39;, &#39;project&#39;, &#39;space&#39;, &#39;aircraft&#39;, &#39;wright&#39;, &#39;design&#39;, &#39;launch&#39;, &#39;flight&#39;]
[&#39;alan&#39;, &#39;phillips&#39;, &#39;preov&#39;, &#39;koice&#39;, &#39;beth&#39;, &#39;trenn&#39;, &#39;phillip&#39;, &#39;nitra&#39;, &#39;town&#39;, &#39;trnava&#39;]
[&#39;racing&#39;, &#39;cars&#39;, &#39;car&#39;, &#39;engines&#39;, &#39;models&#39;, &#39;series&#39;, &#39;engine&#39;, &#39;system&#39;, &#39;race&#39;, &#39;model&#39;]
[&#39;building&#39;, &#39;duck&#39;, &#39;london&#39;, &#39;philadelphia&#39;, &#39;represented&#39;, &#39;major&#39;, &#39;york&#39;, &#39;design&#39;, &#39;journal&#39;, &#39;duncan&#39;]
[&#39;english&#39;, &#39;language&#39;, &#39;form&#39;, &#39;meaning&#39;, &#39;word&#39;, &#39;words&#39;, &#39;names&#39;, &#39;written&#39;, &#39;languages&#39;, &#39;common&#39;]
[&#39;gene&#39;, &#39;enzyme&#39;, &#39;dna&#39;, &#39;site&#39;, &#39;proteins&#39;, &#39;protein&#39;, &#39;cells&#39;, &#39;cell&#39;, &#39;structure&#39;, &#39;genes&#39;]
[&#39;work&#39;, &#39;year&#39;, &#39;2009&#39;, &#39;andrew&#39;, &#39;list&#39;, &#39;henin&#39;, &#39;link&#39;, &#39;dates&#39;, &#39;part&#39;, &#39;calendar&#39;]
[&#39;law&#39;, &#39;public&#39;, &#39;united&#39;, &#39;state&#39;, &#39;legal&#39;, &#39;act&#39;, &#39;states&#39;, &#39;court&#39;, &#39;case&#39;, &#39;federal&#39;]
[&#39;trains&#39;, &#39;west&#39;, &#39;line&#39;, &#39;rail&#39;, &#39;train&#39;, &#39;station&#39;, &#39;services&#39;, &#39;service&#39;, &#39;opened&#39;, &#39;railway&#39;]
[&#39;served&#39;, &#39;cemetery&#39;, &#39;received&#39;, &#39;texas&#39;, &#39;po&#39;, &#39;christi&#39;, &#39;university&#39;, &#39;post&#39;, &#39;corpus&#39;, &#39;mexico&#39;]
[&#39;international&#39;, &#39;worked&#39;, &#39;festival&#39;, &#39;director&#39;, &#39;film&#39;, &#39;awards&#39;, &#39;won&#39;, &#39;award&#39;, &#39;awarded&#39;, &#39;academy&#39;]
[&#39;empire&#39;, &#39;china&#39;, &#39;chinese&#39;, &#39;dynasty&#39;, &#39;roman&#39;, &#39;greek&#39;, &#39;time&#39;, &#39;king&#39;, &#39;bc&#39;, &#39;emperor&#39;]
[&#39;port&#39;, &#39;ship&#39;, &#39;coast&#39;, &#39;island&#39;, &#39;sea&#39;, &#39;fleet&#39;, &#39;region&#39;, &#39;bay&#39;, &#39;ships&#39;, &#39;islands&#39;]
[&#39;south&#39;, &#39;north&#39;, &#39;river&#39;, &#39;mountain&#39;, &#39;water&#39;, &#39;creek&#39;, &#39;lake&#39;, &#39;valley&#39;, &#39;park&#39;, &#39;area&#39;]
[&#39;january&#39;, &#39;day&#39;, &#39;june&#39;, &#39;2009&#39;, &#39;october&#39;, &#39;december&#39;, &#39;2010&#39;, &#39;2007&#39;, &#39;2008&#39;, &#39;september&#39;]
[&#39;round&#39;, &#39;team&#39;, &#39;won&#39;, &#39;event&#39;, &#39;title&#39;, &#39;world&#39;, &#39;match&#39;, &#39;championship&#39;, &#39;lost&#39;, &#39;open&#39;]
[&#39;created&#39;, &#39;2010&#39;, &#39;ash&#39;, &#39;complex&#39;, &#39;sanders&#39;, &#39;hotel&#39;, &#39;skating&#39;, &#39;school&#39;, &#39;house&#39;, &#39;msn&#39;]
[&#39;left&#39;, &#39;easy&#39;, &#39;leg&#39;, &#39;ancient&#39;, &#39;benson&#39;, &#39;school&#39;, &#39;2003&#39;, &#39;critical&#39;, &#39;british&#39;, &#39;westfield&#39;]
[&#39;released&#39;, &#39;world&#39;, &#39;games&#39;, &#39;version&#39;, &#39;series&#39;, &#39;video&#39;, &#39;player&#39;, &#39;game&#39;, &#39;players&#39;, &#39;2&#39;]
[&#39;won&#39;, &#39;cup&#39;, &#39;team&#39;, &#39;teams&#39;, &#39;season&#39;, &#39;final&#39;, &#39;football&#39;, &#39;club&#39;, &#39;league&#39;, &#39;played&#39;]
[&#39;1988&#39;, &#39;called&#39;, &#39;list&#39;, &#39;1971&#39;, &#39;2010&#39;, &#39;1994&#39;, &#39;made&#39;, &#39;trent&#39;, &#39;found&#39;, &#39;local&#39;]
[&#39;world&#39;, &#39;received&#39;, &#39;usa&#39;, &#39;wall&#39;, &#39;part&#39;, &#39;start0&#39;, &#39;williams&#39;, &#39;work&#39;, &#39;events&#39;, &#39;plotdata&#39;]
[&#39;years&#39;, &#39;age&#39;, &#39;income&#39;, &#39;median&#39;, &#39;18&#39;, &#39;living&#39;, &#39;males&#39;, &#39;town&#39;, &#39;average&#39;, &#39;population&#39;]
[&#39;youth&#39;, &#39;bamboo&#39;, &#39;ross&#39;, &#39;griffin&#39;, &#39;williams&#39;, &#39;meeting&#39;, &#39;monument&#39;, &#39;town&#39;, &#39;joined&#39;, &#39;girl&#39;]
[&#39;south&#39;, &#39;european&#39;, &#39;international&#39;, &#39;economic&#39;, &#39;states&#39;, &#39;development&#39;, &#39;united&#39;, &#39;government&#39;, &#39;countries&#39;, &#39;world&#39;]
[&#39;national&#39;, &#39;constituencies&#39;, &#39;animation&#39;, &#39;part&#39;, &#39;track&#39;, &#39;baldwin&#39;, &#39;1982&#39;, &#39;private&#39;, &#39;back&#39;, &#39;chicago&#39;]
[&#39;hill&#39;, &#39;morgan&#39;, &#39;davis&#39;, &#39;cj&#39;, &#39;1992&#39;, &#39;arch&#39;, &#39;child&#39;, &#39;1995&#39;, &#39;tony&#39;, &#39;part&#39;]
[&#39;form&#39;, &#39;called&#39;, &#39;1&#39;, &#39;theory&#39;, &#39;set&#39;, &#39;number&#39;, &#39;function&#39;, &#39;type&#39;, &#39;system&#39;, &#39;model&#39;]
[&#39;form&#39;, &#39;women&#39;, &#39;social&#39;, &#39;life&#39;, &#39;society&#39;, &#39;people&#39;, &#39;time&#39;, &#39;world&#39;, &#39;human&#39;, &#39;work&#39;]
[&#39;city&#39;, &#39;san&#39;, &#39;paris&#39;, &#39;el&#39;, &#39;france&#39;, &#39;la&#39;, &#39;de&#39;, &#39;french&#39;, &#39;spain&#39;, &#39;spanish&#39;]
[&#39;city&#39;, &#39;located&#39;, &#39;house&#39;, &#39;park&#39;, &#39;building&#39;, &#39;street&#39;, &#39;built&#39;, &#39;town&#39;, &#39;area&#39;, &#39;century&#39;]
[&#39;made&#39;, &#39;include&#39;, &#39;variety&#39;, &#39;traditional&#39;, &#39;rice&#39;, &#39;popular&#39;, &#39;food&#39;, &#39;called&#39;, &#39;served&#39;, &#39;wine&#39;]
[&#39;canadian&#39;, &#39;ontario&#39;, &#39;alberta&#39;, &#39;british&#39;, &#39;york&#39;, &#39;2002&#39;, &#39;toronto&#39;, &#39;quebec&#39;, &#39;canada&#39;, &#39;montreal&#39;]
[&#39;khan&#39;, &#39;afghanistan&#39;, &#39;indian&#39;, &#39;singh&#39;, &#39;temple&#39;, &#39;punjab&#39;, &#39;pakistan&#39;, &#39;sri&#39;, &#39;india&#39;, &#39;community&#39;]
[&#39;brooklyn&#39;, &#39;city&#39;, &#39;class&#39;, &#39;ambassador&#39;, &#39;2004&#39;, &#39;due&#39;, &#39;babylon&#39;, &#39;historical&#39;, &#39;area&#39;, &#39;5&#39;]
[&#39;heat&#39;, &#39;iron&#39;, &#39;high&#39;, &#39;process&#39;, &#39;water&#39;, &#39;form&#39;, &#39;gas&#39;, &#39;temperature&#39;, &#39;nuclear&#39;, &#39;energy&#39;]
[&#39;airlines&#39;, &#39;regional&#39;, &#39;airport&#39;, &#39;2010&#39;, &#39;international&#39;, &#39;travel&#39;, &#39;airways&#39;, &#39;2005&#39;, &#39;airline&#39;, &#39;joined&#39;]
[&#39;head&#39;, &#39;15&#39;, &#39;home&#39;, &#39;2010&#39;, &#39;2003&#39;, &#39;elected&#39;, &#39;park&#39;, &#39;stone&#39;, &#39;gaol&#39;, &#39;numerous&#39;]
[&#39;poland&#39;, &#39;years&#39;, &#39;polish&#39;, &#39;soviet&#39;, &#39;moscow&#39;, &#39;war&#39;, &#39;russian&#39;, &#39;swedish&#39;, &#39;union&#39;, &#39;russia&#39;]
[&#39;william&#39;, &#39;henry&#39;, &#39;england&#39;, &#39;sir&#39;, &#39;london&#39;, &#39;royal&#39;, &#39;lord&#39;, &#39;king&#39;, &#39;son&#39;, &#39;john&#39;]
[&#39;ohio&#39;, &#39;virginia&#39;, &#39;district&#39;, &#39;washington&#39;, &#39;john&#39;, &#39;carolina&#39;, &#39;county&#39;, &#39;state&#39;, &#39;served&#39;, &#39;south&#39;]
[&#39;state&#39;, &#39;election&#39;, &#39;political&#39;, &#39;minister&#39;, &#39;council&#39;, &#39;national&#39;, &#39;party&#39;, &#39;president&#39;, &#39;government&#39;, &#39;elected&#39;]
[&#39;district&#39;, &#39;districts&#39;, &#39;register&#39;, &#39;properties&#39;, &#39;places&#39;, &#39;illinois&#39;, &#39;national&#39;, &#39;county&#39;, &#39;historic&#39;, &#39;school&#39;]
[&#39;operations&#39;, &#39;aircraft&#39;, &#39;base&#39;, &#39;united&#39;, &#39;war&#39;, &#39;service&#39;, &#39;air&#39;, &#39;group&#39;, &#39;force&#39;, &#39;training&#39;]
[&#39;number&#39;, &#39;25&#39;, &#39;2010&#39;, &#39;golf&#39;, &#39;time&#39;, &#39;scrooge&#39;, &#39;group&#39;, &#39;university&#39;, &#39;chams&#39;, &#39;world&#39;]
[&#39;light&#39;, &#39;range&#39;, &#39;made&#39;, &#39;time&#39;, &#39;system&#39;, &#39;small&#39;, &#39;power&#39;, &#39;energy&#39;, &#39;high&#39;, &#39;current&#39;]
[&#39;1983&#39;, &#39;university&#39;, &#39;states&#39;, &#39;served&#39;, &#39;appointed&#39;, &#39;1986&#39;, &#39;degree&#39;, &#39;bill&#39;, &#39;professor&#39;, &#39;2000&#39;]
[&#39;years&#39;, &#39;head&#39;, &#39;joseph&#39;, &#39;school&#39;, &#39;smiths&#39;, &#39;rejoice&#39;, &#39;smith&#39;, &#39;clark&#39;, &#39;stone&#39;, &#39;plates&#39;]
[&#39;found&#39;, &#39;occur&#39;, &#39;body&#39;, &#39;small&#39;, &#39;disease&#39;, &#39;large&#39;, &#39;species&#39;, &#39;family&#39;, &#39;order&#39;, &#39;birds&#39;]
[&#39;number&#39;, &#39;fat&#39;, &#39;2006&#39;, &#39;named&#39;, &#39;work&#39;, &#39;death&#39;, &#39;published&#39;, &#39;flores&#39;, &#39;vincent&#39;, &#39;villa&#39;]
[&#39;company&#39;, &#39;business&#39;, &#39;mine&#39;, &#39;sold&#39;, &#39;oil&#39;, &#39;stores&#39;, &#39;industry&#39;, &#39;year&#39;, &#39;production&#39;, &#39;mining&#39;]
[&#39;martin&#39;, &#39;kitty&#39;, &#39;obesity&#39;, &#39;turtle&#39;, &#39;point&#39;, &#39;2000&#39;, &#39;camp&#39;, &#39;clark&#39;, &#39;moved&#39;, &#39;born&#39;]
[&#39;1994&#39;, &#39;1998&#39;, &#39;ryo&#39;, &#39;venezuela&#39;, &#39;tannins&#39;, &#39;national&#39;, &#39;group&#39;, &#39;minor&#39;, &#39;christmas&#39;, &#39;world&#39;]
[&#39;parish&#39;, &#39;saint&#39;, &#39;bishop&#39;, &#39;church&#39;, &#39;roman&#39;, &#39;council&#39;, &#39;st&#39;, &#39;century&#39;, &#39;catholic&#39;, &#39;pope&#39;]
[&#39;released&#39;, &#39;records&#39;, &#39;single&#39;, &#39;album&#39;, &#39;songs&#39;, &#39;music&#39;, &#39;band&#39;, &#39;live&#39;, &#39;song&#39;, &#39;tour&#39;]
[&#39;wales&#39;, &#39;australia&#39;, &#39;played&#39;, &#39;cricket&#39;, &#39;zealand&#39;, &#39;day&#39;, &#39;sydney&#39;, &#39;made&#39;, &#39;australian&#39;, &#39;south&#39;]
[&#39;information&#39;, &#39;network&#39;, &#39;system&#39;, &#39;software&#39;, &#39;systems&#39;, &#39;internet&#39;, &#39;users&#39;, &#39;technology&#39;, &#39;computer&#39;, &#39;data&#39;]
[&#39;philippine&#39;, &#39;clara&#39;, &#39;foundation&#39;, &#39;chief&#39;, &#39;full&#39;, &#39;fair&#39;, &#39;philippines&#39;, &#39;manila&#39;, &#39;rupiah&#39;, &#39;belle&#39;]
[&#39;group&#39;, &#39;began&#39;, &#39;anderson&#39;, &#39;minnesota&#39;, &#39;john&#39;, &#39;period&#39;, &#39;jones&#39;, &#39;te&#39;, &#39;td&#39;, &#39;dont&#39;]
[&#39;northern&#39;, &#39;cork&#39;, &#39;dublin&#39;, &#39;ireland&#39;, &#39;irish&#39;, &#39;senior&#39;, &#39;john&#39;, &#39;county&#39;, &#39;title&#39;, &#39;medal&#39;]
[&#39;school&#39;, &#39;2006&#39;, &#39;stone&#39;, &#39;york&#39;, &#39;bay&#39;, &#39;village&#39;, &#39;held&#39;, &#39;created&#39;, &#39;local&#39;, &#39;community&#39;]
[&#39;years&#39;, &#39;jersey&#39;, &#39;police&#39;, &#39;city&#39;, &#39;york&#39;, &#39;family&#39;, &#39;crime&#39;, &#39;gang&#39;, &#39;prison&#39;, &#39;arrested&#39;]
[&#39;2001&#39;, &#39;american&#39;, &#39;saudi&#39;, &#39;bin&#39;, &#39;world&#39;, &#39;al&#39;, &#39;sh&#39;, &#39;including&#39;, &#39;laden&#39;, &#39;joined&#39;]
[&#39;school&#39;, &#39;education&#39;, &#39;year&#39;, &#39;students&#39;, &#39;research&#39;, &#39;schools&#39;, &#39;college&#39;, &#39;high&#39;, &#39;university&#39;, &#39;program&#39;]
[&#39;events&#39;, &#39;time&#39;, &#39;mr&#39;, &#39;ride&#39;, &#39;roller&#39;, &#39;part&#39;, &#39;including&#39;, &#39;bicycle&#39;, &#39;riders&#39;, &#39;bike&#39;]
[&#39;montenegro&#39;, &#39;yugoslavia&#39;, &#39;serbia&#39;, &#39;school&#39;, &#39;serbian&#39;, &#39;albanian&#39;, &#39;albania&#39;, &#39;croatian&#39;, &#39;croatia&#39;, &#39;year&#39;]
[&#39;austin&#39;, &#39;shells&#39;, &#39;place&#39;, &#39;peter&#39;, &#39;shell&#39;, &#39;uk&#39;, &#39;school&#39;, &#39;2010&#39;, &#39;active&#39;, &#39;mark&#39;]
[&#39;york&#39;, &#39;series&#39;, &#39;masters&#39;, &#39;booth&#39;, &#39;world&#39;, &#39;free&#39;, &#39;2003&#39;, &#39;major&#39;, &#39;birmingham&#39;, &#39;setting&#39;]
[&#39;role&#39;, &#39;appeared&#39;, &#39;films&#39;, &#39;episode&#39;, &#39;television&#39;, &#39;show&#39;, &#39;series&#39;, &#39;character&#39;, &#39;movie&#39;, &#39;film&#39;]
[&#39;medicine&#39;, &#39;dr&#39;, &#39;training&#39;, &#39;care&#39;, &#39;hospital&#39;, &#39;health&#39;, &#39;surgery&#39;, &#39;center&#39;, &#39;dog&#39;, &#39;medical&#39;]
[&#39;norwegian&#39;, &#39;travis&#39;, &#39;2007&#39;, &#39;ste&#39;, &#39;bar&#39;, &#39;city&#39;, &#39;home&#39;, &#39;norway&#39;, &#39;parker&#39;, &#39;include&#39;]
[&#39;jewish&#39;, &#39;christian&#39;, &#39;people&#39;, &#39;god&#39;, &#39;gods&#39;, &#39;religious&#39;, &#39;great&#39;, &#39;church&#39;, &#39;churches&#39;, &#39;jesus&#39;]
[&#39;zion&#39;, &#39;contest&#39;, &#39;miss&#39;, &#39;relay&#39;, &#39;gold&#39;, &#39;post&#39;, &#39;nec&#39;, &#39;mori&#39;, &#39;yacht&#39;, &#39;time&#39;]
[&#39;york&#39;, &#39;theatre&#39;, &#39;theater&#39;, &#39;dance&#39;, &#39;musical&#39;, &#39;orchestra&#39;, &#39;opera&#39;, &#39;music&#39;, &#39;performed&#39;, &#39;festival&#39;]
[&#39;tax&#39;, &#39;money&#39;, &#39;financial&#39;, &#39;market&#39;, &#39;bank&#39;, &#39;million&#39;, &#39;business&#39;, &#39;price&#39;, &#39;services&#39;, &#39;company&#39;]
[&#39;life&#39;, &#39;death&#39;, &#39;father&#39;, &#39;end&#39;, &#39;find&#39;, &#39;back&#39;, &#39;man&#39;, &#39;make&#39;, &#39;time&#39;, &#39;tells&#39;]
[&#39;years&#39;, &#39;2007&#39;, &#39;walker&#39;, &#39;post&#39;, &#39;1911&#39;, &#39;croydon&#39;, &#39;burma&#39;, &#39;burmese&#39;, &#39;named&#39;, &#39;day&#39;]
[&#39;high&#39;, &#39;vegas&#39;, &#39;purchased&#39;, &#39;alice&#39;, &#39;paul&#39;, &#39;hotel&#39;, &#39;scott&#39;, &#39;ranch&#39;, &#39;las&#39;, &#39;highlands&#39;]
[&#39;horse&#39;, &#39;stakes&#39;, &#39;born&#39;, &#39;american&#39;, &#39;horses&#39;, &#39;race&#39;, &#39;boas&#39;, &#39;breed&#39;, &#39;english&#39;, &#39;racing&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Help on TopicModel in module turicreate.toolkits.topic_model.topic_model object:

class TopicModel(turicreate.toolkits._model.Model)
 |  TopicModel objects can be used to predict the underlying topic of a
 |  document.
 |  
 |  This model cannot be constructed directly.  Instead, use
 |  :func:`turicreate.topic_model.create` to create an instance
 |  of this model. A detailed list of parameter options and code samples
 |  are available in the documentation for the create function.
 |  
 |  Method resolution order:
 |      TopicModel
 |      turicreate.toolkits._model.Model
 |      turicreate.toolkits._model.ExposeAttributesFromProxy
 |      builtins.object
 |  
 |  Methods defined here:
 |  
 |  __init__(self, model_proxy)
 |      Initialize self.  See help(type(self)) for accurate signature.
 |  
 |  __repr__(self)
 |      Print a string description of the model when the model name is entered
 |      in the terminal.
 |  
 |  __str__(self)
 |      Return a string description of the model to the ``print`` method.
 |      
 |      Returns
 |      -------
 |      out : string
 |          A description of the model.
 |  
 |  evaluate(self, train_data, test_data=None, metric=&#39;perplexity&#39;)
 |      Estimate the model&#39;s ability to predict new data. Imagine you have a
 |      corpus of books. One common approach to evaluating topic models is to
 |      train on the first half of all of the books and see how well the model
 |      predicts the second half of each book.
 |      
 |      This method returns a metric called perplexity, which  is related to the
 |      likelihood of observing these words under the given model. See
 |      :py:func:`~turicreate.topic_model.perplexity` for more details.
 |      
 |      The provided `train_data` and `test_data` must have the same length,
 |      i.e., both data sets must have the same number of documents; the model
 |      will use train_data to estimate which topic the document belongs to, and
 |      this is used to estimate the model&#39;s performance at predicting the
 |      unseen words in the test data.
 |      
 |      See :py:func:`~turicreate.topic_model.TopicModel.predict` for details
 |      on how these predictions are made, and see
 |      :py:func:`~turicreate.text_analytics.random_split` for a helper function
 |      that can be used for making train/test splits.
 |      
 |      Parameters
 |      ----------
 |      train_data : SArray or SFrame
 |          A set of documents to predict topics for.
 |      
 |      test_data : SArray or SFrame, optional
 |          A set of documents to evaluate performance on.
 |          By default this will set to be the same as train_data.
 |      
 |      metric : str
 |          The chosen metric to use for evaluating the topic model.
 |          Currently only &#39;perplexity&#39; is supported.
 |      
 |      Returns
 |      -------
 |      out : dict
 |          The set of estimated evaluation metrics.
 |      
 |      See Also
 |      --------
 |      predict, turicreate.toolkits.text_analytics.random_split
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; docs = turicreate.SArray(&#39;https://static.turi.com/datasets/nips-text&#39;)
 |      &gt;&gt;&gt; train_data, test_data = turicreate.text_analytics.random_split(docs)
 |      &gt;&gt;&gt; m = turicreate.topic_model.create(train_data)
 |      &gt;&gt;&gt; m.evaluate(train_data, test_data)
 |      {&#39;perplexity&#39;: 2467.530370396021}
 |  
 |  get_topics(self, topic_ids=None, num_words=5, cdf_cutoff=1.0, output_type=&#39;topic_probabilities&#39;)
 |      Get the words associated with a given topic. The score column is the
 |      probability of choosing that word given that you have chosen a
 |      particular topic.
 |      
 |      Parameters
 |      ----------
 |      topic_ids : list of int, optional
 |          The topics to retrieve words. Topic ids are zero-based.
 |          Throws an error if greater than or equal to m[&#39;num_topics&#39;], or
 |          if the requested topic name is not present.
 |      
 |      num_words : int, optional
 |          The number of words to show.
 |      
 |      cdf_cutoff : float, optional
 |          Allows one to only show the most probable words whose cumulative
 |          probability is below this cutoff. For example if there exist
 |          three words where
 |      
 |          .. math::
 |             p(word_1 | topic_k) = .1
 |      
 |             p(word_2 | topic_k) = .2
 |      
 |             p(word_3 | topic_k) = .05
 |      
 |          then setting :math:`cdf_{cutoff}=.3` would return only
 |          :math:`word_1` and :math:`word_2` since
 |          :math:`p(word_1 | topic_k) + p(word_2 | topic_k) &lt;= cdf_{cutoff}`
 |      
 |      output_type : {&#39;topic_probabilities&#39; | &#39;topic_words&#39;}, optional
 |          Determine the type of desired output. See below.
 |      
 |      Returns
 |      -------
 |      out : SFrame
 |          If output_type is &#39;topic_probabilities&#39;, then the returned value is
 |          an SFrame with a column of words ranked by a column of scores for
 |          each topic. Otherwise, the returned value is a SArray where
 |          each element is a list of the most probable words for each topic.
 |      
 |      Examples
 |      --------
 |      Get the highest ranked words for all topics.
 |      
 |      &gt;&gt;&gt; docs = turicreate.SArray(&#39;https://static.turi.com/datasets/nips-text&#39;)
 |      &gt;&gt;&gt; m = turicreate.topic_model.create(docs,
 |                                          num_iterations=50)
 |      &gt;&gt;&gt; m.get_topics()
 |      +-------+----------+-----------------+
 |      | topic |   word   |      score      |
 |      +-------+----------+-----------------+
 |      |   0   |   cell   |  0.028974400831 |
 |      |   0   |  input   | 0.0259470208503 |
 |      |   0   |  image   | 0.0215721599763 |
 |      |   0   |  visual  | 0.0173635081992 |
 |      |   0   |  object  | 0.0172447874156 |
 |      |   1   | function | 0.0482834508265 |
 |      |   1   |  input   | 0.0456270024091 |
 |      |   1   |  point   | 0.0302662839454 |
 |      |   1   |  result  | 0.0239474934631 |
 |      |   1   | problem  | 0.0231750116011 |
 |      |  ...  |   ...    |       ...       |
 |      +-------+----------+-----------------+
 |      
 |      Get the highest ranked words for topics 0 and 1 and show 15 words per
 |      topic.
 |      
 |      &gt;&gt;&gt; m.get_topics([0, 1], num_words=15)
 |      +-------+----------+------------------+
 |      | topic |   word   |      score       |
 |      +-------+----------+------------------+
 |      |   0   |   cell   |  0.028974400831  |
 |      |   0   |  input   | 0.0259470208503  |
 |      |   0   |  image   | 0.0215721599763  |
 |      |   0   |  visual  | 0.0173635081992  |
 |      |   0   |  object  | 0.0172447874156  |
 |      |   0   | response | 0.0139740298286  |
 |      |   0   |  layer   | 0.0122585145062  |
 |      |   0   | features | 0.0115343177265  |
 |      |   0   | feature  | 0.0103530459301  |
 |      |   0   | spatial  | 0.00823387994361 |
 |      |  ...  |   ...    |       ...        |
 |      +-------+----------+------------------+
 |      
 |      If one wants to instead just get the top words per topic, one may
 |      change the format of the output as follows.
 |      
 |      &gt;&gt;&gt; topics = m.get_topics(output_type=&#39;topic_words&#39;)
 |      dtype: list
 |      Rows: 10
 |      [[&#39;cell&#39;, &#39;image&#39;, &#39;input&#39;, &#39;object&#39;, &#39;visual&#39;],
 |       [&#39;algorithm&#39;, &#39;data&#39;, &#39;learning&#39;, &#39;method&#39;, &#39;set&#39;],
 |       [&#39;function&#39;, &#39;input&#39;, &#39;point&#39;, &#39;problem&#39;, &#39;result&#39;],
 |       [&#39;model&#39;, &#39;output&#39;, &#39;pattern&#39;, &#39;set&#39;, &#39;unit&#39;],
 |       [&#39;action&#39;, &#39;learning&#39;, &#39;net&#39;, &#39;problem&#39;, &#39;system&#39;],
 |       [&#39;error&#39;, &#39;function&#39;, &#39;network&#39;, &#39;parameter&#39;, &#39;weight&#39;],
 |       [&#39;information&#39;, &#39;level&#39;, &#39;neural&#39;, &#39;threshold&#39;, &#39;weight&#39;],
 |       [&#39;control&#39;, &#39;field&#39;, &#39;model&#39;, &#39;network&#39;, &#39;neuron&#39;],
 |       [&#39;hidden&#39;, &#39;layer&#39;, &#39;system&#39;, &#39;training&#39;, &#39;vector&#39;],
 |       [&#39;component&#39;, &#39;distribution&#39;, &#39;local&#39;, &#39;model&#39;, &#39;optimal&#39;]]
 |  
 |  predict(self, dataset, output_type=&#39;assignment&#39;, num_burnin=None)
 |      Use the model to predict topics for each document. The provided
 |      `dataset` should be an SArray object where each element is a dict
 |      representing a single document in bag-of-words format, where keys
 |      are words and values are their corresponding counts. If `dataset` is
 |      an SFrame, then it must contain a single column of dict type.
 |      
 |      The current implementation will make inferences about each document
 |      given its estimates of the topics learned when creating the model.
 |      This is done via Gibbs sampling.
 |      
 |      Parameters
 |      ----------
 |      dataset : SArray, SFrame of type dict
 |          A set of documents to use for making predictions.
 |      
 |      output_type : str, optional
 |          The type of output desired. This can either be
 |      
 |          - assignment: the returned values are integers in [0, num_topics)
 |          - probability: each returned prediction is a vector with length
 |            num_topics, where element k represents the probability that
 |            document belongs to topic k.
 |      
 |      num_burnin : int, optional
 |          The number of iterations of Gibbs sampling to perform when
 |          inferring the topics for documents at prediction time.
 |          If provided this will override the burnin value set during
 |          training.
 |      
 |      Returns
 |      -------
 |      out : SArray
 |      
 |      See Also
 |      --------
 |      evaluate
 |      
 |      Examples
 |      --------
 |      Make predictions about which topic each document belongs to.
 |      
 |      &gt;&gt;&gt; docs = turicreate.SArray(&#39;https://static.turi.com/datasets/nips-text&#39;)
 |      &gt;&gt;&gt; m = turicreate.topic_model.create(docs)
 |      &gt;&gt;&gt; pred = m.predict(docs)
 |      
 |      If one is interested in the probability of each topic
 |      
 |      &gt;&gt;&gt; pred = m.predict(docs, output_type=&#39;probability&#39;)
 |      
 |      Notes
 |      -----
 |      For each unique word w in a document d, we sample an assignment to
 |      topic k with probability proportional to
 |      
 |      .. math::
 |          p(z_{dw} = k) \propto (n_{d,k} + \alpha) * \Phi_{w,k}
 |      
 |      where
 |      
 |      - :math:`W` is the size of the vocabulary,
 |      - :math:`n_{d,k}` is the number of other times we have assigned a word in
 |        document to d to topic :math:`k`,
 |      - :math:`\Phi_{w,k}` is the probability under the model of choosing word
 |        :math:`w` given the word is of topic :math:`k`. This is the matrix
 |        returned by calling `m[&#39;topics&#39;]`.
 |      
 |      This represents a collapsed Gibbs sampler for the document assignments
 |      while we keep the topics learned during training fixed.
 |      This process is done in parallel across all documents, five times per
 |      document.
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from turicreate.toolkits._model.Model:
 |  
 |  save(self, location)
 |      Save the model. The model is saved as a directory which can then be
 |      loaded using the :py:func:`~turicreate.load_model` method.
 |      
 |      Parameters
 |      ----------
 |      location : string
 |          Target destination for the model. Can be a local path or remote URL.
 |      
 |      See Also
 |      ----------
 |      turicreate.load_model
 |      
 |      Examples
 |      ----------
 |      &gt;&gt;&gt; model.save(&#39;my_model_file&#39;)
 |      &gt;&gt;&gt; loaded_model = turicreate.load_model(&#39;my_model_file&#39;)
 |  
 |  summary(self, output=None)
 |      Print a summary of the model. The summary includes a description of
 |      training data, options, hyper-parameters, and statistics measured
 |      during model creation.
 |      
 |      Parameters
 |      ----------
 |      output : str, None
 |          The type of summary to return.
 |      
 |          - None or &#39;stdout&#39; : print directly to stdout.
 |      
 |          - &#39;str&#39; : string of summary
 |      
 |          - &#39;dict&#39; : a dict with &#39;sections&#39; and &#39;section_titles&#39; ordered
 |            lists. The entries in the &#39;sections&#39; list are tuples of the form
 |            (&#39;label&#39;, &#39;value&#39;).
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; m.summary()
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from turicreate.toolkits._model.ExposeAttributesFromProxy:
 |  
 |  __dir__(self)
 |      Combine the results of dir from the current class with the results of
 |      list_fields().
 |  
 |  __getattribute__(self, attr)
 |      Use the internal proxy object for obtaining list_fields.
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from turicreate.toolkits._model.ExposeAttributesFromProxy:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from turicreate.toolkits._model.ExposeAttributesFromProxy:
 |  
 |  __proxy__ = None
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">print_topics</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="n">topics</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">get_topics</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">topics</span> <span class="o">=</span> <span class="n">topics</span><span class="o">.</span><span class="n">unstack</span><span class="p">([</span><span class="s1">&#39;word&#39;</span><span class="p">,</span><span class="s1">&#39;score&#39;</span><span class="p">],</span> <span class="n">new_column_name</span><span class="o">=</span><span class="s1">&#39;topic_words&#39;</span><span class="p">)[</span><span class="s1">&#39;topic_words&#39;</span><span class="p">]</span>
    <span class="n">topics</span> <span class="o">=</span> <span class="n">topics</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">topic</span> <span class="ow">in</span> <span class="n">topics</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">topic</span><span class="p">)</span>
<span class="n">print_topics</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;people&#39;, &#39;texas&#39;, &#39;tropical&#39;, &#39;florida&#39;, &#39;storm&#39;]
[&#39;school&#39;, &#39;founded&#39;, &#39;wilson&#39;, &#39;harvard&#39;, &#39;including&#39;]
[&#39;members&#39;, &#39;association&#39;, &#39;society&#39;, &#39;member&#39;, &#39;group&#39;]
[&#39;summer&#39;, &#39;date&#39;, &#39;julian&#39;, &#39;years&#39;, &#39;george&#39;]
[&#39;war&#39;, &#39;general&#39;, &#39;battle&#39;, &#39;german&#39;, &#39;army&#39;]
[&#39;california&#39;, &#39;angeles&#39;, &#39;san&#39;, &#39;los&#39;, &#39;santa&#39;]
[&#39;miller&#39;, &#39;morris&#39;, &#39;2005&#39;, &#39;1999&#39;, &#39;time&#39;]
[&#39;game&#39;, &#39;season&#39;, &#39;team&#39;, &#39;points&#39;, &#39;games&#39;]
[&#39;evans&#39;, &#39;years&#39;, &#39;time&#39;, &#39;green&#39;, &#39;lebanon&#39;]
[&#39;und&#39;, &#39;der&#39;, &#39;die&#39;, &#39;van&#39;, &#39;von&#39;]
[&#39;wear&#39;, &#39;worn&#39;, &#39;made&#39;, &#39;green&#39;, &#39;top&#39;]
[&#39;2008&#39;, &#39;year&#39;, &#39;2007&#39;, &#39;2009&#39;, &#39;2010&#39;]
[&#39;oregon&#39;, &#39;magazine&#39;, &#39;year&#39;, &#39;portland&#39;, &#39;beer&#39;]
[&#39;network&#39;, &#39;news&#39;, &#39;radio&#39;, &#39;show&#39;, &#39;station&#39;]
[&#39;bridge&#39;, &#39;north&#39;, &#39;route&#39;, &#39;west&#39;, &#39;road&#39;]
[&#39;part&#39;, &#39;born&#39;, &#39;na&#39;, &#39;agent&#39;, &#39;valid&#39;]
[&#39;years&#39;, &#39;family&#39;, &#39;father&#39;, &#39;died&#39;, &#39;time&#39;]
[&#39;united&#39;, &#39;population&#39;, &#39;people&#39;, &#39;american&#39;, &#39;states&#39;]
[&#39;work&#39;, &#39;magazine&#39;, &#39;published&#39;, &#39;book&#39;, &#39;books&#39;]
[&#39;collection&#39;, &#39;museum&#39;, &#39;arts&#39;, &#39;art&#39;, &#39;work&#39;]
[&#39;white&#39;, &#39;black&#39;, &#39;red&#39;, &#39;flag&#39;, &#39;blue&#39;]
[&#39;aircraft&#39;, &#39;design&#39;, &#39;space&#39;, &#39;project&#39;, &#39;flight&#39;]
[&#39;trenn&#39;, &#39;phillip&#39;, &#39;nitra&#39;, &#39;koice&#39;, &#39;preov&#39;]
[&#39;engine&#39;, &#39;cars&#39;, &#39;car&#39;, &#39;race&#39;, &#39;model&#39;]
[&#39;london&#39;, &#39;duck&#39;, &#39;journal&#39;, &#39;philadelphia&#39;, &#39;york&#39;]
[&#39;english&#39;, &#39;word&#39;, &#39;language&#39;, &#39;languages&#39;, &#39;words&#39;]
[&#39;dna&#39;, &#39;cell&#39;, &#39;cells&#39;, &#39;enzyme&#39;, &#39;protein&#39;]
[&#39;2009&#39;, &#39;calendar&#39;, &#39;year&#39;, &#39;link&#39;, &#39;list&#39;]
[&#39;court&#39;, &#39;act&#39;, &#39;state&#39;, &#39;states&#39;, &#39;law&#39;]
[&#39;station&#39;, &#39;services&#39;, &#39;railway&#39;, &#39;line&#39;, &#39;service&#39;]
[&#39;cemetery&#39;, &#39;university&#39;, &#39;mexico&#39;, &#39;texas&#39;, &#39;corpus&#39;]
[&#39;film&#39;, &#39;worked&#39;, &#39;festival&#39;, &#39;award&#39;, &#39;awards&#39;]
[&#39;chinese&#39;, &#39;emperor&#39;, &#39;bc&#39;, &#39;king&#39;, &#39;empire&#39;]
[&#39;islands&#39;, &#39;region&#39;, &#39;ships&#39;, &#39;island&#39;, &#39;ship&#39;]
[&#39;water&#39;, &#39;park&#39;, &#39;lake&#39;, &#39;area&#39;, &#39;river&#39;]
[&#39;2007&#39;, &#39;2009&#39;, &#39;december&#39;, &#39;2010&#39;, &#39;2008&#39;]
[&#39;match&#39;, &#39;world&#39;, &#39;title&#39;, &#39;won&#39;, &#39;championship&#39;]
[&#39;msn&#39;, &#39;house&#39;, &#39;2010&#39;, &#39;skating&#39;, &#39;school&#39;]
[&#39;school&#39;, &#39;westfield&#39;, &#39;easy&#39;, &#39;british&#39;, &#39;2003&#39;]
[&#39;player&#39;, &#39;players&#39;, &#39;game&#39;, &#39;games&#39;, &#39;series&#39;]
[&#39;team&#39;, &#39;league&#39;, &#39;season&#39;, &#39;club&#39;, &#39;football&#39;]
[&#39;local&#39;, &#39;list&#39;, &#39;found&#39;, &#39;called&#39;, &#39;2010&#39;]
[&#39;plotdata&#39;, &#39;received&#39;, &#39;world&#39;, &#39;part&#39;, &#39;usa&#39;]
[&#39;income&#39;, &#39;population&#39;, &#39;18&#39;, &#39;years&#39;, &#39;age&#39;]
[&#39;youth&#39;, &#39;ross&#39;, &#39;griffin&#39;, &#39;joined&#39;, &#39;williams&#39;]
[&#39;south&#39;, &#39;government&#39;, &#39;international&#39;, &#39;countries&#39;, &#39;world&#39;]
[&#39;national&#39;, &#39;private&#39;, &#39;back&#39;, &#39;chicago&#39;, &#39;baldwin&#39;]
[&#39;cj&#39;, &#39;hill&#39;, &#39;morgan&#39;, &#39;davis&#39;, &#39;child&#39;]
[&#39;set&#39;, &#39;1&#39;, &#39;model&#39;, &#39;theory&#39;, &#39;number&#39;]
[&#39;social&#39;, &#39;people&#39;, &#39;time&#39;, &#39;form&#39;, &#39;work&#39;]
[&#39;french&#39;, &#39;de&#39;, &#39;spanish&#39;, &#39;france&#39;, &#39;la&#39;]
[&#39;area&#39;, &#39;city&#39;, &#39;building&#39;, &#39;town&#39;, &#39;built&#39;]
[&#39;food&#39;, &#39;popular&#39;, &#39;made&#39;, &#39;called&#39;, &#39;wine&#39;]
[&#39;canadian&#39;, &#39;british&#39;, &#39;ontario&#39;, &#39;canada&#39;, &#39;toronto&#39;]
[&#39;india&#39;, &#39;temple&#39;, &#39;khan&#39;, &#39;pakistan&#39;, &#39;indian&#39;]
[&#39;babylon&#39;, &#39;2004&#39;, &#39;area&#39;, &#39;class&#39;, &#39;5&#39;]
[&#39;water&#39;, &#39;process&#39;, &#39;nuclear&#39;, &#39;energy&#39;, &#39;form&#39;]
[&#39;international&#39;, &#39;2010&#39;, &#39;airport&#39;, &#39;airlines&#39;, &#39;airline&#39;]
[&#39;15&#39;, &#39;park&#39;, &#39;head&#39;, &#39;stone&#39;, &#39;2003&#39;]
[&#39;soviet&#39;, &#39;russia&#39;, &#39;poland&#39;, &#39;russian&#39;, &#39;polish&#39;]
[&#39;john&#39;, &#39;royal&#39;, &#39;william&#39;, &#39;sir&#39;, &#39;king&#39;]
[&#39;virginia&#39;, &#39;county&#39;, &#39;served&#39;, &#39;state&#39;, &#39;carolina&#39;]
[&#39;election&#39;, &#39;government&#39;, &#39;president&#39;, &#39;state&#39;, &#39;party&#39;]
[&#39;school&#39;, &#39;county&#39;, &#39;national&#39;, &#39;districts&#39;, &#39;district&#39;]
[&#39;group&#39;, &#39;war&#39;, &#39;force&#39;, &#39;air&#39;, &#39;aircraft&#39;]
[&#39;world&#39;, &#39;university&#39;, &#39;2010&#39;, &#39;chams&#39;, &#39;number&#39;]
[&#39;energy&#39;, &#39;power&#39;, &#39;system&#39;, &#39;time&#39;, &#39;light&#39;]
[&#39;bill&#39;, &#39;professor&#39;, &#39;degree&#39;, &#39;served&#39;, &#39;university&#39;]
[&#39;joseph&#39;, &#39;head&#39;, &#39;smiths&#39;, &#39;smith&#39;, &#39;school&#39;]
[&#39;birds&#39;, &#39;family&#39;, &#39;small&#39;, &#39;species&#39;, &#39;found&#39;]
[&#39;fat&#39;, &#39;2006&#39;, &#39;named&#39;, &#39;work&#39;, &#39;vincent&#39;]
[&#39;business&#39;, &#39;stores&#39;, &#39;oil&#39;, &#39;company&#39;, &#39;mine&#39;]
[&#39;2000&#39;, &#39;kitty&#39;, &#39;camp&#39;, &#39;moved&#39;, &#39;obesity&#39;]
[&#39;1994&#39;, &#39;christmas&#39;, &#39;world&#39;, &#39;national&#39;, &#39;minor&#39;]
[&#39;bishop&#39;, &#39;saint&#39;, &#39;church&#39;, &#39;st&#39;, &#39;century&#39;]
[&#39;band&#39;, &#39;released&#39;, &#39;album&#39;, &#39;music&#39;, &#39;song&#39;]
[&#39;made&#39;, &#39;zealand&#39;, &#39;australian&#39;, &#39;australia&#39;, &#39;south&#39;]
[&#39;system&#39;, &#39;software&#39;, &#39;data&#39;, &#39;systems&#39;, &#39;information&#39;]
[&#39;full&#39;, &#39;fair&#39;, &#39;philippines&#39;, &#39;manila&#39;, &#39;philippine&#39;]
[&#39;began&#39;, &#39;jones&#39;, &#39;minnesota&#39;, &#39;anderson&#39;, &#39;td&#39;]
[&#39;county&#39;, &#39;ireland&#39;, &#39;medal&#39;, &#39;irish&#39;, &#39;dublin&#39;]
[&#39;school&#39;, &#39;held&#39;, &#39;village&#39;, &#39;local&#39;, &#39;community&#39;]
[&#39;family&#39;, &#39;city&#39;, &#39;prison&#39;, &#39;police&#39;, &#39;york&#39;]
[&#39;al&#39;, &#39;bin&#39;, &#39;2001&#39;, &#39;joined&#39;, &#39;world&#39;]
[&#39;college&#39;, &#39;university&#39;, &#39;education&#39;, &#39;students&#39;, &#39;school&#39;]
[&#39;including&#39;, &#39;riders&#39;, &#39;ride&#39;, &#39;time&#39;, &#39;part&#39;]
[&#39;year&#39;, &#39;yugoslavia&#39;, &#39;serbian&#39;, &#39;albanian&#39;, &#39;serbia&#39;]
[&#39;shells&#39;, &#39;uk&#39;, &#39;school&#39;, &#39;austin&#39;, &#39;shell&#39;]
[&#39;world&#39;, &#39;birmingham&#39;, &#39;york&#39;, &#39;booth&#39;, &#39;free&#39;]
[&#39;show&#39;, &#39;role&#39;, &#39;episode&#39;, &#39;series&#39;, &#39;film&#39;]
[&#39;dr&#39;, &#39;care&#39;, &#39;health&#39;, &#39;medical&#39;, &#39;hospital&#39;]
[&#39;include&#39;, &#39;2007&#39;, &#39;norway&#39;, &#39;norwegian&#39;, &#39;city&#39;]
[&#39;religious&#39;, &#39;christian&#39;, &#39;church&#39;, &#39;god&#39;, &#39;jesus&#39;]
[&#39;nec&#39;, &#39;mori&#39;, &#39;miss&#39;, &#39;post&#39;, &#39;time&#39;]
[&#39;festival&#39;, &#39;theatre&#39;, &#39;dance&#39;, &#39;music&#39;, &#39;opera&#39;]
[&#39;business&#39;, &#39;company&#39;, &#39;financial&#39;, &#39;bank&#39;, &#39;million&#39;]
[&#39;man&#39;, &#39;tells&#39;, &#39;life&#39;, &#39;back&#39;, &#39;time&#39;]
[&#39;years&#39;, &#39;2007&#39;, &#39;post&#39;, &#39;croydon&#39;, &#39;day&#39;]
[&#39;las&#39;, &#39;scott&#39;, &#39;vegas&#39;, &#39;ranch&#39;, &#39;hotel&#39;]
[&#39;american&#39;, &#39;horses&#39;, &#39;horse&#39;, &#39;breed&#39;, &#39;stakes&#39;]
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>pred = m.predict(another_data)</p>
</div></blockquote>
<blockquote>
<div><p>pred = m.predict(another_data, output_type=’probabilities’)</p>
</div></blockquote>
<div class="section" id="initializing-from-other-models">
<h3>Initializing from other models<a class="headerlink" href="#initializing-from-other-models" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">dir</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;__class__&#39;,
 &#39;__delattr__&#39;,
 &#39;__dict__&#39;,
 &#39;__dir__&#39;,
 &#39;__doc__&#39;,
 &#39;__eq__&#39;,
 &#39;__format__&#39;,
 &#39;__ge__&#39;,
 &#39;__getattribute__&#39;,
 &#39;__gt__&#39;,
 &#39;__hash__&#39;,
 &#39;__init__&#39;,
 &#39;__le__&#39;,
 &#39;__lt__&#39;,
 &#39;__module__&#39;,
 &#39;__ne__&#39;,
 &#39;__new__&#39;,
 &#39;__proxy__&#39;,
 &#39;__reduce__&#39;,
 &#39;__reduce_ex__&#39;,
 &#39;__repr__&#39;,
 &#39;__setattr__&#39;,
 &#39;__sizeof__&#39;,
 &#39;__str__&#39;,
 &#39;__subclasshook__&#39;,
 &#39;__weakref__&#39;,
 &#39;_get&#39;,
 &#39;_get_queryable_methods&#39;,
 &#39;_get_summary_struct&#39;,
 &#39;_list_fields&#39;,
 &#39;_name&#39;,
 &#39;_native_name&#39;,
 &#39;_training_stats&#39;,
 &#39;alpha&#39;,
 &#39;beta&#39;,
 &#39;evaluate&#39;,
 &#39;get_topics&#39;,
 &#39;num_burnin&#39;,
 &#39;num_iterations&#39;,
 &#39;num_topics&#39;,
 &#39;predict&#39;,
 &#39;print_interval&#39;,
 &#39;save&#39;,
 &#39;summary&#39;,
 &#39;topics&#39;,
 &#39;training_iterations&#39;,
 &#39;training_time&#39;,
 &#39;validation_time&#39;,
 &#39;verbose&#39;,
 &#39;vocabulary&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="o">.</span><span class="n">vocabulary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dtype: str
Rows: 108205
[&#39;book&#39;, &#39;political&#39;, &#39;time&#39;, &#39;readers&#39;, &#39;individual&#39;, &#39;appeared&#39;, &#39;peikoff&#39;, &#39;concepts&#39;, &#39;100&#39;, &#39;picture&#39;, &#39;america&#39;, &#39;reviewers&#39;, &#39;philosopher&#39;, &#39;screenwriter&#39;, &#39;work&#39;, &#39;traditional&#39;, &#39;purged&#39;, &#39;ayn&#39;, &#39;york&#39;, &#39;articles&#39;, &#39;pharmacy&#39;, &#39;scholarship&#39;, &#39;2001&#39;, &#39;designed&#39;, &#39;permission&#39;, &#39;taking&#39;, &#39;historian&#39;, &#39;library&#39;, &#39;russian&#39;, &#39;extent&#39;, &#39;childhood&#39;, &#39;respondents&#39;, &#39;language&#39;, &#39;alisa&#39;, &#39;writing&#39;, &#39;union&#39;, &#39;libertarian&#39;, &#39;positive&#39;, &#39;jennifer&#39;, &#39;notes&#39;, &#39;line&#39;, &#39;burns&#39;, &#39;state&#39;, &#39;crimea&#39;, &#39;sciabarra&#39;, &#39;based&#39;, &#39;rights&#39;, &#39;life&#39;, &#39;shes&#39;, &#39;argument&#39;, &#39;nonfiction&#39;, &#39;rejection&#39;, &#39;allowed&#39;, &#39;reason&#39;, &#39;culture&#39;, &#39;closest&#39;, &#39;shrugged&#39;, &#39;free&#39;, &#39;january&#39;, &#39;success&#39;, &#39;living&#39;, &#39;robert&#39;, &#39;literary&#39;, &#39;animated&#39;, &#39;american&#39;, &#39;reviews&#39;, &#39;paterson&#39;, &#39;people&#39;, &#39;percent&#39;, &#39;house&#39;, &#39;academic&#39;, &#39;sacrificing&#39;, &#39;referred&#39;, &#39;broadway&#39;, &#39;fountainhead&#39;, &#39;lectures&#39;, &#39;john&#39;, &#39;inspiration&#39;, &#39;conditions&#39;, &#39;lifetime&#39;, &#39;written&#39;, &#39;1938&#39;, &#39;established&#39;, &#39;barbara&#39;, &#39;twelve&#39;, &#39;modern&#39;, &#39;final&#39;, &#39;intellectual&#39;, &#39;audience&#39;, &#39;stated&#39;, &#39;selfinterest&#39;, &#39;achievement&#39;, &#39;century&#39;, &#39;relationship&#39;, &#39;allowing&#39;, &#39;delivering&#39;, &#39;writers&#39;, &#39;influence&#39;, &#39;branden&#39;, &#39;film&#39;, ... ]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="o">.</span><span class="n">topics</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>108205
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m2</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">topic_model</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span>
                                 <span class="n">num_topics</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                 <span class="n">initial_topics</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">topics</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre>Initializing from provided topics and vocabulary.</pre></div><div class="output text_html"><pre>Learning a topic model</pre></div><div class="output text_html"><pre>       Number of documents     72269</pre></div><div class="output text_html"><pre>           Vocabulary size    171005</pre></div><div class="output text_html"><pre>   Running collapsed Gibbs sampling</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div><div class="output text_html"><pre>| Iteration | Elapsed Time  | Tokens/Second  | Est. Perplexity |</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div><div class="output text_html"><pre>| 10        | 2.99s         | 7.251e+06      | 0               |</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div></div>
</div>
</div>
<div class="section" id="seeding-the-model-with-prior-knowledge">
<h3>Seeding the model with prior knowledge<a class="headerlink" href="#seeding-the-model-with-prior-knowledge" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">associations</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">SFrame</span><span class="p">()</span>
<span class="n">associations</span><span class="p">[</span><span class="s1">&#39;word&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;recognition&#39;</span><span class="p">]</span>
<span class="n">associations</span><span class="p">[</span><span class="s1">&#39;topic&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m2</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">topic_model</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span>
                                 <span class="n">num_topics</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                 <span class="n">num_iterations</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                                 <span class="n">associations</span><span class="o">=</span><span class="n">associations</span><span class="p">,</span> 
                                 <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre>Learning a topic model</pre></div><div class="output text_html"><pre>       Number of documents     72269</pre></div><div class="output text_html"><pre>           Vocabulary size    171005</pre></div><div class="output text_html"><pre>   Running collapsed Gibbs sampling</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div><div class="output text_html"><pre>| Iteration | Elapsed Time  | Tokens/Second  | Est. Perplexity |</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div><div class="output text_html"><pre>| 10        | 2.10s         | 1.04058e+07    | 0               |</pre></div><div class="output text_html"><pre>| 20        | 3.97s         | 1.09325e+07    | 0               |</pre></div><div class="output text_html"><pre>| 30        | 5.79s         | 9.42067e+06    | 0               |</pre></div><div class="output text_html"><pre>| 40        | 7.66s         | 1.0637e+07     | 0               |</pre></div><div class="output text_html"><pre>| 50        | 9.51s         | 9.86708e+06    | 0               |</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m2</span><span class="o">.</span><span class="n">get_topics</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div style="max-height:1000px;max-width:1500px;overflow:auto;"><table frame="box" rules="cols">
    <tr>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">topic</th>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">word</th>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">score</th>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">line</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.0109206038501584</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">german</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.010542910113799127</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">de</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.010148794910641626</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">railway</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.010079824750089063</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">english</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.009242329943379372</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">chinese</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.008900763433976205</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">language</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.008654441432002766</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">china</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.008490226764020474</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">large</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.008004151346792889</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">russian</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.007705280651065117</td>
    </tr>
</table>
[200 rows x 3 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_topics</span><span class="p">(</span><span class="n">m2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;german&#39;, &#39;line&#39;, &#39;english&#39;, &#39;de&#39;, &#39;railway&#39;]
[&#39;son&#39;, &#39;time&#39;, &#39;book&#39;, &#39;life&#39;, &#39;john&#39;]
[&#39;role&#39;, &#39;episode&#39;, &#39;show&#39;, &#39;film&#39;, &#39;series&#39;]
[&#39;york&#39;, &#39;station&#39;, &#39;park&#39;, &#39;de&#39;, &#39;company&#39;]
[&#39;information&#39;, &#39;law&#39;, &#39;time&#39;, &#39;work&#39;, &#39;social&#39;]
[&#39;west&#39;, &#39;county&#39;, &#39;north&#39;, &#39;city&#39;, &#39;east&#39;]
[&#39;years&#39;, &#39;18&#39;, &#39;population&#39;, &#39;town&#39;, &#39;age&#39;]
[&#39;games&#39;, &#39;team&#39;, &#39;game&#39;, &#39;won&#39;, &#39;season&#39;]
[&#39;company&#39;, &#39;aircraft&#39;, &#39;air&#39;, &#39;force&#39;, &#39;division&#39;]
[&#39;india&#39;, &#39;art&#39;, &#39;century&#39;, &#39;roman&#39;, &#39;church&#39;]
[&#39;government&#39;, &#39;students&#39;, &#39;national&#39;, &#39;state&#39;, &#39;party&#39;]
[&#39;schools&#39;, &#39;college&#39;, &#39;university&#39;, &#39;school&#39;, &#39;high&#39;]
[&#39;series&#39;, &#39;world&#39;, &#39;back&#39;, &#39;king&#39;, &#39;time&#39;]
[&#39;services&#39;, &#39;system&#39;, &#39;service&#39;, &#39;million&#39;, &#39;engine&#39;]
[&#39;area&#39;, &#39;built&#39;, &#39;river&#39;, &#39;road&#39;, &#39;region&#39;]
[&#39;systems&#39;, &#39;set&#39;, &#39;number&#39;, &#39;system&#39;, &#39;data&#39;]
[&#39;water&#39;, &#39;small&#39;, &#39;species&#39;, &#39;food&#39;, &#39;found&#39;]
[&#39;league&#39;, &#39;year&#39;, &#39;club&#39;, &#39;song&#39;, &#39;time&#39;]
[&#39;released&#39;, &#39;music&#39;, &#39;songs&#39;, &#39;album&#39;, &#39;band&#39;]
[&#39;army&#39;, &#39;united&#39;, &#39;states&#39;, &#39;court&#39;, &#39;war&#39;]
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="id1">
<h2>阅读材料<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>https://apple.github.io/turicreate/docs/userguide/text/</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="12-topic-models-update.html" title="previous page">主题模型简介</a>
    <a class='right-next' id="next-link" href="13-recsys-intro.html" title="next page">第九章 推荐系统简介</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Cheng-Jun Wang<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>