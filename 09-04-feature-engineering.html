
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Feature Engineering &#8212; è®¡ç®—ä¼ æ’­å­¦</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="In Depth: Naive Bayes Classification" href="09-05-naive-bayes.html" />
    <link rel="prev" title="Hyperparameters and Model Validation" href="09-03-hyperparameters-and-model-validation.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/socrates_jump.gif" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">è®¡ç®—ä¼ æ’­å­¦</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   å¯»æ‰¾äººç±»ä¼ æ’­è¡Œä¸ºçš„åŸºå› 
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="01-intro2cjc.html">
   ç¬¬ä¸€ç«  è®¡ç®—ä¼ æ’­å­¦ç®€ä»‹
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="02-bigdata.html">
     æ•°æ®ç§‘å­¦çš„ç¼–ç¨‹å·¥å…·ï¼šå¤§æ•°æ®
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="03-python-intro.html">
   ç¬¬äºŒç«  æ•°æ®ç§‘å­¦çš„ç¼–ç¨‹å·¥å…·
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="0-jupyter-notebook.html">
     Jupyter Notebook
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="0-slides.html">
     ä½¿ç”¨Jupyteråˆ¶ä½œSlidesçš„ä»‹ç»
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="0-turicreate.html">
     Turicreate: Departure from Graphlab
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="0-matplotlib-chinese.html">
     è§£å†³Matplotlibç»˜å›¾æ˜¾ç¤ºä¸­æ–‡é—®é¢˜
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="04-crawler-beautifulsoup.html">
   ç¬¬ä¸‰ç«  æ•°æ®æŠ“å–
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="04-crawler-fact-checking.html">
     æŠ“å–å®æ—¶è¾Ÿè°£æ•°æ®
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04-crawler-13chambers.html">
     æŠ“å–ç½‘ç»œå°è¯´
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04-crawler-wechat.html">
     æŠ“å–å¾®ä¿¡å…¬ä¼—å·æ–‡ç« å†…å®¹
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04-crawler-douban.html">
     ä½¿ç”¨requests + XpathæŠ“å–è±†ç“£ç”µå½±æ•°æ®
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04-crawler-gov-report.html">
     æŠ“å–å†å±Šæ”¿åºœå·¥ä½œæŠ¥å‘Š
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04-crawler-cppcc.html">
     æŠ“å–æ±Ÿè‹çœæ”¿ååå¹´ææ¡ˆ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04-crawler-netease-music.html">
     æŠ“å–ç½‘æ˜“äº‘éŸ³ä¹çƒ­é—¨è¯„è®º
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04-crawler-selenium.html">
     ä½¿ç”¨Seleniumæ“çºµæµè§ˆå™¨
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04-crawler-selenium-music-history.html">
     æŠ“å–ç½‘æ˜“äº‘éŸ³ä¹ç”¨æˆ·çš„å¬æ­Œè®°å½•
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04-crawler-selenium-people-com-search.html">
     ä½¿ç”¨Seleniumæå–äººæ°‘ç½‘æœç´¢æ•°æ®
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04-crawler-tripadvisor.html">
     ä½¿ç”¨SeleniumæŠ“å–TripAdvisorç”¨æˆ·è¯„è®º
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04-crawler-pyppeteer.html">
     ä½¿ç”¨Pyppeteerå®ç°å¼‚æ­¥æŠ“å–!
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="06-data-cleaning-intro.html">
   ç¬¬å››ç«  æ•°æ®æ¸…æ´—
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="06-data-cleaning-preprocessing.html">
     å¯¹å¤§æ•°æ®è¿›è¡Œé¢„å¤„ç†
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06-data-cleaning-tweets.html">
     æ•°æ®æ¸…æ´—ä¹‹æ¨ç‰¹æ•°æ®
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06-data-cleaning-occupy-central-news.html">
     å¯¹å ä¸­æ–°é—»è¿›è¡Œæ•°æ®æ¸…æ´—
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06-data-cleaning-music-list.html">
     æ¸…æ´—éŸ³ä¹åˆ—è¡¨ğŸµ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06-data-cleaning-pandas.html">
     ä½¿ç”¨Pandasè¿›è¡Œæ•°æ®æ¸…æ´—
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="08-01-statistics-thinking.html">
   ç¬¬äº”ç«  ç»Ÿè®¡æ€ç»´
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="08-02-kl-divergence.html">
     KL Divergence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-02-linear-algebra.html">
     Linear algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-03-distributions.html">
     Distribution Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-03-probability.html">
     Probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-04-hypothesis-inference.html">
     Statistical Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-05-gradient-descent.html">
     Introduction to Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-06-regression.html">
     Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-06-statsmodels.html">
     Statistical Modeling with Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-07-analyzing-titanic-dataset.html">
     Logistic Regression of Titanic Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-07-covid19-pew-survey.html">
     Analysing the Pew Survey Data of COVID19
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-08-covid19-grangercausality.html">
     ç¤¾äº¤åª’ä½“å¯ä»¥é¢„æµ‹æ–°å† ç–«æƒ…å—ï¼Ÿ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08-09-survival-analysis.html">
     Survival Analysis with Python
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="09-01-machine-learning-with-sklearn.html">
   ç¬¬å…­ç«  ç¤¾ä¼šç§‘å­¦å®¶çš„æœºå™¨å­¦ä¹ 
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="09-03-hyperparameters-and-model-validation.html">
     Hyperparameters and Model Validation
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Feature Engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09-05-naive-bayes.html">
     In Depth: Naive Bayes Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09-06-linear-regression.html">
     In Depth: Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09-07-support-vector-machines.html">
     In-Depth: Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09-08-random-forests.html">
     In-Depth: Decision Trees and Random Forests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09-09-googleflustudy.html">
     Forecasting and nowcasting with Google Flu Trends
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09-10-future-employment.html">
     The future of employment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09-grf.html">
     Causal Forests
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="09-11-neural-network-intro.html">
   ç¬¬ä¸ƒç«  ç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ 
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="09-13-cnn.html">
     Convolutional Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09-14-rnn.html">
     Sequnce Modeling: Recurrent and Recursive Nets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09-12-hand-written-digits.html">
     Recognizing Hand-Written Digits with Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09-15-cifar10.html">
     ä½¿ç”¨CNNå¯¹CIFAR10å›¾åƒè¿›è¡Œåˆ†ç±»
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09-16-pytorch_vgg_pretrained.html">
     VGG16é¢„è®­ç»ƒæ¨¡å‹
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="10-text-minning-gov-report.html">
   ç¬¬å…«ç«  æ–‡æœ¬æŒ–æ˜
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="10-word2vec.html">
     è¯å‘é‡æ¨¡å‹ç®€ä»‹
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10-doc2vec.html">
     Doc2Vec
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11-1-sentiment-analysis-with-dict.html">
     åŸºäºå­—å…¸çš„æƒ…æ„Ÿåˆ†æ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11-2-emotion-dict.html">
     å¤§è¿ç†å·¥å¤§å­¦ä¸­æ–‡æƒ…æ„Ÿè¯æ±‡
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11-3-NRC-Chinese-dict.html">
     åŸºäºNRCå­—å…¸çš„æƒ…æ„Ÿåˆ†æ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11-3-textblob.html">
     åˆ©ç”¨textblobè¿›è¡Œæƒ…æ„Ÿåˆ†æ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11-4-sentiment-classifier.html">
     åŸºäºæœºå™¨å­¦ä¹ çš„æƒ…æ„Ÿåˆ†æ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11-5-LIWC.html">
     LIWC: Linguistic Inquiry and Word Count  analyzer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12-topic-models-update.html">
     ä¸»é¢˜æ¨¡å‹ç®€ä»‹
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12-topic-models-with-turicreate.html">
     ä½¿ç”¨Turicreateå»ºç«‹ä¸»é¢˜æ¨¡å‹
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="13-recsys-intro.html">
   ç¬¬ä¹ç«  æ¨èç³»ç»Ÿç®€ä»‹
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="13-recsys-latent-factor-model.html">
     Latent Factor Recommender System
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13-recsys-intro-surprise.html">
     ä½¿ç”¨Surpriseæ„å»ºæ¨èç³»ç»Ÿ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14-millionsong.html">
     ä½¿ç”¨Turicreateè¿›è¡ŒéŸ³ä¹æ¨è
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14-movielens.html">
     ä½¿ç”¨Turicreateè¿›è¡Œç”µå½±æ¨è
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="15-network-science-intro.html">
   ç¬¬åç«  ç½‘ç»œç§‘å­¦ç®€ä»‹
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="16-network-science-models.html">
     ç½‘ç»œç§‘å­¦æ¨¡å‹
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="17-networkx.html">
     ä½¿ç”¨NetworkXåˆ†æç½‘ç»œ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="18-02-network-diffusion.html">
     Simulating Network Diffusion With NDlib
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="18-03-network-epidemics.html">
     Epidemics on Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="18-04-seir-hcd-model.html">
     SEIR-HCD Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="18-network-ergm-siena.html">
     Social Network Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="18-network-analysis-of-tianya-bbs.html">
     å¤©æ¶¯è®ºå›çš„å›å¸–ç½‘ç»œåˆ†æ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="19-facebook-ego-netwrok-visualization.html">
     å¯è§†åŒ–Facebookç¤¾äº¤ç½‘ç»œ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="reproducing_hidagos_result.html">
     4 digit sitc trade data
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="19-visualization-with-seaborn.html">
   ç¬¬åä¸€ç«  å¯è§†åŒ–
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="19-visualization-scientific-plot.html">
     Matplotlibçš„ç§‘å­¦ç»˜å›¾æ ·å¼
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="19-visualization-with-pyecharts.html">
     ä½¿ç”¨PyEchartsè¿›è¡Œå¯è§†åŒ–
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="19-visualization-plotly-express.html">
     Plotly Express in Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="19-visualization-maps-using-folium.html">
     ä½¿ç”¨foliumåšåœ°å›¾å¯è§†åŒ–
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="19-visualization-datashader.html">
     ä½¿ç”¨Datashaderå¯è§†åŒ–åœ°ç†ä¿¡æ¯
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="19-visualization-datapane.html">
     ä½¿ç”¨Datapaneåˆ¶ä½œæ•°æ®æŠ¥å‘Š
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Pantheon.html">
     ä¸‡ç¥æ®¿é¡¹ç›®ï¼ˆPantheon Projectï¼‰
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/09-04-feature-engineering.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/chengjun/mybook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/chengjun/mybook/issues/new?title=Issue%20on%20page%20%2F09-04-feature-engineering.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/chengjun/mybook/main?urlpath=tree/09-04-feature-engineering.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/chengjun/mybook/blob/main/09-04-feature-engineering.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#categorical-features">
   Categorical Features
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#notice">
   Notice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-features">
   Text Features
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#image-features">
   Image Features
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#derived-features">
   Derived Features
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imputation-of-missing-data">
   Imputation of Missing Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-pipelines">
   Feature Pipelines
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="feature-engineering">
<h1>Feature Engineering<a class="headerlink" href="#feature-engineering" title="Permalink to this headline">Â¶</a></h1>
<!--BOOK_INFORMATION-->
<p><em>This notebook contains an excerpt from the <a class="reference external" href="http://shop.oreilly.com/product/0636920034919.do">Python Data Science Handbook</a> by Jake VanderPlas; the content is available <a class="reference external" href="https://github.com/jakevdp/PythonDataScienceHandbook">on GitHub</a>.</em></p>
<p><em>The text is released under the <a class="reference external" href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode">CC-BY-NC-ND license</a>, and code is released under the <a class="reference external" href="https://opensource.org/licenses/MIT">MIT license</a>. If you find this content useful, please consider supporting the work by <a class="reference external" href="http://shop.oreilly.com/product/0636920034919.do">buying the book</a>!</em></p>
<p>numerical data in a tidy, <code class="docutils literal notranslate"><span class="pre">[n_samples,</span> <span class="pre">n_features]</span></code> format VS. Real world.</p>
<p><strong>Feature engineering</strong> taking whatever information you have about your problem and turning it into numbers that you can use to build your <code class="docutils literal notranslate"><span class="pre">feature</span> <span class="pre">matrix</span></code>.</p>
<p>In this section, we will cover a few common examples of feature engineering tasks:</p>
<ul class="simple">
<li><p>features for representing <em>categorical data</em>,</p></li>
<li><p>features for representing <em>text</em>, and</p></li>
<li><p>features for representing <em>images</em>.</p></li>
<li><p><em>derived features</em> for increasing model complexity</p></li>
<li><p><em>imputation</em> of missing data.</p></li>
</ul>
<p>Often this process is known as <em>vectorization</em></p>
<ul class="simple">
<li><p>as it involves converting arbitrary data into well-behaved vectors.</p></li>
</ul>
<div class="section" id="categorical-features">
<h2>Categorical Features<a class="headerlink" href="#categorical-features" title="Permalink to this headline">Â¶</a></h2>
<p>One common type of non-numerical data is <em>categorical</em> data.</p>
<p>Housing prices,</p>
<ul class="simple">
<li><p>â€œpriceâ€ and â€œroomsâ€</p></li>
<li><p>â€œneighborhoodâ€ information.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s1">&#39;price&#39;</span><span class="p">:</span> <span class="mi">850000</span><span class="p">,</span> <span class="s1">&#39;rooms&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;neighborhood&#39;</span><span class="p">:</span> <span class="s1">&#39;Queen Anne&#39;</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;price&#39;</span><span class="p">:</span> <span class="mi">700000</span><span class="p">,</span> <span class="s1">&#39;rooms&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;neighborhood&#39;</span><span class="p">:</span> <span class="s1">&#39;Fremont&#39;</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;price&#39;</span><span class="p">:</span> <span class="mi">650000</span><span class="p">,</span> <span class="s1">&#39;rooms&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;neighborhood&#39;</span><span class="p">:</span> <span class="s1">&#39;Wallingford&#39;</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;price&#39;</span><span class="p">:</span> <span class="mi">600000</span><span class="p">,</span> <span class="s1">&#39;rooms&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;neighborhood&#39;</span><span class="p">:</span> <span class="s1">&#39;Fremont&#39;</span><span class="p">}</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>You might be tempted to encode this data with a straightforward numerical mapping:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;Queen Anne&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Fremont&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;Wallingford&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">};</span>
<span class="c1"># It turns out that this is not generally a useful approach</span>
</pre></div>
</div>
</div>
</div>
<p>A fundamental assumption: numerical features reflect algebraic quantities.</p>
<ul class="simple">
<li><p><em>Queen Anne &lt; Fremont &lt; Wallingford</em></p></li>
<li><p><em>Wallingford - Queen Anne = Fremont</em></p></li>
</ul>
<p>It does not make much sense.</p>
<p><strong>One-hot encoding</strong> (Dummy coding) effectively creates extra columns indicating the presence or absence of a category with a value of 1 or 0, respectively.</p>
<ul class="simple">
<li><p>When your data comes as a list of dictionaries</p>
<ul>
<li><p>Scikit-Learnâ€™s <code class="docutils literal notranslate"><span class="pre">DictVectorizer</span></code> will do this for you:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction</span> <span class="kn">import</span> <span class="n">DictVectorizer</span>
<span class="n">vec</span> <span class="o">=</span> <span class="n">DictVectorizer</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span> <span class="p">)</span>
<span class="n">vec</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[     0,      1,      0, 850000,      4],
       [     1,      0,      0, 700000,      3],
       [     0,      0,      1, 650000,      3],
       [     1,      0,      0, 600000,      2]], dtype=int64)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="notice">
<h2>Notice<a class="headerlink" href="#notice" title="Permalink to this headline">Â¶</a></h2>
<ul class="simple">
<li><p>the â€˜neighborhoodâ€™ column has been expanded into <strong>three</strong> separate columns (why not four?)</p></li>
<li><p>representing the three neighborhood labels, and that each row has a 1 in the column associated with its neighborhood.</p></li>
</ul>
<p>To see the meaning of each column, you can inspect the feature names:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vec</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;neighborhood=Fremont&#39;,
 &#39;neighborhood=Queen Anne&#39;,
 &#39;neighborhood=Wallingford&#39;,
 &#39;price&#39;,
 &#39;rooms&#39;]
</pre></div>
</div>
</div>
</div>
<p>There is one clear disadvantage of this approach:</p>
<ul class="simple">
<li><p>if your category has many possible values, this can <em>greatly</em> increase the size of your dataset.</p>
<ul>
<li><p>However, because the encoded data contains mostly zeros, a sparse output can be a very efficient solution:</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vec</span> <span class="o">=</span> <span class="n">DictVectorizer</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="n">vec</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;4x5 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;
	with 12 stored elements in Compressed Sparse Row format&gt;
</pre></div>
</div>
</div>
</div>
<p>Many (though not yet all) of the Scikit-Learn estimators accept such sparse inputs when fitting and evaluating models.</p>
<p>two additional tools that Scikit-Learn includes to support this type of encoding:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sklearn.preprocessing.OneHotEncoder</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sklearn.feature_extraction.FeatureHasher</span></code></p></li>
</ul>
</div>
<div class="section" id="text-features">
<h2>Text Features<a class="headerlink" href="#text-features" title="Permalink to this headline">Â¶</a></h2>
<p>Another common need in feature engineering is to convert text to a set of representative numerical values.</p>
<p>Most automatic mining of social media data relies on some form of encoding the text as numbers.</p>
<ul class="simple">
<li><p>One of the simplest methods of encoding data is by <em>word counts</em>:</p>
<ul>
<li><p>you take each snippet of text, count the occurrences of each word within it, and put the results in a table.</p></li>
</ul>
</li>
</ul>
<p>For example, consider the following set of three phrases:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;problem of evil&#39;</span><span class="p">,</span>
          <span class="s1">&#39;evil queen&#39;</span><span class="p">,</span>
          <span class="s1">&#39;horizon problem&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>For a vectorization of this data based on word count, we could construct a column representing the word â€œproblem,â€ the word â€œevil,â€ the word â€œhorizon,â€ and so on.</p>
<p>While doing this by hand would be possible, the tedium can be avoided by using Scikit-Learnâ€™s <code class="docutils literal notranslate"><span class="pre">CountVectorizer</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vec</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<span class="n">X</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;3x5 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39;
	with 7 stored elements in Compressed Sparse Row format&gt;
</pre></div>
</div>
</div>
</div>
<p>The result is a sparse matrix recording the number of times each word appears;</p>
<p>it is easier to inspect if we convert this to a <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> with labeled columns:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">vec</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>evil</th>
      <th>horizon</th>
      <th>of</th>
      <th>problem</th>
      <th>queen</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Problem: The raw word counts put too much weight on words that appear very frequently.</p>
<p><em>term frequency-inverse document frequency</em> (<strong>TFâ€“IDF</strong>) weights the word counts by a measure of how often they appear in the documents.</p>
<p>The syntax for computing these features is similar to the previous example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="n">vec</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">vec</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">vec</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/datalab/Applications/anaconda/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1015: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  if hasattr(X, &#39;dtype&#39;) and np.issubdtype(X.dtype, np.float):
</pre></div>
</div>
<div class="output text_html"><div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>evil</th>
      <th>horizon</th>
      <th>of</th>
      <th>problem</th>
      <th>queen</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.517856</td>
      <td>0.000000</td>
      <td>0.680919</td>
      <td>0.517856</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.605349</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.795961</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000000</td>
      <td>0.795961</td>
      <td>0.000000</td>
      <td>0.605349</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>For an example of using TF-IDF in a classification problem, see <strong>In Depth: Naive Bayes Classification</strong>).</p>
</div>
<div class="section" id="image-features">
<h2>Image Features<a class="headerlink" href="#image-features" title="Permalink to this headline">Â¶</a></h2>
<p>The simplest approach is what we used for the digits data in <strong>Introducing Scikit-Learn</strong>: <strong>simply using the pixel values themselves</strong>.</p>
<ul class="simple">
<li><p>But depending on the application, such approaches may not be optimal.</p></li>
<li><p>A comprehensive summary of feature extraction techniques for images in the <a class="reference external" href="http://scikit-image.org">Scikit-Image project</a>.</p></li>
</ul>
<p>For one example of using Scikit-Learn and Scikit-Image together, see <strong>Feature Engineering: Working with Images</strong>.</p>
</div>
<div class="section" id="derived-features">
<h2>Derived Features<a class="headerlink" href="#derived-features" title="Permalink to this headline">Â¶</a></h2>
<p>Another useful type of feature is one that is mathematically derived from some input features.</p>
<p>We saw an example of this in <strong>Hyperparameters and Model Validation</strong> when we constructed <em>polynomial features</em> from our input data.</p>
<p>To convert a linear regression into a polynomial regression</p>
<ul class="simple">
<li><p>not by changing the model</p></li>
<li><p>but by transforming the input!</p>
<ul>
<li><p><em>basis function regression</em>, and is explored further in <strong>In Depth: Linear Regression</strong>.</p></li>
</ul>
</li>
</ul>
<p>For example, this data clearly cannot be well described by a straight line:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/09-04-feature-engineering_25_0.png" src="_images/09-04-feature-engineering_25_0.png" />
</div>
</div>
<p>Still, we can fit a line to the data using <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code> and get the optimal result:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">yfit</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">yfit</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/09-04-feature-engineering_27_0.png" src="_images/09-04-feature-engineering_27_0.png" />
</div>
</div>
<p>We need a more sophisticated model to describe the relationship between $x$ and $y$.</p>
<ul class="simple">
<li><p>One approach to this is to transform the data,</p>
<ul>
<li><p>adding extra columns of features to drive more flexibility in the model.</p></li>
</ul>
</li>
</ul>
<p>For example, we can add polynomial features to the data this way:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[  1.   1.   1.]
 [  2.   4.   8.]
 [  3.   9.  27.]
 [  4.  16.  64.]
 [  5.  25. 125.]]
</pre></div>
</div>
</div>
</div>
<p>The derived feature matrix has one column representing $x$, and a second column representing $x^2$, and a third column representing $x^3$.
Computing a linear regression on this expanded input gives a much closer fit to our data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">yfit</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">yfit</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/09-04-feature-engineering_31_0.png" src="_images/09-04-feature-engineering_31_0.png" />
</div>
</div>
<p>This idea of improving a model not by changing the model, but by transforming the inputs, is fundamental to many of the more powerful machine learning methods.</p>
<ul class="simple">
<li><p>We explore this idea further in <strong>In Depth: Linear Regression</strong> in the context of <em>basis function regression</em>.</p></li>
<li><p>More generally, this is one motivational path to the powerful set of techniques known as <em>kernel methods</em>, which we will explore in <strong>In-Depth: Support Vector Machines</strong>.</p></li>
</ul>
</div>
<div class="section" id="imputation-of-missing-data">
<h2>Imputation of Missing Data<a class="headerlink" href="#imputation-of-missing-data" title="Permalink to this headline">Â¶</a></h2>
<p>Another common need in feature engineering is handling of missing data.</p>
<ul class="simple">
<li><p><strong>Handling Missing Data</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">NaN</span></code> value is used to mark missing values.</p></li>
</ul>
</li>
</ul>
<p>For example, we might have a dataset that looks like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">nan</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="n">nan</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>   <span class="mi">3</span>  <span class="p">],</span>
              <span class="p">[</span> <span class="mi">3</span><span class="p">,</span>   <span class="mi">7</span><span class="p">,</span>   <span class="mi">9</span>  <span class="p">],</span>
              <span class="p">[</span> <span class="mi">3</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">2</span>  <span class="p">],</span>
              <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>   <span class="n">nan</span><span class="p">,</span> <span class="mi">6</span>  <span class="p">],</span>
              <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>   <span class="mi">8</span><span class="p">,</span>   <span class="mi">1</span>  <span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">14</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>When applying a typical machine learning model to such data, we will need to first replace such missing data with some appropriate fill value.</p>
<p>This is known as <em>imputation</em> of missing values</p>
<ul class="simple">
<li><p>simple method, e.g., replacing missing values with the mean of the column</p></li>
<li><p>sophisticated method, e.g., using matrix completion or a robust model to handle such data</p>
<ul>
<li><p>It tends to be very application-specific, and we wonâ€™t dive into them here.</p></li>
</ul>
</li>
</ul>
<p>For a baseline imputation approach, using the mean, median, or most frequent value, Scikit-Learn provides the <code class="docutils literal notranslate"><span class="pre">Imputer</span></code> class:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">Imputer</span>
<span class="n">imp</span> <span class="o">=</span> <span class="n">Imputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">imp</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[4.5, 0. , 3. ],
       [3. , 7. , 9. ],
       [3. , 5. , 2. ],
       [4. , 5. , 6. ],
       [8. , 8. , 1. ]])
</pre></div>
</div>
</div>
</div>
<p>We see that in the resulting data, the two missing values have been replaced with the mean of the remaining values in the column.</p>
<p>This imputed data can then be fed directly into, for example, a <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code> estimator:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([13.14869292, 14.3784627 , -1.15539732, 10.96606197, -5.33782027])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="feature-pipelines">
<h2>Feature Pipelines<a class="headerlink" href="#feature-pipelines" title="Permalink to this headline">Â¶</a></h2>
<p>With any of the preceding examples, it can quickly become tedious to do the transformations by hand, especially if you wish to string together multiple steps.</p>
<p>For example, we might want a processing pipeline that looks something like this:</p>
<ol class="simple">
<li><p>Impute missing values using the mean</p></li>
<li><p>Transform features to quadratic</p></li>
<li><p>Fit a linear regression</p></li>
</ol>
<p>To streamline this type of processing pipeline, Scikit-Learn provides a <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> object, which can be used as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">Imputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">),</span>
                      <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
                      <span class="n">LinearRegression</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>This pipeline looks and acts like a standard Scikit-Learn object, and will apply all the specified steps to any input data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># X with missing values, from above</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[14 16 -1  8 -5]
[14. 16. -1.  8. -5.]
</pre></div>
</div>
</div>
</div>
<p>All the steps of the model are applied automatically.</p>
<p>Notice that for the simplicity of this demonstration, weâ€™ve applied the model to the data it was trained on;</p>
<ul class="simple">
<li><p>this is why it was able to perfectly predict the result (refer back to <strong>Hyperparameters and Model Validation</strong> for further discussion of this).</p></li>
</ul>
<p>For some examples of Scikit-Learn pipelines in action, see the following section on naive Bayes classification, as well as <strong>In Depth: Linear Regression</strong>, and **In-Depth: Support Vector Machines.</p>
<p><img alt="" src="_images/end.png" /></p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="09-03-hyperparameters-and-model-validation.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Hyperparameters and Model Validation</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="09-05-naive-bayes.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">In Depth: Naive Bayes Classification</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Cheng-Jun Wang<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>