

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>使用Turicreate建立主题模型 &#8212; 计算传播学</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '12-topic-models-with-turicreate';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="第九章 推荐系统简介" href="13-recsys-intro.html" />
    <link rel="prev" title="主题模型简介" href="12-topic-models-update.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/socrates_jump.gif" class="logo__image only-light" alt="计算传播学 - Home"/>
    <script>document.write(`<img src="_static/socrates_jump.gif" class="logo__image only-dark" alt="计算传播学 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    寻找人类传播行为的基因
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="01-intro2cjc.html">第一章 计算传播学简介</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="02-bigdata.html">数据科学的编程工具：大数据</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="03-python-intro.html">第二章 数据科学的编程工具</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="0-jupyter-notebook.html">Jupyter Notebook</a></li>
<li class="toctree-l2"><a class="reference internal" href="0-chatgpt.html">Using ChatGPT to Learn Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="0-iching.html">iching: A python package of I Ching</a></li>
<li class="toctree-l2"><a class="reference internal" href="01-recombination.html">计算思维：通过拆解和重组学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="0-slides.html">使用Jupyter制作Slides的介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="0-turicreate.html">Turicreate: Departure from Graphlab</a></li>
<li class="toctree-l2"><a class="reference internal" href="0-matplotlib-chinese.html">解决Matplotlib绘图显示中文问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="03-UK-MPS-Scandal.html">案例：2009年英国国会议员开支丑闻</a></li>
<li class="toctree-l2"><a class="reference internal" href="03-umbrella-of-love.html">案例：《转角遇到爱》背后的数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="03-who-runs-China.html">案例：Who runs China？背后的数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="03-gdelt.html">Gdelt Dataset: Events, Mentions, and Global Knowledge Graph</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="04-crawler-beautifulsoup.html">第三章 数据抓取</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-fact-checking.html">抓取实时辟谣数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-13chambers.html">抓取网络小说</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-wechat.html">抓取微信公众号文章内容</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-douban.html">使用requests + Xpath抓取豆瓣电影数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-gov-report.html">抓取历届政府工作报告</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-cppcc.html">抓取江苏省政协十年提案</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-netease-music.html">抓取网易云音乐热门评论</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-selenium.html">使用Selenium操纵浏览器</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-selenium-music-history.html">抓取网易云音乐用户的听歌记录</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-selenium-people-com-search.html">使用Selenium提取人民网搜索数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-tripadvisor.html">使用Selenium抓取TripAdvisor用户评论</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-pyppeteer.html">使用Pyppeteer实现异步抓取!</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-weibo.html">轻型微博爬虫</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-crawler-snscrape-twitter.html">snscrape</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="06-data-cleaning-intro.html">第四章 数据清洗</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="06-data-cleaning-preprocessing.html">对大数据进行预处理</a></li>
<li class="toctree-l2"><a class="reference internal" href="06-data-cleaning-tweets.html">数据清洗之推特数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="06-data-cleaning-occupy-central-news.html">对占中新闻进行数据清洗</a></li>
<li class="toctree-l2"><a class="reference internal" href="06-data-cleaning-music-list.html">清洗音乐列表🎵</a></li>
<li class="toctree-l2"><a class="reference internal" href="06-data-cleaning-pandas.html">使用Pandas进行数据清洗</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="08-01-statistics-thinking.html">第五章 统计思维</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="08-02-kl-divergence.html">KL Divergence</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-02-linear-algebra.html">Linear algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-03-distributions.html">Distribution Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-03-probability.html">Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-04-hypothesis-inference.html">Statistical Hypothesis Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-05-gradient-descent.html">Introduction to Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-06-regression.html">Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-06-statsmodels.html">Statistical Modeling with Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-07-analyzing-titanic-dataset.html">Logistic Regression of Titanic Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-07-covid19-pew-survey.html">Analysing the Pew Survey Data of COVID19</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-11-cfps-survey-analysis.html">中国家庭追踪调查2018</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-08-covid19-grangercausality.html">社交媒体可以预测新冠疫情吗？</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-09-survival-analysis.html">Survival Analysis with Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="08-10-dowhy-estimation-methods.html">The Book of Why</a></li>

</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="09-01-machine-learning-with-sklearn.html">第六章 社会科学家的机器学习</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="09-03-hyperparameters-and-model-validation.html">Hyperparameters and Model Validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-04-feature-engineering.html">Feature Engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-05-naive-bayes.html">In Depth: Naive Bayes Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-06-linear-regression.html">In Depth: Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-07-support-vector-machines.html">In-Depth: Support Vector Machines</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-08-random-forests.html">In-Depth: Decision Trees and Random Forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-09-googleflustudy.html">Forecasting and nowcasting with Google Flu Trends</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-10-future-employment.html">The future of employment</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-grf.html">Causal Forests</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="09-11-neural-network-intro.html">第七章 神经网络与深度学习</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="09-13-cnn.html">Convolutional Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-14-rnn.html">Sequnce Modeling: Recurrent and Recursive Nets</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-12-hand-written-digits.html">Recognizing Hand-Written Digits with Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-15-cifar10.html">使用CNN对CIFAR10图像进行分类</a></li>
<li class="toctree-l2"><a class="reference internal" href="09-16-pytorch_vgg_pretrained.html">VGG16预训练模型</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="10-text-mining-gov-report.html">第八章 文本挖掘</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="10-word2vec.html">词向量模型简介</a></li>
<li class="toctree-l2"><a class="reference internal" href="10-doc2vec.html">Doc2Vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-1-sentiment-analysis-with-dict.html">基于字典的情感分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-2-emotion-dict.html">大连理工大学中文情感词汇</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-3-NRC-Chinese-dict.html">基于NRC字典的情感分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-3-textblob.html">利用textblob进行情感分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-4-sentiment-classifier.html">基于机器学习的情感分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-5-LIWC.html">LIWC: Linguistic Inquiry and Word Count  analyzer</a></li>
<li class="toctree-l2"><a class="reference internal" href="11-6-Chinese-moral-foundation-dict.html">Chinese Moral Foundation Dictionary 2.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="12-topic-models-update.html">主题模型简介</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">使用Turicreate建立主题模型</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="13-recsys-intro.html">第九章 推荐系统简介</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="13-recsys-latent-factor-model.html">Latent Factor Recommender System</a></li>
<li class="toctree-l2"><a class="reference internal" href="13-recsys-intro-surprise.html">使用Surprise构建推荐系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="14-millionsong.html">使用Turicreate进行音乐推荐</a></li>
<li class="toctree-l2"><a class="reference internal" href="14-movielens.html">使用Turicreate进行电影推荐</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="15-network-science-intro.html">第十章 网络科学简介</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="16-network-science-models.html">网络科学模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="17-networkx.html">使用NetworkX分析网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="18-02-network-diffusion.html">Simulating Network Diffusion With NDlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="18-03-network-epidemics.html">Epidemics on Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="18-04-seir-hcd-model.html">SEIR-HCD Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="18-network-ergm-siena.html">Social Network Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="18-network-weibo-hot-search.html">微博热搜分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="18-network-analysis-of-tianya-bbs.html">天涯论坛的回帖网络分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-facebook-ego-netwrok-visualization.html">可视化Facebook社交网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="18-network-ecomplexity.html">Economic Complexity and Product Complexity</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="19-visualization-with-seaborn.html">第十一章 可视化</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-matplotlib-colormap.html">Qualitative Colormaps in Matplotlib Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-scientific-plot.html">Matplotlib的科学绘图样式</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-with-pyecharts.html">使用PyEcharts进行可视化</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-plotly-express.html">Plotly Express in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-maps-using-folium.html">使用folium做地图可视化</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-datashader.html">使用Datashader可视化地理信息</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-datapane.html">使用Datapane制作数据报告</a></li>
<li class="toctree-l2"><a class="reference internal" href="19-visualization-pantheon.html">万神殿项目（Pantheon Project）</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/chengjun/mybook/blob/main/12-topic-models-with-turicreate.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/chengjun/mybook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/chengjun/mybook/issues/new?title=Issue%20on%20page%20%2F12-topic-models-with-turicreate.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/12-topic-models-with-turicreate.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>使用Turicreate建立主题模型</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transformations">Transformations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-cleaning">Text Cleaning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topic-modeling">Topic modeling</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#initializing-from-other-models">Initializing from other models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seeding-the-model-with-prior-knowledge">Seeding the model with prior knowledge</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">阅读材料</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="turicreate">
<h1>使用Turicreate建立主题模型<a class="headerlink" href="#turicreate" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">turicreate</span> <span class="k">as</span> <span class="nn">tc</span>
</pre></div>
</div>
</div>
</div>
<p>Download Data: <del><a class="reference external" href="http://select.cs.cmu.edu/code/graphlab/datasets/wikipedia/wikipedia_raw/w15">http://select.cs.cmu.edu/code/graphlab/datasets/wikipedia/wikipedia_raw/w15</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sf</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">SFrame</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;/Users/datalab/bigdata/cjc/w15&quot;</span><span class="p">,</span> 
                              <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre>Finished parsing file /Users/datalab/bigdata/cjc/w15</pre></div><div class="output text_html"><pre>Parsing completed. Parsed 100 lines in 0.447868 secs.</pre></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>------------------------------------------------------
Inferred types from first 100 line(s) of file as 
column_type_hints=[str]
If parsing fails due to incorrect types, you can correct
the inferred type list above and pass it to read_csv in
the column_type_hints argument
------------------------------------------------------
</pre></div>
</div>
<div class="output text_html"><pre>Read 12278 lines. Lines per second: 16914.5</pre></div><div class="output text_html"><pre>Finished parsing file /Users/datalab/bigdata/cjc/w15</pre></div><div class="output text_html"><pre>Parsing completed. Parsed 72269 lines in 1.73223 secs.</pre></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div style="max-height:1000px;max-width:1500px;overflow:auto;"><table frame="box" rules="cols">
    <tr>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">X1</th>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">aynrand born and educated<br>in russia rand migrated ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">asphalt in american<br>english asphalt or ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">actinopterygii the<br>actinopterygii consti ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">altaiclanguages these<br>language families share ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">argon the name argon is<br>derived from the greek ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">augustderleth a 1938<br>guggenheim fellow der ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">amateur amateurism can be<br>seen in both a negative ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">assemblyline an assembly<br>line is a manufacturing ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">astronomicalunit an<br>astronomical unit ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">abbess an abbess latin<br>abbatissa feminine form ...</td>
    </tr>
</table>
[72269 rows x 1 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.
</div></div></div>
</div>
<section id="transformations">
<h2>Transformations<a class="headerlink" href="#transformations" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://dato.com/learn/userguide/text/analysis.html">https://dato.com/learn/userguide/text/analysis.html</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">dir</span><span class="p">(</span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;X1&#39;</span><span class="p">])</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;_SArray__check_min_observations&#39;,
 &#39;__abs__&#39;,
 &#39;__add__&#39;,
 &#39;__and__&#39;,
 &#39;__bool__&#39;,
 &#39;__class__&#39;,
 &#39;__contains__&#39;,
 &#39;__copy__&#39;,
 &#39;__deepcopy__&#39;,
 &#39;__delattr__&#39;,
 &#39;__dir__&#39;,
 &#39;__div__&#39;,
 &#39;__doc__&#39;,
 &#39;__eq__&#39;,
 &#39;__floordiv__&#39;,
 &#39;__format__&#39;,
 &#39;__ge__&#39;,
 &#39;__get_content_identifier__&#39;,
 &#39;__getattribute__&#39;,
 &#39;__getitem__&#39;,
 &#39;__gt__&#39;,
 &#39;__has_size__&#39;,
 &#39;__hash__&#39;,
 &#39;__init__&#39;,
 &#39;__is_materialized__&#39;,
 &#39;__iter__&#39;,
 &#39;__le__&#39;,
 &#39;__len__&#39;,
 &#39;__lt__&#39;,
 &#39;__materialize__&#39;,
 &#39;__mod__&#39;,
 &#39;__module__&#39;,
 &#39;__mul__&#39;,
 &#39;__ne__&#39;,
 &#39;__neg__&#39;,
 &#39;__new__&#39;,
 &#39;__nonzero__&#39;,
 &#39;__or__&#39;,
 &#39;__pos__&#39;,
 &#39;__pow__&#39;,
 &#39;__proxy__&#39;,
 &#39;__radd__&#39;,
 &#39;__rdiv__&#39;,
 &#39;__reduce__&#39;,
 &#39;__reduce_ex__&#39;,
 &#39;__repr__&#39;,
 &#39;__rfloordiv__&#39;,
 &#39;__rmod__&#39;,
 &#39;__rmul__&#39;,
 &#39;__rpow__&#39;,
 &#39;__rsub__&#39;,
 &#39;__rtruediv__&#39;,
 &#39;__setattr__&#39;,
 &#39;__sizeof__&#39;,
 &#39;__slots__&#39;,
 &#39;__str__&#39;,
 &#39;__sub__&#39;,
 &#39;__subclasshook__&#39;,
 &#39;__truediv__&#39;,
 &#39;_count_ngrams&#39;,
 &#39;_count_words&#39;,
 &#39;_getitem_cache&#39;,
 &#39;_save_as_text&#39;,
 &#39;all&#39;,
 &#39;any&#39;,
 &#39;append&#39;,
 &#39;apply&#39;,
 &#39;argmax&#39;,
 &#39;argmin&#39;,
 &#39;astype&#39;,
 &#39;clip&#39;,
 &#39;clip_lower&#39;,
 &#39;clip_upper&#39;,
 &#39;contains&#39;,
 &#39;countna&#39;,
 &#39;cumulative_max&#39;,
 &#39;cumulative_mean&#39;,
 &#39;cumulative_min&#39;,
 &#39;cumulative_std&#39;,
 &#39;cumulative_sum&#39;,
 &#39;cumulative_var&#39;,
 &#39;date_range&#39;,
 &#39;datetime_to_str&#39;,
 &#39;dict_has_all_keys&#39;,
 &#39;dict_has_any_keys&#39;,
 &#39;dict_keys&#39;,
 &#39;dict_trim_by_keys&#39;,
 &#39;dict_trim_by_values&#39;,
 &#39;dict_values&#39;,
 &#39;dropna&#39;,
 &#39;dtype&#39;,
 &#39;element_slice&#39;,
 &#39;explore&#39;,
 &#39;fillna&#39;,
 &#39;filter&#39;,
 &#39;filter_by&#39;,
 &#39;from_const&#39;,
 &#39;from_sequence&#39;,
 &#39;hash&#39;,
 &#39;head&#39;,
 &#39;is_in&#39;,
 &#39;is_materialized&#39;,
 &#39;is_topk&#39;,
 &#39;item_length&#39;,
 &#39;materialize&#39;,
 &#39;max&#39;,
 &#39;mean&#39;,
 &#39;min&#39;,
 &#39;nnz&#39;,
 &#39;pixel_array_to_image&#39;,
 &#39;plot&#39;,
 &#39;random_integers&#39;,
 &#39;random_split&#39;,
 &#39;read_json&#39;,
 &#39;rolling_count&#39;,
 &#39;rolling_max&#39;,
 &#39;rolling_mean&#39;,
 &#39;rolling_min&#39;,
 &#39;rolling_stdv&#39;,
 &#39;rolling_sum&#39;,
 &#39;rolling_var&#39;,
 &#39;sample&#39;,
 &#39;save&#39;,
 &#39;shape&#39;,
 &#39;show&#39;,
 &#39;sort&#39;,
 &#39;split_datetime&#39;,
 &#39;stack&#39;,
 &#39;std&#39;,
 &#39;str_to_datetime&#39;,
 &#39;sum&#39;,
 &#39;summary&#39;,
 &#39;tail&#39;,
 &#39;to_numpy&#39;,
 &#39;unique&#39;,
 &#39;unpack&#39;,
 &#39;value_counts&#39;,
 &#39;var&#39;,
 &#39;vector_slice&#39;,
 &#39;where&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bow</span> <span class="o">=</span> <span class="n">sf</span><span class="p">[</span><span class="s1">&#39;X1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">_count_words</span><span class="p">()</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;X1&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>turicreate.data_structures.sarray.SArray
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">bow</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>turicreate.data_structures.sarray.SArray
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bow</span><span class="o">.</span><span class="n">dict_has_any_keys</span><span class="p">([</span><span class="s1">&#39;limited&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dtype: int
Rows: 72269
[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ... ]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bow</span><span class="o">.</span><span class="n">dict_values</span><span class="p">()[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">20</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div style="max-height:1000px;max-width:1500px;overflow:auto;"><table frame="box" rules="cols">
    <tr>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">X1</th>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">aynrand born and educated<br>in russia rand migrated ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">asphalt in american<br>english asphalt or ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">actinopterygii the<br>actinopterygii consti ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">altaiclanguages these<br>language families share ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">argon the name argon is<br>derived from the greek ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">augustderleth a 1938<br>guggenheim fellow der ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">amateur amateurism can be<br>seen in both a negative ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">assemblyline an assembly<br>line is a manufacturing ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">astronomicalunit an<br>astronomical unit ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">abbess an abbess latin<br>abbatissa feminine form ...</td>
    </tr>
</table>
[72269 rows x 1 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;bow&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bow</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div style="max-height:1000px;max-width:1500px;overflow:auto;"><table frame="box" rules="cols">
    <tr>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">X1</th>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">bow</th>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">aynrand born and educated<br>in russia rand migrated ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;spoke&#x27;: 1, &#x27;5000&#x27;: 1,<br>&#x27;follows&#x27;: 1, &#x27;given&#x27; ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">asphalt in american<br>english asphalt or ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;lain&#x27;: 1, &#x27;commonly&#x27;:<br>4, &#x27;has&#x27;: 6, &#x27;percent&#x27;: ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">actinopterygii the<br>actinopterygii consti ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;what&#x27;: 1, &#x27;follows&#x27;: 1,<br>&#x27;given&#x27;: 1, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">altaiclanguages these<br>language families share ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;follows&#x27;: 2, &#x27;has&#x27;: 11,<br>&#x27;general&#x27;: 1, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">argon the name argon is<br>derived from the greek ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;commonly&#x27;: 1,<br>&#x27;lattice&#x27;: 1, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">augustderleth a 1938<br>guggenheim fellow der ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;rescue&#x27;: 2, &#x27;amoral&#x27;:<br>1, &#x27;lovecraft&#x27;: 11, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">amateur amateurism can be<br>seen in both a negative ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;receiving&#x27;: 1,<br>&#x27;having&#x27;: 1, &#x27;hand&#x27;: 1, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">assemblyline an assembly<br>line is a manufacturing ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;consider&#x27;: 1, &#x27;world&#x27;:<br>1, &#x27;bring&#x27;: 2, &#x27;pins&#x27; ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">astronomicalunit an<br>astronomical unit ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;given&#x27;: 1, &#x27;ephemeris&#x27;:<br>2, &#x27;world&#x27;: 2, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">abbess an abbess latin<br>abbatissa feminine form ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;major&#x27;: 1, &#x27;abbess&#x27;:<br>10, &#x27;given&#x27;: 1, ...</td>
    </tr>
</table>
[72269 rows x 2 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;bow&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>turicreate.data_structures.sarray.SArray
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;bow&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>72269
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;bow&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">())[:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;spoke&#39;, 1), (&#39;5000&#39;, 1), (&#39;follows&#39;, 1)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;tfidf&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">text_analytics</span><span class="o">.</span><span class="n">tf_idf</span><span class="p">(</span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;X1&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div style="max-height:1000px;max-width:1500px;overflow:auto;"><table frame="box" rules="cols">
    <tr>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">X1</th>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">bow</th>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">tfidf</th>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">aynrand born and educated<br>in russia rand migrated ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;spoke&#x27;: 1, &#x27;5000&#x27;: 1,<br>&#x27;follows&#x27;: 1, &#x27;given&#x27; ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;spoke&#x27;:<br>4.830308280673057, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">asphalt in american<br>english asphalt or ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;lain&#x27;: 1, &#x27;commonly&#x27;:<br>4, &#x27;has&#x27;: 6, &#x27;percent&#x27;: ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;lain&#x27;:<br>8.480100346078947, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">actinopterygii the<br>actinopterygii consti ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;what&#x27;: 1, &#x27;follows&#x27;: 1,<br>&#x27;given&#x27;: 1, ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;what&#x27;:<br>2.505781957805935, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">altaiclanguages these<br>language families share ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;follows&#x27;: 2, &#x27;has&#x27;: 11,<br>&#x27;general&#x27;: 1, ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;follows&#x27;:<br>7.5113334785280745, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">argon the name argon is<br>derived from the greek ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;commonly&#x27;: 1,<br>&#x27;lattice&#x27;: 1, ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;commonly&#x27;:<br>3.7717720679882287, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">augustderleth a 1938<br>guggenheim fellow der ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;rescue&#x27;: 2, &#x27;amoral&#x27;:<br>1, &#x27;lovecraft&#x27;: 11, ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;rescue&#x27;:<br>9.19021202607744, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">amateur amateurism can be<br>seen in both a negative ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;receiving&#x27;: 1,<br>&#x27;having&#x27;: 1, &#x27;hand&#x27;: 1, ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;receiving&#x27;:<br>4.162612232542636, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">assemblyline an assembly<br>line is a manufacturing ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;consider&#x27;: 1, &#x27;world&#x27;:<br>1, &#x27;bring&#x27;: 2, &#x27;pins&#x27; ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;consider&#x27;:<br>4.336965619687414, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">astronomicalunit an<br>astronomical unit ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;given&#x27;: 1, &#x27;ephemeris&#x27;:<br>2, &#x27;world&#x27;: 2, ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;given&#x27;:<br>2.5682202783138064, ...</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">abbess an abbess latin<br>abbatissa feminine form ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;major&#x27;: 1, &#x27;abbess&#x27;:<br>10, &#x27;given&#x27;: 1, ...</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">{&#x27;major&#x27;:<br>2.356876809458607, ...</td>
    </tr>
</table>
[72269 rows x 3 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">sf</span><span class="p">[</span><span class="s1">&#39;tfidf&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">())[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;spoke&#39;, 4.830308280673057),
 (&#39;5000&#39;, 4.791220891965009),
 (&#39;follows&#39;, 3.7556667392640373),
 (&#39;given&#39;, 2.5682202783138064),
 (&#39;percent&#39;, 17.481279902908025)]
</pre></div>
</div>
</div>
</div>
</section>
<section id="text-cleaning">
<h2>Text Cleaning<a class="headerlink" href="#text-cleaning" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">docs</span> <span class="o">=</span> <span class="n">sf</span><span class="p">[</span><span class="s1">&#39;bow&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dict_trim_by_values</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">docs</span> <span class="o">=</span> <span class="n">docs</span><span class="o">.</span><span class="n">dict_trim_by_keys</span><span class="p">(</span>
    <span class="n">tc</span><span class="o">.</span><span class="n">text_analytics</span><span class="o">.</span><span class="n">stop_words</span><span class="p">(),</span>
    <span class="n">exclude</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="topic-modeling">
<h2>Topic modeling<a class="headerlink" href="#topic-modeling" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">tc</span><span class="o">.</span><span class="n">topic_model</span><span class="o">.</span><span class="n">create</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Help on function create in module turicreate.toolkits.topic_model.topic_model:

create(dataset, num_topics=10, initial_topics=None, alpha=None, beta=0.1, num_iterations=10, num_burnin=5, associations=None, verbose=False, print_interval=10, validation_set=None, method=&#39;auto&#39;)
    Create a topic model from the given data set. A topic model assumes each
    document is a mixture of a set of topics, where for each topic some words
    are more likely than others. One statistical approach to do this is called a
    &quot;topic model&quot;. This method learns a topic model for the given document
    collection.
    
    Parameters
    ----------
    dataset : SArray of type dict or SFrame with a single column of type dict
        A bag of words representation of a document corpus.
        Each element is a dictionary representing a single document, where
        the keys are words and the values are the number of times that word
        occurs in that document.
    
    num_topics : int, optional
        The number of topics to learn.
    
    initial_topics : SFrame, optional
        An SFrame with a column of unique words representing the vocabulary
        and a column of dense vectors representing
        probability of that word given each topic. When provided,
        these values are used to initialize the algorithm.
    
    alpha : float, optional
        Hyperparameter that controls the diversity of topics in a document.
        Smaller values encourage fewer topics per document.
        Provided value must be positive. Default value is 50/num_topics.
    
    beta : float, optional
        Hyperparameter that controls the diversity of words in a topic.
        Smaller values encourage fewer words per topic. Provided value
        must be positive.
    
    num_iterations : int, optional
        The number of iterations to perform.
    
    num_burnin : int, optional
        The number of iterations to perform when inferring the topics for
        documents at prediction time.
    
    verbose : bool, optional
        When True, print most probable words for each topic while printing
        progress.
    
    print_interval : int, optional
        The number of iterations to wait between progress reports.
    
    associations : SFrame, optional
        An SFrame with two columns named &quot;word&quot; and &quot;topic&quot; containing words
        and the topic id that the word should be associated with. These words
        are not considered during learning.
    
    validation_set : SArray of type dict or SFrame with a single column
        A bag of words representation of a document corpus, similar to the
        format required for `dataset`. This will be used to monitor model
        performance during training. Each document in the provided validation
        set is randomly split: the first portion is used estimate which topic
        each document belongs to, and the second portion is used to estimate
        the model&#39;s performance at predicting the unseen words in the test data.
    
    method : {&#39;cgs&#39;, &#39;alias&#39;}, optional
        The algorithm used for learning the model.
    
        - *cgs:* Collapsed Gibbs sampling
        - *alias:* AliasLDA method.
    
    Returns
    -------
    out : TopicModel
        A fitted topic model. This can be used with
        :py:func:`~TopicModel.get_topics()` and
        :py:func:`~TopicModel.predict()`. While fitting is in progress, several
        metrics are shown, including:
    
        +------------------+---------------------------------------------------+
        |      Field       | Description                                       |
        +==================+===================================================+
        | Elapsed Time     | The number of elapsed seconds.                    |
        +------------------+---------------------------------------------------+
        | Tokens/second    | The number of unique words processed per second   |
        +------------------+---------------------------------------------------+
        | Est. Perplexity  | An estimate of the model&#39;s ability to model the   |
        |                  | training data. See the documentation on evaluate. |
        +------------------+---------------------------------------------------+
    
    See Also
    --------
    TopicModel, TopicModel.get_topics, TopicModel.predict,
    turicreate.SArray.dict_trim_by_keys, TopicModel.evaluate
    
    References
    ----------
    - `Wikipedia - Latent Dirichlet allocation
      &lt;http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation&gt;`_
    
    - Alias method: Li, A. et al. (2014) `Reducing the Sampling Complexity of
      Topic Models. &lt;http://www.sravi.org/pubs/fastlda-kdd2014.pdf&gt;`_.
      KDD 2014.
    
    Examples
    --------
    The following example includes an SArray of documents, where
    each element represents a document in &quot;bag of words&quot; representation
    -- a dictionary with word keys and whose values are the number of times
    that word occurred in the document:
    
    &gt;&gt;&gt; docs = turicreate.SArray(&#39;https://static.turi.com/datasets/nytimes&#39;)
    
    Once in this form, it is straightforward to learn a topic model.
    
    &gt;&gt;&gt; m = turicreate.topic_model.create(docs)
    
    It is also easy to create a new topic model from an old one  -- whether
    it was created using Turi Create or another package.
    
    &gt;&gt;&gt; m2 = turicreate.topic_model.create(docs, initial_topics=m[&#39;topics&#39;])
    
    To manually fix several words to always be assigned to a topic, use
    the `associations` argument. The following will ensure that topic 0
    has the most probability for each of the provided words:
    
    &gt;&gt;&gt; from turicreate import SFrame
    &gt;&gt;&gt; associations = SFrame({&#39;word&#39;:[&#39;hurricane&#39;, &#39;wind&#39;, &#39;storm&#39;],
                               &#39;topic&#39;: [0, 0, 0]})
    &gt;&gt;&gt; m = turicreate.topic_model.create(docs,
                                        associations=associations)
    
    More advanced usage allows you  to control aspects of the model and the
    learning method.
    
    &gt;&gt;&gt; import turicreate as tc
    &gt;&gt;&gt; m = tc.topic_model.create(docs,
                                  num_topics=20,       # number of topics
                                  num_iterations=10,   # algorithm parameters
                                  alpha=.01, beta=.1)  # hyperparameters
    
    To evaluate the model&#39;s ability to generalize, we can create a train/test
    split where a portion of the words in each document are held out from
    training.
    
    &gt;&gt;&gt; train, test = tc.text_analytics.random_split(.8)
    &gt;&gt;&gt; m = tc.topic_model.create(train)
    &gt;&gt;&gt; results = m.evaluate(test)
    &gt;&gt;&gt; print results[&#39;perplexity&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">tc</span><span class="o">.</span><span class="n">text_analytics</span><span class="o">.</span><span class="n">random_split</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Help on function random_split in module turicreate.toolkits.text_analytics._util:

random_split(dataset, prob=0.5)
    Utility for performing a random split for text data that is already in
    bag-of-words format. For each (word, count) pair in a particular element,
    the counts are uniformly partitioned in either a training set or a test
    set.
    
    Parameters
    ----------
    dataset : SArray of type dict, SFrame with columns of type dict
        A data set in bag-of-words format.
    
    prob : float, optional
        Probability for sampling a word to be placed in the test set.
    
    Returns
    -------
    train, test : SArray
        Two data sets in bag-of-words format, where the combined counts are
        equal to the counts in the original data set.
    
    Examples
    --------
    &gt;&gt;&gt; docs = turicreate.SArray([{&#39;are&#39;:5, &#39;you&#39;:3, &#39;not&#39;: 1, &#39;entertained&#39;:10}])
    &gt;&gt;&gt; train, test = turicreate.text_analytics.random_split(docs)
    &gt;&gt;&gt; print(train)
    [{&#39;not&#39;: 1.0, &#39;you&#39;: 3.0, &#39;are&#39;: 3.0, &#39;entertained&#39;: 7.0}]
    &gt;&gt;&gt; print(test)
    [{&#39;are&#39;: 2.0, &#39;entertained&#39;: 3.0}]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">text_analytics</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="mf">.8</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">topic_model</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> 
                                <span class="n">num_topics</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>       <span class="c1"># number of topics</span>
                                <span class="n">num_iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>   <span class="c1"># algorithm parameters</span>
                                <span class="n">alpha</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">.1</span><span class="p">)</span>  <span class="c1"># hyperparameters</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre>Learning a topic model</pre></div><div class="output text_html"><pre>       Number of documents     72269</pre></div><div class="output text_html"><pre>           Vocabulary size    108205</pre></div><div class="output text_html"><pre>   Running collapsed Gibbs sampling</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div><div class="output text_html"><pre>| Iteration | Elapsed Time  | Tokens/Second  | Est. Perplexity |</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div><div class="output text_html"><pre>| 10        | 1.66s         | 6.17013e+06    | 0               |</pre></div><div class="output text_html"><pre>| 20        | 3.12s         | 6.57117e+06    | 0               |</pre></div><div class="output text_html"><pre>| 30        | 4.58s         | 6.41968e+06    | 0               |</pre></div><div class="output text_html"><pre>| 40        | 6.00s         | 6.61674e+06    | 0               |</pre></div><div class="output text_html"><pre>| 50        | 7.42s         | 6.53873e+06    | 0               |</pre></div><div class="output text_html"><pre>| 60        | 8.85s         | 6.46591e+06    | 0               |</pre></div><div class="output text_html"><pre>| 70        | 10.38s        | 5.92867e+06    | 0               |</pre></div><div class="output text_html"><pre>| 80        | 11.90s        | 6.36375e+06    | 0               |</pre></div><div class="output text_html"><pre>| 90        | 13.42s        | 6.20572e+06    | 0               |</pre></div><div class="output text_html"><pre>| 100       | 15.03s        | 5.4879e+06     | 0               |</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;perplexity&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4552.105441414741
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Class                          : TopicModel

Schema
------
Vocabulary Size                : 108205

Settings
--------
Number of Topics               : 100
alpha                          : 0.5
beta                           : 0.1
Iterations                     : 100
Training time                  : 16.0432
Verbose                        : True

Accessible fields             : 
m.topics                      : An SFrame containing the topics.
m.vocabulary                  : An SArray containing the words in the vocabulary.
Useful methods                : 
m.get_topics()                : Get the most probable words per topic.
m.predict(new_docs)           : Make predictions for new documents.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="o">.</span><span class="n">get_topics</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div style="max-height:1000px;max-width:1500px;overflow:auto;"><table frame="box" rules="cols">
    <tr>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">topic</th>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">word</th>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">score</th>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">years</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.004647514462204498</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">evans</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.004059221492305195</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">lebanon</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.0028172696669622205</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">green</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.0028172696669622205</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">time</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.0020982449259741827</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">1</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">national</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.005351237598960527</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">1</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">back</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.002278117379832135</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">1</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">baldwin</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.0018772756121197358</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">1</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">chicago</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.0018104686508343358</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">1</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">private</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.0016100477669781365</td>
    </tr>
</table>
[500 rows x 3 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">get_topics</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Help on method get_topics in module turicreate.toolkits.topic_model.topic_model:

get_topics(topic_ids=None, num_words=5, cdf_cutoff=1.0, output_type=&#39;topic_probabilities&#39;) method of turicreate.toolkits.topic_model.topic_model.TopicModel instance
    Get the words associated with a given topic. The score column is the
    probability of choosing that word given that you have chosen a
    particular topic.
    
    Parameters
    ----------
    topic_ids : list of int, optional
        The topics to retrieve words. Topic ids are zero-based.
        Throws an error if greater than or equal to m[&#39;num_topics&#39;], or
        if the requested topic name is not present.
    
    num_words : int, optional
        The number of words to show.
    
    cdf_cutoff : float, optional
        Allows one to only show the most probable words whose cumulative
        probability is below this cutoff. For example if there exist
        three words where
    
        .. math::
           p(word_1 | topic_k) = .1
    
           p(word_2 | topic_k) = .2
    
           p(word_3 | topic_k) = .05
    
        then setting :math:`cdf_{cutoff}=.3` would return only
        :math:`word_1` and :math:`word_2` since
        :math:`p(word_1 | topic_k) + p(word_2 | topic_k) &lt;= cdf_{cutoff}`
    
    output_type : {&#39;topic_probabilities&#39; | &#39;topic_words&#39;}, optional
        Determine the type of desired output. See below.
    
    Returns
    -------
    out : SFrame
        If output_type is &#39;topic_probabilities&#39;, then the returned value is
        an SFrame with a column of words ranked by a column of scores for
        each topic. Otherwise, the returned value is a SArray where
        each element is a list of the most probable words for each topic.
    
    Examples
    --------
    Get the highest ranked words for all topics.
    
    &gt;&gt;&gt; docs = turicreate.SArray(&#39;https://static.turi.com/datasets/nips-text&#39;)
    &gt;&gt;&gt; m = turicreate.topic_model.create(docs,
                                        num_iterations=50)
    &gt;&gt;&gt; m.get_topics()
    +-------+----------+-----------------+
    | topic |   word   |      score      |
    +-------+----------+-----------------+
    |   0   |   cell   |  0.028974400831 |
    |   0   |  input   | 0.0259470208503 |
    |   0   |  image   | 0.0215721599763 |
    |   0   |  visual  | 0.0173635081992 |
    |   0   |  object  | 0.0172447874156 |
    |   1   | function | 0.0482834508265 |
    |   1   |  input   | 0.0456270024091 |
    |   1   |  point   | 0.0302662839454 |
    |   1   |  result  | 0.0239474934631 |
    |   1   | problem  | 0.0231750116011 |
    |  ...  |   ...    |       ...       |
    +-------+----------+-----------------+
    
    Get the highest ranked words for topics 0 and 1 and show 15 words per
    topic.
    
    &gt;&gt;&gt; m.get_topics([0, 1], num_words=15)
    +-------+----------+------------------+
    | topic |   word   |      score       |
    +-------+----------+------------------+
    |   0   |   cell   |  0.028974400831  |
    |   0   |  input   | 0.0259470208503  |
    |   0   |  image   | 0.0215721599763  |
    |   0   |  visual  | 0.0173635081992  |
    |   0   |  object  | 0.0172447874156  |
    |   0   | response | 0.0139740298286  |
    |   0   |  layer   | 0.0122585145062  |
    |   0   | features | 0.0115343177265  |
    |   0   | feature  | 0.0103530459301  |
    |   0   | spatial  | 0.00823387994361 |
    |  ...  |   ...    |       ...        |
    +-------+----------+------------------+
    
    If one wants to instead just get the top words per topic, one may
    change the format of the output as follows.
    
    &gt;&gt;&gt; topics = m.get_topics(output_type=&#39;topic_words&#39;)
    dtype: list
    Rows: 10
    [[&#39;cell&#39;, &#39;image&#39;, &#39;input&#39;, &#39;object&#39;, &#39;visual&#39;],
     [&#39;algorithm&#39;, &#39;data&#39;, &#39;learning&#39;, &#39;method&#39;, &#39;set&#39;],
     [&#39;function&#39;, &#39;input&#39;, &#39;point&#39;, &#39;problem&#39;, &#39;result&#39;],
     [&#39;model&#39;, &#39;output&#39;, &#39;pattern&#39;, &#39;set&#39;, &#39;unit&#39;],
     [&#39;action&#39;, &#39;learning&#39;, &#39;net&#39;, &#39;problem&#39;, &#39;system&#39;],
     [&#39;error&#39;, &#39;function&#39;, &#39;network&#39;, &#39;parameter&#39;, &#39;weight&#39;],
     [&#39;information&#39;, &#39;level&#39;, &#39;neural&#39;, &#39;threshold&#39;, &#39;weight&#39;],
     [&#39;control&#39;, &#39;field&#39;, &#39;model&#39;, &#39;network&#39;, &#39;neuron&#39;],
     [&#39;hidden&#39;, &#39;layer&#39;, &#39;system&#39;, &#39;training&#39;, &#39;vector&#39;],
     [&#39;component&#39;, &#39;distribution&#39;, &#39;local&#39;, &#39;model&#39;, &#39;optimal&#39;]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">topics</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">get_topics</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">unstack</span><span class="p">([</span><span class="s1">&#39;word&#39;</span><span class="p">,</span><span class="s1">&#39;score&#39;</span><span class="p">],</span> \
                                <span class="n">new_column_name</span><span class="o">=</span><span class="s1">&#39;topic_words&#39;</span><span class="p">)[</span><span class="s1">&#39;topic_words&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="k">for</span> <span class="n">topic</span> <span class="ow">in</span> <span class="n">topics</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">topic</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;storm&#39;, &#39;florida&#39;, &#39;area&#39;, &#39;due&#39;, &#39;texas&#39;, &#39;people&#39;, &#39;damage&#39;, &#39;hurricane&#39;, &#39;tropical&#39;, &#39;system&#39;]
[&#39;project&#39;, &#39;ryan&#39;, &#39;founded&#39;, &#39;harvard&#39;, &#39;carroll&#39;, &#39;including&#39;, &#39;wilson&#39;, &#39;school&#39;, &#39;oxford&#39;, &#39;national&#39;]
[&#39;alliance&#39;, &#39;organization&#39;, &#39;membership&#39;, &#39;board&#39;, &#39;member&#39;, &#39;members&#39;, &#39;association&#39;, &#39;groups&#39;, &#39;group&#39;, &#39;society&#39;]
[&#39;summer&#39;, &#39;george&#39;, &#39;kan&#39;, &#39;julian&#39;, &#39;1978&#39;, &#39;date&#39;, &#39;years&#39;, &#39;wolfe&#39;, &#39;london&#39;, &#39;italian&#39;]
[&#39;german&#39;, &#39;division&#39;, &#39;forces&#39;, &#39;british&#39;, &#39;army&#39;, &#39;men&#39;, &#39;battle&#39;, &#39;general&#39;, &#39;war&#39;, &#39;military&#39;]
[&#39;arrow&#39;, &#39;williams&#39;, &#39;california&#39;, &#39;warren&#39;, &#39;santa&#39;, &#39;los&#39;, &#39;san&#39;, &#39;great&#39;, &#39;angeles&#39;, &#39;renamed&#39;]
[&#39;miller&#39;, &#39;time&#39;, &#39;produced&#39;, &#39;years&#39;, &#39;lewis&#39;, &#39;hamilton&#39;, &#39;morris&#39;, &#39;1999&#39;, &#39;2005&#39;, &#39;epic&#39;]
[&#39;played&#39;, &#39;games&#39;, &#39;coach&#39;, &#39;won&#39;, &#39;points&#39;, &#39;team&#39;, &#39;game&#39;, &#39;record&#39;, &#39;season&#39;, &#39;teams&#39;]
[&#39;green&#39;, &#39;time&#39;, &#39;connecticut&#39;, &#39;evans&#39;, &#39;years&#39;, &#39;sixth&#39;, &#39;lebanon&#39;, &#39;2001&#39;, &#39;worked&#39;, &#39;2005&#39;]
[&#39;van&#39;, &#39;berlin&#39;, &#39;im&#39;, &#39;des&#39;, &#39;von&#39;, &#39;die&#39;, &#39;den&#39;, &#39;der&#39;, &#39;das&#39;, &#39;und&#39;]
[&#39;clothing&#39;, &#39;hat&#39;, &#39;worn&#39;, &#39;wear&#39;, &#39;made&#39;, &#39;green&#39;, &#39;summer&#39;, &#39;black&#39;, &#39;top&#39;, &#39;dress&#39;]
[&#39;2009&#39;, &#39;year&#39;, &#39;kids&#39;, &#39;october&#39;, &#39;2010&#39;, &#39;2007&#39;, &#39;school&#39;, &#39;2006&#39;, &#39;2008&#39;, &#39;national&#39;]
[&#39;magazine&#39;, &#39;grant&#39;, &#39;oregon&#39;, &#39;portland&#39;, &#39;college&#39;, &#39;1985&#39;, &#39;2006&#39;, &#39;year&#39;, &#39;long&#39;, &#39;beer&#39;]
[&#39;network&#39;, &#39;show&#39;, &#39;local&#39;, &#39;news&#39;, &#39;broadcast&#39;, &#39;radio&#39;, &#39;channel&#39;, &#39;stations&#39;, &#39;television&#39;, &#39;station&#39;]
[&#39;bridge&#39;, &#39;north&#39;, &#39;river&#39;, &#39;county&#39;, &#39;state&#39;, &#39;west&#39;, &#39;route&#39;, &#39;city&#39;, &#39;east&#39;, &#39;road&#39;]
[&#39;part&#39;, &#39;degree&#39;, &#39;na&#39;, &#39;valid&#39;, &#39;agent&#39;, &#39;history&#39;, &#39;reform&#39;, &#39;born&#39;, &#39;agency&#39;, &#39;trn&#39;]
[&#39;children&#39;, &#39;father&#39;, &#39;mother&#39;, &#39;married&#39;, &#39;years&#39;, &#39;family&#39;, &#39;born&#39;, &#39;life&#39;, &#39;died&#39;, &#39;time&#39;]
[&#39;early&#39;, &#39;population&#39;, &#39;century&#39;, &#39;american&#39;, &#39;war&#39;, &#39;government&#39;, &#39;states&#39;, &#39;british&#39;, &#39;united&#39;, &#39;people&#39;]
[&#39;stories&#39;, &#39;magazine&#39;, &#39;writing&#39;, &#39;history&#39;, &#39;work&#39;, &#39;wrote&#39;, &#39;works&#39;, &#39;published&#39;, &#39;book&#39;, &#39;books&#39;]
[&#39;collection&#39;, &#39;painting&#39;, &#39;arts&#39;, &#39;museum&#39;, &#39;work&#39;, &#39;york&#39;, &#39;design&#39;, &#39;artists&#39;, &#39;art&#39;, &#39;works&#39;]
[&#39;named&#39;, &#39;flag&#39;, &#39;orange&#39;, &#39;blue&#39;, &#39;colors&#39;, &#39;yellow&#39;, &#39;tiger&#39;, &#39;black&#39;, &#39;red&#39;, &#39;white&#39;]
[&#39;made&#39;, &#39;mission&#39;, &#39;test&#39;, &#39;project&#39;, &#39;space&#39;, &#39;aircraft&#39;, &#39;wright&#39;, &#39;design&#39;, &#39;launch&#39;, &#39;flight&#39;]
[&#39;alan&#39;, &#39;phillips&#39;, &#39;preov&#39;, &#39;koice&#39;, &#39;beth&#39;, &#39;trenn&#39;, &#39;phillip&#39;, &#39;nitra&#39;, &#39;town&#39;, &#39;trnava&#39;]
[&#39;racing&#39;, &#39;cars&#39;, &#39;car&#39;, &#39;engines&#39;, &#39;models&#39;, &#39;series&#39;, &#39;engine&#39;, &#39;system&#39;, &#39;race&#39;, &#39;model&#39;]
[&#39;building&#39;, &#39;duck&#39;, &#39;london&#39;, &#39;philadelphia&#39;, &#39;represented&#39;, &#39;major&#39;, &#39;york&#39;, &#39;design&#39;, &#39;journal&#39;, &#39;duncan&#39;]
[&#39;english&#39;, &#39;language&#39;, &#39;form&#39;, &#39;meaning&#39;, &#39;word&#39;, &#39;words&#39;, &#39;names&#39;, &#39;written&#39;, &#39;languages&#39;, &#39;common&#39;]
[&#39;gene&#39;, &#39;enzyme&#39;, &#39;dna&#39;, &#39;site&#39;, &#39;proteins&#39;, &#39;protein&#39;, &#39;cells&#39;, &#39;cell&#39;, &#39;structure&#39;, &#39;genes&#39;]
[&#39;work&#39;, &#39;year&#39;, &#39;2009&#39;, &#39;andrew&#39;, &#39;list&#39;, &#39;henin&#39;, &#39;link&#39;, &#39;dates&#39;, &#39;part&#39;, &#39;calendar&#39;]
[&#39;law&#39;, &#39;public&#39;, &#39;united&#39;, &#39;state&#39;, &#39;legal&#39;, &#39;act&#39;, &#39;states&#39;, &#39;court&#39;, &#39;case&#39;, &#39;federal&#39;]
[&#39;trains&#39;, &#39;west&#39;, &#39;line&#39;, &#39;rail&#39;, &#39;train&#39;, &#39;station&#39;, &#39;services&#39;, &#39;service&#39;, &#39;opened&#39;, &#39;railway&#39;]
[&#39;served&#39;, &#39;cemetery&#39;, &#39;received&#39;, &#39;texas&#39;, &#39;po&#39;, &#39;christi&#39;, &#39;university&#39;, &#39;post&#39;, &#39;corpus&#39;, &#39;mexico&#39;]
[&#39;international&#39;, &#39;worked&#39;, &#39;festival&#39;, &#39;director&#39;, &#39;film&#39;, &#39;awards&#39;, &#39;won&#39;, &#39;award&#39;, &#39;awarded&#39;, &#39;academy&#39;]
[&#39;empire&#39;, &#39;china&#39;, &#39;chinese&#39;, &#39;dynasty&#39;, &#39;roman&#39;, &#39;greek&#39;, &#39;time&#39;, &#39;king&#39;, &#39;bc&#39;, &#39;emperor&#39;]
[&#39;port&#39;, &#39;ship&#39;, &#39;coast&#39;, &#39;island&#39;, &#39;sea&#39;, &#39;fleet&#39;, &#39;region&#39;, &#39;bay&#39;, &#39;ships&#39;, &#39;islands&#39;]
[&#39;south&#39;, &#39;north&#39;, &#39;river&#39;, &#39;mountain&#39;, &#39;water&#39;, &#39;creek&#39;, &#39;lake&#39;, &#39;valley&#39;, &#39;park&#39;, &#39;area&#39;]
[&#39;january&#39;, &#39;day&#39;, &#39;june&#39;, &#39;2009&#39;, &#39;october&#39;, &#39;december&#39;, &#39;2010&#39;, &#39;2007&#39;, &#39;2008&#39;, &#39;september&#39;]
[&#39;round&#39;, &#39;team&#39;, &#39;won&#39;, &#39;event&#39;, &#39;title&#39;, &#39;world&#39;, &#39;match&#39;, &#39;championship&#39;, &#39;lost&#39;, &#39;open&#39;]
[&#39;created&#39;, &#39;2010&#39;, &#39;ash&#39;, &#39;complex&#39;, &#39;sanders&#39;, &#39;hotel&#39;, &#39;skating&#39;, &#39;school&#39;, &#39;house&#39;, &#39;msn&#39;]
[&#39;left&#39;, &#39;easy&#39;, &#39;leg&#39;, &#39;ancient&#39;, &#39;benson&#39;, &#39;school&#39;, &#39;2003&#39;, &#39;critical&#39;, &#39;british&#39;, &#39;westfield&#39;]
[&#39;released&#39;, &#39;world&#39;, &#39;games&#39;, &#39;version&#39;, &#39;series&#39;, &#39;video&#39;, &#39;player&#39;, &#39;game&#39;, &#39;players&#39;, &#39;2&#39;]
[&#39;won&#39;, &#39;cup&#39;, &#39;team&#39;, &#39;teams&#39;, &#39;season&#39;, &#39;final&#39;, &#39;football&#39;, &#39;club&#39;, &#39;league&#39;, &#39;played&#39;]
[&#39;1988&#39;, &#39;called&#39;, &#39;list&#39;, &#39;1971&#39;, &#39;2010&#39;, &#39;1994&#39;, &#39;made&#39;, &#39;trent&#39;, &#39;found&#39;, &#39;local&#39;]
[&#39;world&#39;, &#39;received&#39;, &#39;usa&#39;, &#39;wall&#39;, &#39;part&#39;, &#39;start0&#39;, &#39;williams&#39;, &#39;work&#39;, &#39;events&#39;, &#39;plotdata&#39;]
[&#39;years&#39;, &#39;age&#39;, &#39;income&#39;, &#39;median&#39;, &#39;18&#39;, &#39;living&#39;, &#39;males&#39;, &#39;town&#39;, &#39;average&#39;, &#39;population&#39;]
[&#39;youth&#39;, &#39;bamboo&#39;, &#39;ross&#39;, &#39;griffin&#39;, &#39;williams&#39;, &#39;meeting&#39;, &#39;monument&#39;, &#39;town&#39;, &#39;joined&#39;, &#39;girl&#39;]
[&#39;south&#39;, &#39;european&#39;, &#39;international&#39;, &#39;economic&#39;, &#39;states&#39;, &#39;development&#39;, &#39;united&#39;, &#39;government&#39;, &#39;countries&#39;, &#39;world&#39;]
[&#39;national&#39;, &#39;constituencies&#39;, &#39;animation&#39;, &#39;part&#39;, &#39;track&#39;, &#39;baldwin&#39;, &#39;1982&#39;, &#39;private&#39;, &#39;back&#39;, &#39;chicago&#39;]
[&#39;hill&#39;, &#39;morgan&#39;, &#39;davis&#39;, &#39;cj&#39;, &#39;1992&#39;, &#39;arch&#39;, &#39;child&#39;, &#39;1995&#39;, &#39;tony&#39;, &#39;part&#39;]
[&#39;form&#39;, &#39;called&#39;, &#39;1&#39;, &#39;theory&#39;, &#39;set&#39;, &#39;number&#39;, &#39;function&#39;, &#39;type&#39;, &#39;system&#39;, &#39;model&#39;]
[&#39;form&#39;, &#39;women&#39;, &#39;social&#39;, &#39;life&#39;, &#39;society&#39;, &#39;people&#39;, &#39;time&#39;, &#39;world&#39;, &#39;human&#39;, &#39;work&#39;]
[&#39;city&#39;, &#39;san&#39;, &#39;paris&#39;, &#39;el&#39;, &#39;france&#39;, &#39;la&#39;, &#39;de&#39;, &#39;french&#39;, &#39;spain&#39;, &#39;spanish&#39;]
[&#39;city&#39;, &#39;located&#39;, &#39;house&#39;, &#39;park&#39;, &#39;building&#39;, &#39;street&#39;, &#39;built&#39;, &#39;town&#39;, &#39;area&#39;, &#39;century&#39;]
[&#39;made&#39;, &#39;include&#39;, &#39;variety&#39;, &#39;traditional&#39;, &#39;rice&#39;, &#39;popular&#39;, &#39;food&#39;, &#39;called&#39;, &#39;served&#39;, &#39;wine&#39;]
[&#39;canadian&#39;, &#39;ontario&#39;, &#39;alberta&#39;, &#39;british&#39;, &#39;york&#39;, &#39;2002&#39;, &#39;toronto&#39;, &#39;quebec&#39;, &#39;canada&#39;, &#39;montreal&#39;]
[&#39;khan&#39;, &#39;afghanistan&#39;, &#39;indian&#39;, &#39;singh&#39;, &#39;temple&#39;, &#39;punjab&#39;, &#39;pakistan&#39;, &#39;sri&#39;, &#39;india&#39;, &#39;community&#39;]
[&#39;brooklyn&#39;, &#39;city&#39;, &#39;class&#39;, &#39;ambassador&#39;, &#39;2004&#39;, &#39;due&#39;, &#39;babylon&#39;, &#39;historical&#39;, &#39;area&#39;, &#39;5&#39;]
[&#39;heat&#39;, &#39;iron&#39;, &#39;high&#39;, &#39;process&#39;, &#39;water&#39;, &#39;form&#39;, &#39;gas&#39;, &#39;temperature&#39;, &#39;nuclear&#39;, &#39;energy&#39;]
[&#39;airlines&#39;, &#39;regional&#39;, &#39;airport&#39;, &#39;2010&#39;, &#39;international&#39;, &#39;travel&#39;, &#39;airways&#39;, &#39;2005&#39;, &#39;airline&#39;, &#39;joined&#39;]
[&#39;head&#39;, &#39;15&#39;, &#39;home&#39;, &#39;2010&#39;, &#39;2003&#39;, &#39;elected&#39;, &#39;park&#39;, &#39;stone&#39;, &#39;gaol&#39;, &#39;numerous&#39;]
[&#39;poland&#39;, &#39;years&#39;, &#39;polish&#39;, &#39;soviet&#39;, &#39;moscow&#39;, &#39;war&#39;, &#39;russian&#39;, &#39;swedish&#39;, &#39;union&#39;, &#39;russia&#39;]
[&#39;william&#39;, &#39;henry&#39;, &#39;england&#39;, &#39;sir&#39;, &#39;london&#39;, &#39;royal&#39;, &#39;lord&#39;, &#39;king&#39;, &#39;son&#39;, &#39;john&#39;]
[&#39;ohio&#39;, &#39;virginia&#39;, &#39;district&#39;, &#39;washington&#39;, &#39;john&#39;, &#39;carolina&#39;, &#39;county&#39;, &#39;state&#39;, &#39;served&#39;, &#39;south&#39;]
[&#39;state&#39;, &#39;election&#39;, &#39;political&#39;, &#39;minister&#39;, &#39;council&#39;, &#39;national&#39;, &#39;party&#39;, &#39;president&#39;, &#39;government&#39;, &#39;elected&#39;]
[&#39;district&#39;, &#39;districts&#39;, &#39;register&#39;, &#39;properties&#39;, &#39;places&#39;, &#39;illinois&#39;, &#39;national&#39;, &#39;county&#39;, &#39;historic&#39;, &#39;school&#39;]
[&#39;operations&#39;, &#39;aircraft&#39;, &#39;base&#39;, &#39;united&#39;, &#39;war&#39;, &#39;service&#39;, &#39;air&#39;, &#39;group&#39;, &#39;force&#39;, &#39;training&#39;]
[&#39;number&#39;, &#39;25&#39;, &#39;2010&#39;, &#39;golf&#39;, &#39;time&#39;, &#39;scrooge&#39;, &#39;group&#39;, &#39;university&#39;, &#39;chams&#39;, &#39;world&#39;]
[&#39;light&#39;, &#39;range&#39;, &#39;made&#39;, &#39;time&#39;, &#39;system&#39;, &#39;small&#39;, &#39;power&#39;, &#39;energy&#39;, &#39;high&#39;, &#39;current&#39;]
[&#39;1983&#39;, &#39;university&#39;, &#39;states&#39;, &#39;served&#39;, &#39;appointed&#39;, &#39;1986&#39;, &#39;degree&#39;, &#39;bill&#39;, &#39;professor&#39;, &#39;2000&#39;]
[&#39;years&#39;, &#39;head&#39;, &#39;joseph&#39;, &#39;school&#39;, &#39;smiths&#39;, &#39;rejoice&#39;, &#39;smith&#39;, &#39;clark&#39;, &#39;stone&#39;, &#39;plates&#39;]
[&#39;found&#39;, &#39;occur&#39;, &#39;body&#39;, &#39;small&#39;, &#39;disease&#39;, &#39;large&#39;, &#39;species&#39;, &#39;family&#39;, &#39;order&#39;, &#39;birds&#39;]
[&#39;number&#39;, &#39;fat&#39;, &#39;2006&#39;, &#39;named&#39;, &#39;work&#39;, &#39;death&#39;, &#39;published&#39;, &#39;flores&#39;, &#39;vincent&#39;, &#39;villa&#39;]
[&#39;company&#39;, &#39;business&#39;, &#39;mine&#39;, &#39;sold&#39;, &#39;oil&#39;, &#39;stores&#39;, &#39;industry&#39;, &#39;year&#39;, &#39;production&#39;, &#39;mining&#39;]
[&#39;martin&#39;, &#39;kitty&#39;, &#39;obesity&#39;, &#39;turtle&#39;, &#39;point&#39;, &#39;2000&#39;, &#39;camp&#39;, &#39;clark&#39;, &#39;moved&#39;, &#39;born&#39;]
[&#39;1994&#39;, &#39;1998&#39;, &#39;ryo&#39;, &#39;venezuela&#39;, &#39;tannins&#39;, &#39;national&#39;, &#39;group&#39;, &#39;minor&#39;, &#39;christmas&#39;, &#39;world&#39;]
[&#39;parish&#39;, &#39;saint&#39;, &#39;bishop&#39;, &#39;church&#39;, &#39;roman&#39;, &#39;council&#39;, &#39;st&#39;, &#39;century&#39;, &#39;catholic&#39;, &#39;pope&#39;]
[&#39;released&#39;, &#39;records&#39;, &#39;single&#39;, &#39;album&#39;, &#39;songs&#39;, &#39;music&#39;, &#39;band&#39;, &#39;live&#39;, &#39;song&#39;, &#39;tour&#39;]
[&#39;wales&#39;, &#39;australia&#39;, &#39;played&#39;, &#39;cricket&#39;, &#39;zealand&#39;, &#39;day&#39;, &#39;sydney&#39;, &#39;made&#39;, &#39;australian&#39;, &#39;south&#39;]
[&#39;information&#39;, &#39;network&#39;, &#39;system&#39;, &#39;software&#39;, &#39;systems&#39;, &#39;internet&#39;, &#39;users&#39;, &#39;technology&#39;, &#39;computer&#39;, &#39;data&#39;]
[&#39;philippine&#39;, &#39;clara&#39;, &#39;foundation&#39;, &#39;chief&#39;, &#39;full&#39;, &#39;fair&#39;, &#39;philippines&#39;, &#39;manila&#39;, &#39;rupiah&#39;, &#39;belle&#39;]
[&#39;group&#39;, &#39;began&#39;, &#39;anderson&#39;, &#39;minnesota&#39;, &#39;john&#39;, &#39;period&#39;, &#39;jones&#39;, &#39;te&#39;, &#39;td&#39;, &#39;dont&#39;]
[&#39;northern&#39;, &#39;cork&#39;, &#39;dublin&#39;, &#39;ireland&#39;, &#39;irish&#39;, &#39;senior&#39;, &#39;john&#39;, &#39;county&#39;, &#39;title&#39;, &#39;medal&#39;]
[&#39;school&#39;, &#39;2006&#39;, &#39;stone&#39;, &#39;york&#39;, &#39;bay&#39;, &#39;village&#39;, &#39;held&#39;, &#39;created&#39;, &#39;local&#39;, &#39;community&#39;]
[&#39;years&#39;, &#39;jersey&#39;, &#39;police&#39;, &#39;city&#39;, &#39;york&#39;, &#39;family&#39;, &#39;crime&#39;, &#39;gang&#39;, &#39;prison&#39;, &#39;arrested&#39;]
[&#39;2001&#39;, &#39;american&#39;, &#39;saudi&#39;, &#39;bin&#39;, &#39;world&#39;, &#39;al&#39;, &#39;sh&#39;, &#39;including&#39;, &#39;laden&#39;, &#39;joined&#39;]
[&#39;school&#39;, &#39;education&#39;, &#39;year&#39;, &#39;students&#39;, &#39;research&#39;, &#39;schools&#39;, &#39;college&#39;, &#39;high&#39;, &#39;university&#39;, &#39;program&#39;]
[&#39;events&#39;, &#39;time&#39;, &#39;mr&#39;, &#39;ride&#39;, &#39;roller&#39;, &#39;part&#39;, &#39;including&#39;, &#39;bicycle&#39;, &#39;riders&#39;, &#39;bike&#39;]
[&#39;montenegro&#39;, &#39;yugoslavia&#39;, &#39;serbia&#39;, &#39;school&#39;, &#39;serbian&#39;, &#39;albanian&#39;, &#39;albania&#39;, &#39;croatian&#39;, &#39;croatia&#39;, &#39;year&#39;]
[&#39;austin&#39;, &#39;shells&#39;, &#39;place&#39;, &#39;peter&#39;, &#39;shell&#39;, &#39;uk&#39;, &#39;school&#39;, &#39;2010&#39;, &#39;active&#39;, &#39;mark&#39;]
[&#39;york&#39;, &#39;series&#39;, &#39;masters&#39;, &#39;booth&#39;, &#39;world&#39;, &#39;free&#39;, &#39;2003&#39;, &#39;major&#39;, &#39;birmingham&#39;, &#39;setting&#39;]
[&#39;role&#39;, &#39;appeared&#39;, &#39;films&#39;, &#39;episode&#39;, &#39;television&#39;, &#39;show&#39;, &#39;series&#39;, &#39;character&#39;, &#39;movie&#39;, &#39;film&#39;]
[&#39;medicine&#39;, &#39;dr&#39;, &#39;training&#39;, &#39;care&#39;, &#39;hospital&#39;, &#39;health&#39;, &#39;surgery&#39;, &#39;center&#39;, &#39;dog&#39;, &#39;medical&#39;]
[&#39;norwegian&#39;, &#39;travis&#39;, &#39;2007&#39;, &#39;ste&#39;, &#39;bar&#39;, &#39;city&#39;, &#39;home&#39;, &#39;norway&#39;, &#39;parker&#39;, &#39;include&#39;]
[&#39;jewish&#39;, &#39;christian&#39;, &#39;people&#39;, &#39;god&#39;, &#39;gods&#39;, &#39;religious&#39;, &#39;great&#39;, &#39;church&#39;, &#39;churches&#39;, &#39;jesus&#39;]
[&#39;zion&#39;, &#39;contest&#39;, &#39;miss&#39;, &#39;relay&#39;, &#39;gold&#39;, &#39;post&#39;, &#39;nec&#39;, &#39;mori&#39;, &#39;yacht&#39;, &#39;time&#39;]
[&#39;york&#39;, &#39;theatre&#39;, &#39;theater&#39;, &#39;dance&#39;, &#39;musical&#39;, &#39;orchestra&#39;, &#39;opera&#39;, &#39;music&#39;, &#39;performed&#39;, &#39;festival&#39;]
[&#39;tax&#39;, &#39;money&#39;, &#39;financial&#39;, &#39;market&#39;, &#39;bank&#39;, &#39;million&#39;, &#39;business&#39;, &#39;price&#39;, &#39;services&#39;, &#39;company&#39;]
[&#39;life&#39;, &#39;death&#39;, &#39;father&#39;, &#39;end&#39;, &#39;find&#39;, &#39;back&#39;, &#39;man&#39;, &#39;make&#39;, &#39;time&#39;, &#39;tells&#39;]
[&#39;years&#39;, &#39;2007&#39;, &#39;walker&#39;, &#39;post&#39;, &#39;1911&#39;, &#39;croydon&#39;, &#39;burma&#39;, &#39;burmese&#39;, &#39;named&#39;, &#39;day&#39;]
[&#39;high&#39;, &#39;vegas&#39;, &#39;purchased&#39;, &#39;alice&#39;, &#39;paul&#39;, &#39;hotel&#39;, &#39;scott&#39;, &#39;ranch&#39;, &#39;las&#39;, &#39;highlands&#39;]
[&#39;horse&#39;, &#39;stakes&#39;, &#39;born&#39;, &#39;american&#39;, &#39;horses&#39;, &#39;race&#39;, &#39;boas&#39;, &#39;breed&#39;, &#39;english&#39;, &#39;racing&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Help on TopicModel in module turicreate.toolkits.topic_model.topic_model object:

class TopicModel(turicreate.toolkits._model.Model)
 |  TopicModel objects can be used to predict the underlying topic of a
 |  document.
 |  
 |  This model cannot be constructed directly.  Instead, use
 |  :func:`turicreate.topic_model.create` to create an instance
 |  of this model. A detailed list of parameter options and code samples
 |  are available in the documentation for the create function.
 |  
 |  Method resolution order:
 |      TopicModel
 |      turicreate.toolkits._model.Model
 |      turicreate.toolkits._model.ExposeAttributesFromProxy
 |      builtins.object
 |  
 |  Methods defined here:
 |  
 |  __init__(self, model_proxy)
 |      Initialize self.  See help(type(self)) for accurate signature.
 |  
 |  __repr__(self)
 |      Print a string description of the model when the model name is entered
 |      in the terminal.
 |  
 |  __str__(self)
 |      Return a string description of the model to the ``print`` method.
 |      
 |      Returns
 |      -------
 |      out : string
 |          A description of the model.
 |  
 |  evaluate(self, train_data, test_data=None, metric=&#39;perplexity&#39;)
 |      Estimate the model&#39;s ability to predict new data. Imagine you have a
 |      corpus of books. One common approach to evaluating topic models is to
 |      train on the first half of all of the books and see how well the model
 |      predicts the second half of each book.
 |      
 |      This method returns a metric called perplexity, which  is related to the
 |      likelihood of observing these words under the given model. See
 |      :py:func:`~turicreate.topic_model.perplexity` for more details.
 |      
 |      The provided `train_data` and `test_data` must have the same length,
 |      i.e., both data sets must have the same number of documents; the model
 |      will use train_data to estimate which topic the document belongs to, and
 |      this is used to estimate the model&#39;s performance at predicting the
 |      unseen words in the test data.
 |      
 |      See :py:func:`~turicreate.topic_model.TopicModel.predict` for details
 |      on how these predictions are made, and see
 |      :py:func:`~turicreate.text_analytics.random_split` for a helper function
 |      that can be used for making train/test splits.
 |      
 |      Parameters
 |      ----------
 |      train_data : SArray or SFrame
 |          A set of documents to predict topics for.
 |      
 |      test_data : SArray or SFrame, optional
 |          A set of documents to evaluate performance on.
 |          By default this will set to be the same as train_data.
 |      
 |      metric : str
 |          The chosen metric to use for evaluating the topic model.
 |          Currently only &#39;perplexity&#39; is supported.
 |      
 |      Returns
 |      -------
 |      out : dict
 |          The set of estimated evaluation metrics.
 |      
 |      See Also
 |      --------
 |      predict, turicreate.toolkits.text_analytics.random_split
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; docs = turicreate.SArray(&#39;https://static.turi.com/datasets/nips-text&#39;)
 |      &gt;&gt;&gt; train_data, test_data = turicreate.text_analytics.random_split(docs)
 |      &gt;&gt;&gt; m = turicreate.topic_model.create(train_data)
 |      &gt;&gt;&gt; m.evaluate(train_data, test_data)
 |      {&#39;perplexity&#39;: 2467.530370396021}
 |  
 |  get_topics(self, topic_ids=None, num_words=5, cdf_cutoff=1.0, output_type=&#39;topic_probabilities&#39;)
 |      Get the words associated with a given topic. The score column is the
 |      probability of choosing that word given that you have chosen a
 |      particular topic.
 |      
 |      Parameters
 |      ----------
 |      topic_ids : list of int, optional
 |          The topics to retrieve words. Topic ids are zero-based.
 |          Throws an error if greater than or equal to m[&#39;num_topics&#39;], or
 |          if the requested topic name is not present.
 |      
 |      num_words : int, optional
 |          The number of words to show.
 |      
 |      cdf_cutoff : float, optional
 |          Allows one to only show the most probable words whose cumulative
 |          probability is below this cutoff. For example if there exist
 |          three words where
 |      
 |          .. math::
 |             p(word_1 | topic_k) = .1
 |      
 |             p(word_2 | topic_k) = .2
 |      
 |             p(word_3 | topic_k) = .05
 |      
 |          then setting :math:`cdf_{cutoff}=.3` would return only
 |          :math:`word_1` and :math:`word_2` since
 |          :math:`p(word_1 | topic_k) + p(word_2 | topic_k) &lt;= cdf_{cutoff}`
 |      
 |      output_type : {&#39;topic_probabilities&#39; | &#39;topic_words&#39;}, optional
 |          Determine the type of desired output. See below.
 |      
 |      Returns
 |      -------
 |      out : SFrame
 |          If output_type is &#39;topic_probabilities&#39;, then the returned value is
 |          an SFrame with a column of words ranked by a column of scores for
 |          each topic. Otherwise, the returned value is a SArray where
 |          each element is a list of the most probable words for each topic.
 |      
 |      Examples
 |      --------
 |      Get the highest ranked words for all topics.
 |      
 |      &gt;&gt;&gt; docs = turicreate.SArray(&#39;https://static.turi.com/datasets/nips-text&#39;)
 |      &gt;&gt;&gt; m = turicreate.topic_model.create(docs,
 |                                          num_iterations=50)
 |      &gt;&gt;&gt; m.get_topics()
 |      +-------+----------+-----------------+
 |      | topic |   word   |      score      |
 |      +-------+----------+-----------------+
 |      |   0   |   cell   |  0.028974400831 |
 |      |   0   |  input   | 0.0259470208503 |
 |      |   0   |  image   | 0.0215721599763 |
 |      |   0   |  visual  | 0.0173635081992 |
 |      |   0   |  object  | 0.0172447874156 |
 |      |   1   | function | 0.0482834508265 |
 |      |   1   |  input   | 0.0456270024091 |
 |      |   1   |  point   | 0.0302662839454 |
 |      |   1   |  result  | 0.0239474934631 |
 |      |   1   | problem  | 0.0231750116011 |
 |      |  ...  |   ...    |       ...       |
 |      +-------+----------+-----------------+
 |      
 |      Get the highest ranked words for topics 0 and 1 and show 15 words per
 |      topic.
 |      
 |      &gt;&gt;&gt; m.get_topics([0, 1], num_words=15)
 |      +-------+----------+------------------+
 |      | topic |   word   |      score       |
 |      +-------+----------+------------------+
 |      |   0   |   cell   |  0.028974400831  |
 |      |   0   |  input   | 0.0259470208503  |
 |      |   0   |  image   | 0.0215721599763  |
 |      |   0   |  visual  | 0.0173635081992  |
 |      |   0   |  object  | 0.0172447874156  |
 |      |   0   | response | 0.0139740298286  |
 |      |   0   |  layer   | 0.0122585145062  |
 |      |   0   | features | 0.0115343177265  |
 |      |   0   | feature  | 0.0103530459301  |
 |      |   0   | spatial  | 0.00823387994361 |
 |      |  ...  |   ...    |       ...        |
 |      +-------+----------+------------------+
 |      
 |      If one wants to instead just get the top words per topic, one may
 |      change the format of the output as follows.
 |      
 |      &gt;&gt;&gt; topics = m.get_topics(output_type=&#39;topic_words&#39;)
 |      dtype: list
 |      Rows: 10
 |      [[&#39;cell&#39;, &#39;image&#39;, &#39;input&#39;, &#39;object&#39;, &#39;visual&#39;],
 |       [&#39;algorithm&#39;, &#39;data&#39;, &#39;learning&#39;, &#39;method&#39;, &#39;set&#39;],
 |       [&#39;function&#39;, &#39;input&#39;, &#39;point&#39;, &#39;problem&#39;, &#39;result&#39;],
 |       [&#39;model&#39;, &#39;output&#39;, &#39;pattern&#39;, &#39;set&#39;, &#39;unit&#39;],
 |       [&#39;action&#39;, &#39;learning&#39;, &#39;net&#39;, &#39;problem&#39;, &#39;system&#39;],
 |       [&#39;error&#39;, &#39;function&#39;, &#39;network&#39;, &#39;parameter&#39;, &#39;weight&#39;],
 |       [&#39;information&#39;, &#39;level&#39;, &#39;neural&#39;, &#39;threshold&#39;, &#39;weight&#39;],
 |       [&#39;control&#39;, &#39;field&#39;, &#39;model&#39;, &#39;network&#39;, &#39;neuron&#39;],
 |       [&#39;hidden&#39;, &#39;layer&#39;, &#39;system&#39;, &#39;training&#39;, &#39;vector&#39;],
 |       [&#39;component&#39;, &#39;distribution&#39;, &#39;local&#39;, &#39;model&#39;, &#39;optimal&#39;]]
 |  
 |  predict(self, dataset, output_type=&#39;assignment&#39;, num_burnin=None)
 |      Use the model to predict topics for each document. The provided
 |      `dataset` should be an SArray object where each element is a dict
 |      representing a single document in bag-of-words format, where keys
 |      are words and values are their corresponding counts. If `dataset` is
 |      an SFrame, then it must contain a single column of dict type.
 |      
 |      The current implementation will make inferences about each document
 |      given its estimates of the topics learned when creating the model.
 |      This is done via Gibbs sampling.
 |      
 |      Parameters
 |      ----------
 |      dataset : SArray, SFrame of type dict
 |          A set of documents to use for making predictions.
 |      
 |      output_type : str, optional
 |          The type of output desired. This can either be
 |      
 |          - assignment: the returned values are integers in [0, num_topics)
 |          - probability: each returned prediction is a vector with length
 |            num_topics, where element k represents the probability that
 |            document belongs to topic k.
 |      
 |      num_burnin : int, optional
 |          The number of iterations of Gibbs sampling to perform when
 |          inferring the topics for documents at prediction time.
 |          If provided this will override the burnin value set during
 |          training.
 |      
 |      Returns
 |      -------
 |      out : SArray
 |      
 |      See Also
 |      --------
 |      evaluate
 |      
 |      Examples
 |      --------
 |      Make predictions about which topic each document belongs to.
 |      
 |      &gt;&gt;&gt; docs = turicreate.SArray(&#39;https://static.turi.com/datasets/nips-text&#39;)
 |      &gt;&gt;&gt; m = turicreate.topic_model.create(docs)
 |      &gt;&gt;&gt; pred = m.predict(docs)
 |      
 |      If one is interested in the probability of each topic
 |      
 |      &gt;&gt;&gt; pred = m.predict(docs, output_type=&#39;probability&#39;)
 |      
 |      Notes
 |      -----
 |      For each unique word w in a document d, we sample an assignment to
 |      topic k with probability proportional to
 |      
 |      .. math::
 |          p(z_{dw} = k) \propto (n_{d,k} + \alpha) * \Phi_{w,k}
 |      
 |      where
 |      
 |      - :math:`W` is the size of the vocabulary,
 |      - :math:`n_{d,k}` is the number of other times we have assigned a word in
 |        document to d to topic :math:`k`,
 |      - :math:`\Phi_{w,k}` is the probability under the model of choosing word
 |        :math:`w` given the word is of topic :math:`k`. This is the matrix
 |        returned by calling `m[&#39;topics&#39;]`.
 |      
 |      This represents a collapsed Gibbs sampler for the document assignments
 |      while we keep the topics learned during training fixed.
 |      This process is done in parallel across all documents, five times per
 |      document.
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from turicreate.toolkits._model.Model:
 |  
 |  save(self, location)
 |      Save the model. The model is saved as a directory which can then be
 |      loaded using the :py:func:`~turicreate.load_model` method.
 |      
 |      Parameters
 |      ----------
 |      location : string
 |          Target destination for the model. Can be a local path or remote URL.
 |      
 |      See Also
 |      ----------
 |      turicreate.load_model
 |      
 |      Examples
 |      ----------
 |      &gt;&gt;&gt; model.save(&#39;my_model_file&#39;)
 |      &gt;&gt;&gt; loaded_model = turicreate.load_model(&#39;my_model_file&#39;)
 |  
 |  summary(self, output=None)
 |      Print a summary of the model. The summary includes a description of
 |      training data, options, hyper-parameters, and statistics measured
 |      during model creation.
 |      
 |      Parameters
 |      ----------
 |      output : str, None
 |          The type of summary to return.
 |      
 |          - None or &#39;stdout&#39; : print directly to stdout.
 |      
 |          - &#39;str&#39; : string of summary
 |      
 |          - &#39;dict&#39; : a dict with &#39;sections&#39; and &#39;section_titles&#39; ordered
 |            lists. The entries in the &#39;sections&#39; list are tuples of the form
 |            (&#39;label&#39;, &#39;value&#39;).
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; m.summary()
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from turicreate.toolkits._model.ExposeAttributesFromProxy:
 |  
 |  __dir__(self)
 |      Combine the results of dir from the current class with the results of
 |      list_fields().
 |  
 |  __getattribute__(self, attr)
 |      Use the internal proxy object for obtaining list_fields.
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from turicreate.toolkits._model.ExposeAttributesFromProxy:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from turicreate.toolkits._model.ExposeAttributesFromProxy:
 |  
 |  __proxy__ = None
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">print_topics</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="n">topics</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">get_topics</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">topics</span> <span class="o">=</span> <span class="n">topics</span><span class="o">.</span><span class="n">unstack</span><span class="p">([</span><span class="s1">&#39;word&#39;</span><span class="p">,</span><span class="s1">&#39;score&#39;</span><span class="p">],</span> <span class="n">new_column_name</span><span class="o">=</span><span class="s1">&#39;topic_words&#39;</span><span class="p">)[</span><span class="s1">&#39;topic_words&#39;</span><span class="p">]</span>
    <span class="n">topics</span> <span class="o">=</span> <span class="n">topics</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">topic</span> <span class="ow">in</span> <span class="n">topics</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">topic</span><span class="p">)</span>
<span class="n">print_topics</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;people&#39;, &#39;texas&#39;, &#39;tropical&#39;, &#39;florida&#39;, &#39;storm&#39;]
[&#39;school&#39;, &#39;founded&#39;, &#39;wilson&#39;, &#39;harvard&#39;, &#39;including&#39;]
[&#39;members&#39;, &#39;association&#39;, &#39;society&#39;, &#39;member&#39;, &#39;group&#39;]
[&#39;summer&#39;, &#39;date&#39;, &#39;julian&#39;, &#39;years&#39;, &#39;george&#39;]
[&#39;war&#39;, &#39;general&#39;, &#39;battle&#39;, &#39;german&#39;, &#39;army&#39;]
[&#39;california&#39;, &#39;angeles&#39;, &#39;san&#39;, &#39;los&#39;, &#39;santa&#39;]
[&#39;miller&#39;, &#39;morris&#39;, &#39;2005&#39;, &#39;1999&#39;, &#39;time&#39;]
[&#39;game&#39;, &#39;season&#39;, &#39;team&#39;, &#39;points&#39;, &#39;games&#39;]
[&#39;evans&#39;, &#39;years&#39;, &#39;time&#39;, &#39;green&#39;, &#39;lebanon&#39;]
[&#39;und&#39;, &#39;der&#39;, &#39;die&#39;, &#39;van&#39;, &#39;von&#39;]
[&#39;wear&#39;, &#39;worn&#39;, &#39;made&#39;, &#39;green&#39;, &#39;top&#39;]
[&#39;2008&#39;, &#39;year&#39;, &#39;2007&#39;, &#39;2009&#39;, &#39;2010&#39;]
[&#39;oregon&#39;, &#39;magazine&#39;, &#39;year&#39;, &#39;portland&#39;, &#39;beer&#39;]
[&#39;network&#39;, &#39;news&#39;, &#39;radio&#39;, &#39;show&#39;, &#39;station&#39;]
[&#39;bridge&#39;, &#39;north&#39;, &#39;route&#39;, &#39;west&#39;, &#39;road&#39;]
[&#39;part&#39;, &#39;born&#39;, &#39;na&#39;, &#39;agent&#39;, &#39;valid&#39;]
[&#39;years&#39;, &#39;family&#39;, &#39;father&#39;, &#39;died&#39;, &#39;time&#39;]
[&#39;united&#39;, &#39;population&#39;, &#39;people&#39;, &#39;american&#39;, &#39;states&#39;]
[&#39;work&#39;, &#39;magazine&#39;, &#39;published&#39;, &#39;book&#39;, &#39;books&#39;]
[&#39;collection&#39;, &#39;museum&#39;, &#39;arts&#39;, &#39;art&#39;, &#39;work&#39;]
[&#39;white&#39;, &#39;black&#39;, &#39;red&#39;, &#39;flag&#39;, &#39;blue&#39;]
[&#39;aircraft&#39;, &#39;design&#39;, &#39;space&#39;, &#39;project&#39;, &#39;flight&#39;]
[&#39;trenn&#39;, &#39;phillip&#39;, &#39;nitra&#39;, &#39;koice&#39;, &#39;preov&#39;]
[&#39;engine&#39;, &#39;cars&#39;, &#39;car&#39;, &#39;race&#39;, &#39;model&#39;]
[&#39;london&#39;, &#39;duck&#39;, &#39;journal&#39;, &#39;philadelphia&#39;, &#39;york&#39;]
[&#39;english&#39;, &#39;word&#39;, &#39;language&#39;, &#39;languages&#39;, &#39;words&#39;]
[&#39;dna&#39;, &#39;cell&#39;, &#39;cells&#39;, &#39;enzyme&#39;, &#39;protein&#39;]
[&#39;2009&#39;, &#39;calendar&#39;, &#39;year&#39;, &#39;link&#39;, &#39;list&#39;]
[&#39;court&#39;, &#39;act&#39;, &#39;state&#39;, &#39;states&#39;, &#39;law&#39;]
[&#39;station&#39;, &#39;services&#39;, &#39;railway&#39;, &#39;line&#39;, &#39;service&#39;]
[&#39;cemetery&#39;, &#39;university&#39;, &#39;mexico&#39;, &#39;texas&#39;, &#39;corpus&#39;]
[&#39;film&#39;, &#39;worked&#39;, &#39;festival&#39;, &#39;award&#39;, &#39;awards&#39;]
[&#39;chinese&#39;, &#39;emperor&#39;, &#39;bc&#39;, &#39;king&#39;, &#39;empire&#39;]
[&#39;islands&#39;, &#39;region&#39;, &#39;ships&#39;, &#39;island&#39;, &#39;ship&#39;]
[&#39;water&#39;, &#39;park&#39;, &#39;lake&#39;, &#39;area&#39;, &#39;river&#39;]
[&#39;2007&#39;, &#39;2009&#39;, &#39;december&#39;, &#39;2010&#39;, &#39;2008&#39;]
[&#39;match&#39;, &#39;world&#39;, &#39;title&#39;, &#39;won&#39;, &#39;championship&#39;]
[&#39;msn&#39;, &#39;house&#39;, &#39;2010&#39;, &#39;skating&#39;, &#39;school&#39;]
[&#39;school&#39;, &#39;westfield&#39;, &#39;easy&#39;, &#39;british&#39;, &#39;2003&#39;]
[&#39;player&#39;, &#39;players&#39;, &#39;game&#39;, &#39;games&#39;, &#39;series&#39;]
[&#39;team&#39;, &#39;league&#39;, &#39;season&#39;, &#39;club&#39;, &#39;football&#39;]
[&#39;local&#39;, &#39;list&#39;, &#39;found&#39;, &#39;called&#39;, &#39;2010&#39;]
[&#39;plotdata&#39;, &#39;received&#39;, &#39;world&#39;, &#39;part&#39;, &#39;usa&#39;]
[&#39;income&#39;, &#39;population&#39;, &#39;18&#39;, &#39;years&#39;, &#39;age&#39;]
[&#39;youth&#39;, &#39;ross&#39;, &#39;griffin&#39;, &#39;joined&#39;, &#39;williams&#39;]
[&#39;south&#39;, &#39;government&#39;, &#39;international&#39;, &#39;countries&#39;, &#39;world&#39;]
[&#39;national&#39;, &#39;private&#39;, &#39;back&#39;, &#39;chicago&#39;, &#39;baldwin&#39;]
[&#39;cj&#39;, &#39;hill&#39;, &#39;morgan&#39;, &#39;davis&#39;, &#39;child&#39;]
[&#39;set&#39;, &#39;1&#39;, &#39;model&#39;, &#39;theory&#39;, &#39;number&#39;]
[&#39;social&#39;, &#39;people&#39;, &#39;time&#39;, &#39;form&#39;, &#39;work&#39;]
[&#39;french&#39;, &#39;de&#39;, &#39;spanish&#39;, &#39;france&#39;, &#39;la&#39;]
[&#39;area&#39;, &#39;city&#39;, &#39;building&#39;, &#39;town&#39;, &#39;built&#39;]
[&#39;food&#39;, &#39;popular&#39;, &#39;made&#39;, &#39;called&#39;, &#39;wine&#39;]
[&#39;canadian&#39;, &#39;british&#39;, &#39;ontario&#39;, &#39;canada&#39;, &#39;toronto&#39;]
[&#39;india&#39;, &#39;temple&#39;, &#39;khan&#39;, &#39;pakistan&#39;, &#39;indian&#39;]
[&#39;babylon&#39;, &#39;2004&#39;, &#39;area&#39;, &#39;class&#39;, &#39;5&#39;]
[&#39;water&#39;, &#39;process&#39;, &#39;nuclear&#39;, &#39;energy&#39;, &#39;form&#39;]
[&#39;international&#39;, &#39;2010&#39;, &#39;airport&#39;, &#39;airlines&#39;, &#39;airline&#39;]
[&#39;15&#39;, &#39;park&#39;, &#39;head&#39;, &#39;stone&#39;, &#39;2003&#39;]
[&#39;soviet&#39;, &#39;russia&#39;, &#39;poland&#39;, &#39;russian&#39;, &#39;polish&#39;]
[&#39;john&#39;, &#39;royal&#39;, &#39;william&#39;, &#39;sir&#39;, &#39;king&#39;]
[&#39;virginia&#39;, &#39;county&#39;, &#39;served&#39;, &#39;state&#39;, &#39;carolina&#39;]
[&#39;election&#39;, &#39;government&#39;, &#39;president&#39;, &#39;state&#39;, &#39;party&#39;]
[&#39;school&#39;, &#39;county&#39;, &#39;national&#39;, &#39;districts&#39;, &#39;district&#39;]
[&#39;group&#39;, &#39;war&#39;, &#39;force&#39;, &#39;air&#39;, &#39;aircraft&#39;]
[&#39;world&#39;, &#39;university&#39;, &#39;2010&#39;, &#39;chams&#39;, &#39;number&#39;]
[&#39;energy&#39;, &#39;power&#39;, &#39;system&#39;, &#39;time&#39;, &#39;light&#39;]
[&#39;bill&#39;, &#39;professor&#39;, &#39;degree&#39;, &#39;served&#39;, &#39;university&#39;]
[&#39;joseph&#39;, &#39;head&#39;, &#39;smiths&#39;, &#39;smith&#39;, &#39;school&#39;]
[&#39;birds&#39;, &#39;family&#39;, &#39;small&#39;, &#39;species&#39;, &#39;found&#39;]
[&#39;fat&#39;, &#39;2006&#39;, &#39;named&#39;, &#39;work&#39;, &#39;vincent&#39;]
[&#39;business&#39;, &#39;stores&#39;, &#39;oil&#39;, &#39;company&#39;, &#39;mine&#39;]
[&#39;2000&#39;, &#39;kitty&#39;, &#39;camp&#39;, &#39;moved&#39;, &#39;obesity&#39;]
[&#39;1994&#39;, &#39;christmas&#39;, &#39;world&#39;, &#39;national&#39;, &#39;minor&#39;]
[&#39;bishop&#39;, &#39;saint&#39;, &#39;church&#39;, &#39;st&#39;, &#39;century&#39;]
[&#39;band&#39;, &#39;released&#39;, &#39;album&#39;, &#39;music&#39;, &#39;song&#39;]
[&#39;made&#39;, &#39;zealand&#39;, &#39;australian&#39;, &#39;australia&#39;, &#39;south&#39;]
[&#39;system&#39;, &#39;software&#39;, &#39;data&#39;, &#39;systems&#39;, &#39;information&#39;]
[&#39;full&#39;, &#39;fair&#39;, &#39;philippines&#39;, &#39;manila&#39;, &#39;philippine&#39;]
[&#39;began&#39;, &#39;jones&#39;, &#39;minnesota&#39;, &#39;anderson&#39;, &#39;td&#39;]
[&#39;county&#39;, &#39;ireland&#39;, &#39;medal&#39;, &#39;irish&#39;, &#39;dublin&#39;]
[&#39;school&#39;, &#39;held&#39;, &#39;village&#39;, &#39;local&#39;, &#39;community&#39;]
[&#39;family&#39;, &#39;city&#39;, &#39;prison&#39;, &#39;police&#39;, &#39;york&#39;]
[&#39;al&#39;, &#39;bin&#39;, &#39;2001&#39;, &#39;joined&#39;, &#39;world&#39;]
[&#39;college&#39;, &#39;university&#39;, &#39;education&#39;, &#39;students&#39;, &#39;school&#39;]
[&#39;including&#39;, &#39;riders&#39;, &#39;ride&#39;, &#39;time&#39;, &#39;part&#39;]
[&#39;year&#39;, &#39;yugoslavia&#39;, &#39;serbian&#39;, &#39;albanian&#39;, &#39;serbia&#39;]
[&#39;shells&#39;, &#39;uk&#39;, &#39;school&#39;, &#39;austin&#39;, &#39;shell&#39;]
[&#39;world&#39;, &#39;birmingham&#39;, &#39;york&#39;, &#39;booth&#39;, &#39;free&#39;]
[&#39;show&#39;, &#39;role&#39;, &#39;episode&#39;, &#39;series&#39;, &#39;film&#39;]
[&#39;dr&#39;, &#39;care&#39;, &#39;health&#39;, &#39;medical&#39;, &#39;hospital&#39;]
[&#39;include&#39;, &#39;2007&#39;, &#39;norway&#39;, &#39;norwegian&#39;, &#39;city&#39;]
[&#39;religious&#39;, &#39;christian&#39;, &#39;church&#39;, &#39;god&#39;, &#39;jesus&#39;]
[&#39;nec&#39;, &#39;mori&#39;, &#39;miss&#39;, &#39;post&#39;, &#39;time&#39;]
[&#39;festival&#39;, &#39;theatre&#39;, &#39;dance&#39;, &#39;music&#39;, &#39;opera&#39;]
[&#39;business&#39;, &#39;company&#39;, &#39;financial&#39;, &#39;bank&#39;, &#39;million&#39;]
[&#39;man&#39;, &#39;tells&#39;, &#39;life&#39;, &#39;back&#39;, &#39;time&#39;]
[&#39;years&#39;, &#39;2007&#39;, &#39;post&#39;, &#39;croydon&#39;, &#39;day&#39;]
[&#39;las&#39;, &#39;scott&#39;, &#39;vegas&#39;, &#39;ranch&#39;, &#39;hotel&#39;]
[&#39;american&#39;, &#39;horses&#39;, &#39;horse&#39;, &#39;breed&#39;, &#39;stakes&#39;]
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>pred = m.predict(another_data)</p>
</div></blockquote>
<blockquote>
<div><p>pred = m.predict(another_data, output_type=’probabilities’)</p>
</div></blockquote>
<section id="initializing-from-other-models">
<h3>Initializing from other models<a class="headerlink" href="#initializing-from-other-models" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">dir</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;__class__&#39;,
 &#39;__delattr__&#39;,
 &#39;__dict__&#39;,
 &#39;__dir__&#39;,
 &#39;__doc__&#39;,
 &#39;__eq__&#39;,
 &#39;__format__&#39;,
 &#39;__ge__&#39;,
 &#39;__getattribute__&#39;,
 &#39;__gt__&#39;,
 &#39;__hash__&#39;,
 &#39;__init__&#39;,
 &#39;__le__&#39;,
 &#39;__lt__&#39;,
 &#39;__module__&#39;,
 &#39;__ne__&#39;,
 &#39;__new__&#39;,
 &#39;__proxy__&#39;,
 &#39;__reduce__&#39;,
 &#39;__reduce_ex__&#39;,
 &#39;__repr__&#39;,
 &#39;__setattr__&#39;,
 &#39;__sizeof__&#39;,
 &#39;__str__&#39;,
 &#39;__subclasshook__&#39;,
 &#39;__weakref__&#39;,
 &#39;_get&#39;,
 &#39;_get_queryable_methods&#39;,
 &#39;_get_summary_struct&#39;,
 &#39;_list_fields&#39;,
 &#39;_name&#39;,
 &#39;_native_name&#39;,
 &#39;_training_stats&#39;,
 &#39;alpha&#39;,
 &#39;beta&#39;,
 &#39;evaluate&#39;,
 &#39;get_topics&#39;,
 &#39;num_burnin&#39;,
 &#39;num_iterations&#39;,
 &#39;num_topics&#39;,
 &#39;predict&#39;,
 &#39;print_interval&#39;,
 &#39;save&#39;,
 &#39;summary&#39;,
 &#39;topics&#39;,
 &#39;training_iterations&#39;,
 &#39;training_time&#39;,
 &#39;validation_time&#39;,
 &#39;verbose&#39;,
 &#39;vocabulary&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="o">.</span><span class="n">vocabulary</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dtype: str
Rows: 108205
[&#39;book&#39;, &#39;political&#39;, &#39;time&#39;, &#39;readers&#39;, &#39;individual&#39;, &#39;appeared&#39;, &#39;peikoff&#39;, &#39;concepts&#39;, &#39;100&#39;, &#39;picture&#39;, &#39;america&#39;, &#39;reviewers&#39;, &#39;philosopher&#39;, &#39;screenwriter&#39;, &#39;work&#39;, &#39;traditional&#39;, &#39;purged&#39;, &#39;ayn&#39;, &#39;york&#39;, &#39;articles&#39;, &#39;pharmacy&#39;, &#39;scholarship&#39;, &#39;2001&#39;, &#39;designed&#39;, &#39;permission&#39;, &#39;taking&#39;, &#39;historian&#39;, &#39;library&#39;, &#39;russian&#39;, &#39;extent&#39;, &#39;childhood&#39;, &#39;respondents&#39;, &#39;language&#39;, &#39;alisa&#39;, &#39;writing&#39;, &#39;union&#39;, &#39;libertarian&#39;, &#39;positive&#39;, &#39;jennifer&#39;, &#39;notes&#39;, &#39;line&#39;, &#39;burns&#39;, &#39;state&#39;, &#39;crimea&#39;, &#39;sciabarra&#39;, &#39;based&#39;, &#39;rights&#39;, &#39;life&#39;, &#39;shes&#39;, &#39;argument&#39;, &#39;nonfiction&#39;, &#39;rejection&#39;, &#39;allowed&#39;, &#39;reason&#39;, &#39;culture&#39;, &#39;closest&#39;, &#39;shrugged&#39;, &#39;free&#39;, &#39;january&#39;, &#39;success&#39;, &#39;living&#39;, &#39;robert&#39;, &#39;literary&#39;, &#39;animated&#39;, &#39;american&#39;, &#39;reviews&#39;, &#39;paterson&#39;, &#39;people&#39;, &#39;percent&#39;, &#39;house&#39;, &#39;academic&#39;, &#39;sacrificing&#39;, &#39;referred&#39;, &#39;broadway&#39;, &#39;fountainhead&#39;, &#39;lectures&#39;, &#39;john&#39;, &#39;inspiration&#39;, &#39;conditions&#39;, &#39;lifetime&#39;, &#39;written&#39;, &#39;1938&#39;, &#39;established&#39;, &#39;barbara&#39;, &#39;twelve&#39;, &#39;modern&#39;, &#39;final&#39;, &#39;intellectual&#39;, &#39;audience&#39;, &#39;stated&#39;, &#39;selfinterest&#39;, &#39;achievement&#39;, &#39;century&#39;, &#39;relationship&#39;, &#39;allowing&#39;, &#39;delivering&#39;, &#39;writers&#39;, &#39;influence&#39;, &#39;branden&#39;, &#39;film&#39;, ... ]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="o">.</span><span class="n">topics</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>108205
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m2</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">topic_model</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span>
                                 <span class="n">num_topics</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                 <span class="n">initial_topics</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">topics</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre>Initializing from provided topics and vocabulary.</pre></div><div class="output text_html"><pre>Learning a topic model</pre></div><div class="output text_html"><pre>       Number of documents     72269</pre></div><div class="output text_html"><pre>           Vocabulary size    171005</pre></div><div class="output text_html"><pre>   Running collapsed Gibbs sampling</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div><div class="output text_html"><pre>| Iteration | Elapsed Time  | Tokens/Second  | Est. Perplexity |</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div><div class="output text_html"><pre>| 10        | 2.99s         | 7.251e+06      | 0               |</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div></div>
</div>
</section>
<section id="seeding-the-model-with-prior-knowledge">
<h3>Seeding the model with prior knowledge<a class="headerlink" href="#seeding-the-model-with-prior-knowledge" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">associations</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">SFrame</span><span class="p">()</span>
<span class="n">associations</span><span class="p">[</span><span class="s1">&#39;word&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;recognition&#39;</span><span class="p">]</span>
<span class="n">associations</span><span class="p">[</span><span class="s1">&#39;topic&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m2</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">topic_model</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span>
                                 <span class="n">num_topics</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                 <span class="n">num_iterations</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                                 <span class="n">associations</span><span class="o">=</span><span class="n">associations</span><span class="p">,</span> 
                                 <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre>Learning a topic model</pre></div><div class="output text_html"><pre>       Number of documents     72269</pre></div><div class="output text_html"><pre>           Vocabulary size    171005</pre></div><div class="output text_html"><pre>   Running collapsed Gibbs sampling</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div><div class="output text_html"><pre>| Iteration | Elapsed Time  | Tokens/Second  | Est. Perplexity |</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div><div class="output text_html"><pre>| 10        | 2.10s         | 1.04058e+07    | 0               |</pre></div><div class="output text_html"><pre>| 20        | 3.97s         | 1.09325e+07    | 0               |</pre></div><div class="output text_html"><pre>| 30        | 5.79s         | 9.42067e+06    | 0               |</pre></div><div class="output text_html"><pre>| 40        | 7.66s         | 1.0637e+07     | 0               |</pre></div><div class="output text_html"><pre>| 50        | 9.51s         | 9.86708e+06    | 0               |</pre></div><div class="output text_html"><pre>+-----------+---------------+----------------+-----------------+</pre></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m2</span><span class="o">.</span><span class="n">get_topics</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div style="max-height:1000px;max-width:1500px;overflow:auto;"><table frame="box" rules="cols">
    <tr>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">topic</th>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">word</th>
        <th style="padding-left: 1em; padding-right: 1em; text-align: center">score</th>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">line</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.0109206038501584</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">german</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.010542910113799127</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">de</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.010148794910641626</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">railway</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.010079824750089063</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">english</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.009242329943379372</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">chinese</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.008900763433976205</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">language</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.008654441432002766</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">china</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.008490226764020474</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">large</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.008004151346792889</td>
    </tr>
    <tr>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">russian</td>
        <td style="padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top">0.007705280651065117</td>
    </tr>
</table>
[200 rows x 3 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_topics</span><span class="p">(</span><span class="n">m2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;german&#39;, &#39;line&#39;, &#39;english&#39;, &#39;de&#39;, &#39;railway&#39;]
[&#39;son&#39;, &#39;time&#39;, &#39;book&#39;, &#39;life&#39;, &#39;john&#39;]
[&#39;role&#39;, &#39;episode&#39;, &#39;show&#39;, &#39;film&#39;, &#39;series&#39;]
[&#39;york&#39;, &#39;station&#39;, &#39;park&#39;, &#39;de&#39;, &#39;company&#39;]
[&#39;information&#39;, &#39;law&#39;, &#39;time&#39;, &#39;work&#39;, &#39;social&#39;]
[&#39;west&#39;, &#39;county&#39;, &#39;north&#39;, &#39;city&#39;, &#39;east&#39;]
[&#39;years&#39;, &#39;18&#39;, &#39;population&#39;, &#39;town&#39;, &#39;age&#39;]
[&#39;games&#39;, &#39;team&#39;, &#39;game&#39;, &#39;won&#39;, &#39;season&#39;]
[&#39;company&#39;, &#39;aircraft&#39;, &#39;air&#39;, &#39;force&#39;, &#39;division&#39;]
[&#39;india&#39;, &#39;art&#39;, &#39;century&#39;, &#39;roman&#39;, &#39;church&#39;]
[&#39;government&#39;, &#39;students&#39;, &#39;national&#39;, &#39;state&#39;, &#39;party&#39;]
[&#39;schools&#39;, &#39;college&#39;, &#39;university&#39;, &#39;school&#39;, &#39;high&#39;]
[&#39;series&#39;, &#39;world&#39;, &#39;back&#39;, &#39;king&#39;, &#39;time&#39;]
[&#39;services&#39;, &#39;system&#39;, &#39;service&#39;, &#39;million&#39;, &#39;engine&#39;]
[&#39;area&#39;, &#39;built&#39;, &#39;river&#39;, &#39;road&#39;, &#39;region&#39;]
[&#39;systems&#39;, &#39;set&#39;, &#39;number&#39;, &#39;system&#39;, &#39;data&#39;]
[&#39;water&#39;, &#39;small&#39;, &#39;species&#39;, &#39;food&#39;, &#39;found&#39;]
[&#39;league&#39;, &#39;year&#39;, &#39;club&#39;, &#39;song&#39;, &#39;time&#39;]
[&#39;released&#39;, &#39;music&#39;, &#39;songs&#39;, &#39;album&#39;, &#39;band&#39;]
[&#39;army&#39;, &#39;united&#39;, &#39;states&#39;, &#39;court&#39;, &#39;war&#39;]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id1">
<h2>阅读材料<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<p><a class="reference external" href="https://apple.github.io/turicreate/docs/userguide/text/">https://apple.github.io/turicreate/docs/userguide/text/</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="12-topic-models-update.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">主题模型简介</p>
      </div>
    </a>
    <a class="right-next"
       href="13-recsys-intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">第九章 推荐系统简介</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transformations">Transformations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#text-cleaning">Text Cleaning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#topic-modeling">Topic modeling</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#initializing-from-other-models">Initializing from other models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#seeding-the-model-with-prior-knowledge">Seeding the model with prior knowledge</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">阅读材料</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Cheng-Jun Wang
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>